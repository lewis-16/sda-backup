{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "384e9b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import spikeinterface as si\n",
    "import matplotlib.pyplot as plt\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.widgets as sw\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import json\n",
    "import probeinterface\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface as si\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5cedfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub1-instance1_B005.ns6\n",
      "Processing chunk 0-500000 (500000 samples)\n",
      "Processing chunk 500000-1000000 (500000 samples)\n",
      "Processing chunk 1000000-1500000 (500000 samples)\n",
      "Processing chunk 1500000-2000000 (500000 samples)\n",
      "Processing chunk 2000000-2500000 (500000 samples)\n",
      "Processing chunk 2500000-3000000 (500000 samples)\n",
      "Processing chunk 3000000-3500000 (500000 samples)\n",
      "Processing chunk 3500000-4000000 (500000 samples)\n",
      "Processing chunk 4000000-4500000 (500000 samples)\n",
      "Processing chunk 4500000-5000000 (500000 samples)\n",
      "Processing chunk 5000000-5500000 (500000 samples)\n",
      "Processing chunk 5500000-6000000 (500000 samples)\n",
      "Processing chunk 6000000-6500000 (500000 samples)\n",
      "Processing chunk 6500000-7000000 (500000 samples)\n",
      "Processing chunk 7000000-7500000 (500000 samples)\n",
      "Processing chunk 7500000-8000000 (500000 samples)\n",
      "Processing chunk 8000000-8500000 (500000 samples)\n",
      "Processing chunk 8500000-9000000 (500000 samples)\n",
      "Processing chunk 9000000-9500000 (500000 samples)\n",
      "Processing chunk 9500000-10000000 (500000 samples)\n",
      "Processing chunk 10000000-10500000 (500000 samples)\n",
      "Processing chunk 10500000-11000000 (500000 samples)\n",
      "Processing chunk 11000000-11500000 (500000 samples)\n",
      "Processing chunk 11500000-12000000 (500000 samples)\n",
      "Processing chunk 12000000-12500000 (500000 samples)\n",
      "Processing chunk 12500000-13000000 (500000 samples)\n",
      "Processing chunk 13000000-13500000 (500000 samples)\n",
      "Processing chunk 13500000-14000000 (500000 samples)\n",
      "Processing chunk 14000000-14500000 (500000 samples)\n",
      "Processing chunk 14500000-15000000 (500000 samples)\n",
      "Processing chunk 15000000-15500000 (500000 samples)\n",
      "Processing chunk 15500000-16000000 (500000 samples)\n",
      "Processing chunk 16000000-16500000 (500000 samples)\n",
      "Processing chunk 16500000-17000000 (500000 samples)\n",
      "Processing chunk 17000000-17500000 (500000 samples)\n",
      "Processing chunk 17500000-18000000 (500000 samples)\n",
      "Processing chunk 18000000-18500000 (500000 samples)\n",
      "Processing chunk 18500000-19000000 (500000 samples)\n",
      "Processing chunk 19000000-19500000 (500000 samples)\n",
      "Processing chunk 19500000-20000000 (500000 samples)\n",
      "Processing chunk 20000000-20500000 (500000 samples)\n",
      "Processing chunk 20500000-21000000 (500000 samples)\n",
      "Processing chunk 21000000-21500000 (500000 samples)\n",
      "Processing chunk 21500000-22000000 (500000 samples)\n",
      "Processing chunk 22000000-22500000 (500000 samples)\n",
      "Processing chunk 22500000-23000000 (500000 samples)\n",
      "Processing chunk 23000000-23500000 (500000 samples)\n",
      "Processing chunk 23500000-24000000 (500000 samples)\n",
      "Processing chunk 24000000-24500000 (500000 samples)\n",
      "Processing chunk 24500000-25000000 (500000 samples)\n",
      "Processing chunk 25000000-25500000 (500000 samples)\n",
      "Processing chunk 25500000-26000000 (500000 samples)\n",
      "Processing chunk 26000000-26500000 (500000 samples)\n",
      "Processing chunk 26500000-27000000 (500000 samples)\n",
      "Processing chunk 27000000-27500000 (500000 samples)\n",
      "Processing chunk 27500000-28000000 (500000 samples)\n",
      "Processing chunk 28000000-28500000 (500000 samples)\n",
      "Processing chunk 28500000-29000000 (500000 samples)\n",
      "Processing chunk 29000000-29500000 (500000 samples)\n",
      "Processing chunk 29500000-30000000 (500000 samples)\n",
      "Processing chunk 30000000-30500000 (500000 samples)\n",
      "Processing chunk 30500000-31000000 (500000 samples)\n",
      "Processing chunk 31000000-31500000 (500000 samples)\n",
      "Processing chunk 31500000-32000000 (500000 samples)\n",
      "Processing chunk 32000000-32500000 (500000 samples)\n",
      "Processing chunk 32500000-33000000 (500000 samples)\n",
      "Processing chunk 33000000-33500000 (500000 samples)\n",
      "Processing chunk 33500000-34000000 (500000 samples)\n",
      "Processing chunk 34000000-34500000 (500000 samples)\n",
      "Processing chunk 34500000-35000000 (500000 samples)\n",
      "Processing chunk 35000000-35500000 (500000 samples)\n",
      "Processing chunk 35500000-36000000 (500000 samples)\n",
      "Processing chunk 36000000-36500000 (500000 samples)\n",
      "Processing chunk 36500000-37000000 (500000 samples)\n",
      "Processing chunk 37000000-37500000 (500000 samples)\n",
      "Processing chunk 37500000-38000000 (500000 samples)\n",
      "Processing chunk 38000000-38500000 (500000 samples)\n",
      "Processing chunk 38500000-39000000 (500000 samples)\n",
      "Processing chunk 39000000-39500000 (500000 samples)\n",
      "Processing chunk 39500000-40000000 (500000 samples)\n",
      "Processing chunk 40000000-40500000 (500000 samples)\n",
      "Processing chunk 40500000-41000000 (500000 samples)\n",
      "Processing chunk 41000000-41500000 (500000 samples)\n",
      "Processing chunk 41500000-42000000 (500000 samples)\n",
      "Processing chunk 42000000-42500000 (500000 samples)\n",
      "Processing chunk 42500000-43000000 (500000 samples)\n",
      "Processing chunk 43000000-43500000 (500000 samples)\n",
      "Processing chunk 43500000-44000000 (500000 samples)\n",
      "Processing chunk 44000000-44500000 (500000 samples)\n",
      "Processing chunk 44500000-45000000 (500000 samples)\n",
      "Processing chunk 45000000-45129688 (129688 samples)\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub1-instance1_B005/array_01_V1.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub1-instance1_B005/array_02_V1.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub1-instance1_B005/array_03_V1.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub1-instance1_B005/array_04_V1.npy\n",
      "Completed processing Hub1-instance1_B005.ns6\n",
      "Processing /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub1-instance2_B005.ns6\n",
      "Processing chunk 0-500000 (500000 samples)\n",
      "Processing chunk 500000-1000000 (500000 samples)\n",
      "Processing chunk 1000000-1500000 (500000 samples)\n",
      "Processing chunk 1500000-2000000 (500000 samples)\n",
      "Processing chunk 2000000-2500000 (500000 samples)\n",
      "Processing chunk 2500000-3000000 (500000 samples)\n",
      "Processing chunk 3000000-3500000 (500000 samples)\n",
      "Processing chunk 3500000-4000000 (500000 samples)\n",
      "Processing chunk 4000000-4500000 (500000 samples)\n",
      "Processing chunk 4500000-5000000 (500000 samples)\n",
      "Processing chunk 5000000-5500000 (500000 samples)\n",
      "Processing chunk 5500000-6000000 (500000 samples)\n",
      "Processing chunk 6000000-6500000 (500000 samples)\n",
      "Processing chunk 6500000-7000000 (500000 samples)\n",
      "Processing chunk 7000000-7500000 (500000 samples)\n",
      "Processing chunk 7500000-8000000 (500000 samples)\n",
      "Processing chunk 8000000-8500000 (500000 samples)\n",
      "Processing chunk 8500000-9000000 (500000 samples)\n",
      "Processing chunk 9000000-9500000 (500000 samples)\n",
      "Processing chunk 9500000-10000000 (500000 samples)\n",
      "Processing chunk 10000000-10500000 (500000 samples)\n",
      "Processing chunk 10500000-11000000 (500000 samples)\n",
      "Processing chunk 11000000-11500000 (500000 samples)\n",
      "Processing chunk 11500000-12000000 (500000 samples)\n",
      "Processing chunk 12000000-12500000 (500000 samples)\n",
      "Processing chunk 12500000-13000000 (500000 samples)\n",
      "Processing chunk 13000000-13500000 (500000 samples)\n",
      "Processing chunk 13500000-14000000 (500000 samples)\n",
      "Processing chunk 14000000-14500000 (500000 samples)\n",
      "Processing chunk 14500000-15000000 (500000 samples)\n",
      "Processing chunk 15000000-15500000 (500000 samples)\n",
      "Processing chunk 15500000-16000000 (500000 samples)\n",
      "Processing chunk 16000000-16500000 (500000 samples)\n",
      "Processing chunk 16500000-17000000 (500000 samples)\n",
      "Processing chunk 17000000-17500000 (500000 samples)\n",
      "Processing chunk 17500000-18000000 (500000 samples)\n",
      "Processing chunk 18000000-18500000 (500000 samples)\n",
      "Processing chunk 18500000-19000000 (500000 samples)\n",
      "Processing chunk 19000000-19500000 (500000 samples)\n",
      "Processing chunk 19500000-20000000 (500000 samples)\n",
      "Processing chunk 20000000-20500000 (500000 samples)\n",
      "Processing chunk 20500000-21000000 (500000 samples)\n",
      "Processing chunk 21000000-21500000 (500000 samples)\n",
      "Processing chunk 21500000-22000000 (500000 samples)\n",
      "Processing chunk 22000000-22500000 (500000 samples)\n",
      "Processing chunk 22500000-23000000 (500000 samples)\n",
      "Processing chunk 23000000-23500000 (500000 samples)\n",
      "Processing chunk 23500000-24000000 (500000 samples)\n",
      "Processing chunk 24000000-24500000 (500000 samples)\n",
      "Processing chunk 24500000-25000000 (500000 samples)\n",
      "Processing chunk 25000000-25500000 (500000 samples)\n",
      "Processing chunk 25500000-26000000 (500000 samples)\n",
      "Processing chunk 26000000-26500000 (500000 samples)\n",
      "Processing chunk 26500000-27000000 (500000 samples)\n",
      "Processing chunk 27000000-27500000 (500000 samples)\n",
      "Processing chunk 27500000-28000000 (500000 samples)\n",
      "Processing chunk 28000000-28500000 (500000 samples)\n",
      "Processing chunk 28500000-29000000 (500000 samples)\n",
      "Processing chunk 29000000-29500000 (500000 samples)\n",
      "Processing chunk 29500000-30000000 (500000 samples)\n",
      "Processing chunk 30000000-30500000 (500000 samples)\n",
      "Processing chunk 30500000-31000000 (500000 samples)\n",
      "Processing chunk 31000000-31500000 (500000 samples)\n",
      "Processing chunk 31500000-32000000 (500000 samples)\n",
      "Processing chunk 32000000-32500000 (500000 samples)\n",
      "Processing chunk 32500000-33000000 (500000 samples)\n",
      "Processing chunk 33000000-33500000 (500000 samples)\n",
      "Processing chunk 33500000-34000000 (500000 samples)\n",
      "Processing chunk 34000000-34500000 (500000 samples)\n",
      "Processing chunk 34500000-35000000 (500000 samples)\n",
      "Processing chunk 35000000-35500000 (500000 samples)\n",
      "Processing chunk 35500000-36000000 (500000 samples)\n",
      "Processing chunk 36000000-36500000 (500000 samples)\n",
      "Processing chunk 36500000-37000000 (500000 samples)\n",
      "Processing chunk 37000000-37500000 (500000 samples)\n",
      "Processing chunk 37500000-38000000 (500000 samples)\n",
      "Processing chunk 38000000-38500000 (500000 samples)\n",
      "Processing chunk 38500000-39000000 (500000 samples)\n",
      "Processing chunk 39000000-39500000 (500000 samples)\n",
      "Processing chunk 39500000-40000000 (500000 samples)\n",
      "Processing chunk 40000000-40500000 (500000 samples)\n",
      "Processing chunk 40500000-41000000 (500000 samples)\n",
      "Processing chunk 41000000-41500000 (500000 samples)\n",
      "Processing chunk 41500000-42000000 (500000 samples)\n",
      "Processing chunk 42000000-42500000 (500000 samples)\n",
      "Processing chunk 42500000-43000000 (500000 samples)\n",
      "Processing chunk 43000000-43500000 (500000 samples)\n",
      "Processing chunk 43500000-44000000 (500000 samples)\n",
      "Processing chunk 44000000-44500000 (500000 samples)\n",
      "Processing chunk 44500000-45000000 (500000 samples)\n",
      "Processing chunk 45000000-45084688 (84688 samples)\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub1-instance2_B005/array_09_IT.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub1-instance2_B005/array_10_IT.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub1-instance2_B005/array_11_IT.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub1-instance2_B005/array_12_IT.npy\n",
      "Completed processing Hub1-instance2_B005.ns6\n",
      "Processing /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub2-instance1_B005.ns6\n",
      "Processing chunk 0-500000 (500000 samples)\n",
      "Processing chunk 500000-1000000 (500000 samples)\n",
      "Processing chunk 1000000-1500000 (500000 samples)\n",
      "Processing chunk 1500000-2000000 (500000 samples)\n",
      "Processing chunk 2000000-2500000 (500000 samples)\n",
      "Processing chunk 2500000-3000000 (500000 samples)\n",
      "Processing chunk 3000000-3500000 (500000 samples)\n",
      "Processing chunk 3500000-4000000 (500000 samples)\n",
      "Processing chunk 4000000-4500000 (500000 samples)\n",
      "Processing chunk 4500000-5000000 (500000 samples)\n",
      "Processing chunk 5000000-5500000 (500000 samples)\n",
      "Processing chunk 5500000-6000000 (500000 samples)\n",
      "Processing chunk 6000000-6500000 (500000 samples)\n",
      "Processing chunk 6500000-7000000 (500000 samples)\n",
      "Processing chunk 7000000-7500000 (500000 samples)\n",
      "Processing chunk 7500000-8000000 (500000 samples)\n",
      "Processing chunk 8000000-8500000 (500000 samples)\n",
      "Processing chunk 8500000-9000000 (500000 samples)\n",
      "Processing chunk 9000000-9500000 (500000 samples)\n",
      "Processing chunk 9500000-10000000 (500000 samples)\n",
      "Processing chunk 10000000-10500000 (500000 samples)\n",
      "Processing chunk 10500000-11000000 (500000 samples)\n",
      "Processing chunk 11000000-11500000 (500000 samples)\n",
      "Processing chunk 11500000-12000000 (500000 samples)\n",
      "Processing chunk 12000000-12500000 (500000 samples)\n",
      "Processing chunk 12500000-13000000 (500000 samples)\n",
      "Processing chunk 13000000-13500000 (500000 samples)\n",
      "Processing chunk 13500000-14000000 (500000 samples)\n",
      "Processing chunk 14000000-14500000 (500000 samples)\n",
      "Processing chunk 14500000-15000000 (500000 samples)\n",
      "Processing chunk 15000000-15500000 (500000 samples)\n",
      "Processing chunk 15500000-16000000 (500000 samples)\n",
      "Processing chunk 16000000-16500000 (500000 samples)\n",
      "Processing chunk 16500000-17000000 (500000 samples)\n",
      "Processing chunk 17000000-17500000 (500000 samples)\n",
      "Processing chunk 17500000-18000000 (500000 samples)\n",
      "Processing chunk 18000000-18500000 (500000 samples)\n",
      "Processing chunk 18500000-19000000 (500000 samples)\n",
      "Processing chunk 19000000-19500000 (500000 samples)\n",
      "Processing chunk 19500000-20000000 (500000 samples)\n",
      "Processing chunk 20000000-20500000 (500000 samples)\n",
      "Processing chunk 20500000-21000000 (500000 samples)\n",
      "Processing chunk 21000000-21500000 (500000 samples)\n",
      "Processing chunk 21500000-22000000 (500000 samples)\n",
      "Processing chunk 22000000-22500000 (500000 samples)\n",
      "Processing chunk 22500000-23000000 (500000 samples)\n",
      "Processing chunk 23000000-23500000 (500000 samples)\n",
      "Processing chunk 23500000-24000000 (500000 samples)\n",
      "Processing chunk 24000000-24500000 (500000 samples)\n",
      "Processing chunk 24500000-25000000 (500000 samples)\n",
      "Processing chunk 25000000-25500000 (500000 samples)\n",
      "Processing chunk 25500000-26000000 (500000 samples)\n",
      "Processing chunk 26000000-26500000 (500000 samples)\n",
      "Processing chunk 26500000-27000000 (500000 samples)\n",
      "Processing chunk 27000000-27500000 (500000 samples)\n",
      "Processing chunk 27500000-28000000 (500000 samples)\n",
      "Processing chunk 28000000-28500000 (500000 samples)\n",
      "Processing chunk 28500000-29000000 (500000 samples)\n",
      "Processing chunk 29000000-29500000 (500000 samples)\n",
      "Processing chunk 29500000-30000000 (500000 samples)\n",
      "Processing chunk 30000000-30500000 (500000 samples)\n",
      "Processing chunk 30500000-31000000 (500000 samples)\n",
      "Processing chunk 31000000-31500000 (500000 samples)\n",
      "Processing chunk 31500000-32000000 (500000 samples)\n",
      "Processing chunk 32000000-32500000 (500000 samples)\n",
      "Processing chunk 32500000-33000000 (500000 samples)\n",
      "Processing chunk 33000000-33500000 (500000 samples)\n",
      "Processing chunk 33500000-34000000 (500000 samples)\n",
      "Processing chunk 34000000-34500000 (500000 samples)\n",
      "Processing chunk 34500000-35000000 (500000 samples)\n",
      "Processing chunk 35000000-35500000 (500000 samples)\n",
      "Processing chunk 35500000-36000000 (500000 samples)\n",
      "Processing chunk 36000000-36500000 (500000 samples)\n",
      "Processing chunk 36500000-37000000 (500000 samples)\n",
      "Processing chunk 37000000-37500000 (500000 samples)\n",
      "Processing chunk 37500000-38000000 (500000 samples)\n",
      "Processing chunk 38000000-38500000 (500000 samples)\n",
      "Processing chunk 38500000-39000000 (500000 samples)\n",
      "Processing chunk 39000000-39500000 (500000 samples)\n",
      "Processing chunk 39500000-40000000 (500000 samples)\n",
      "Processing chunk 40000000-40500000 (500000 samples)\n",
      "Processing chunk 40500000-41000000 (500000 samples)\n",
      "Processing chunk 41000000-41500000 (500000 samples)\n",
      "Processing chunk 41500000-42000000 (500000 samples)\n",
      "Processing chunk 42000000-42500000 (500000 samples)\n",
      "Processing chunk 42500000-43000000 (500000 samples)\n",
      "Processing chunk 43000000-43500000 (500000 samples)\n",
      "Processing chunk 43500000-44000000 (500000 samples)\n",
      "Processing chunk 44000000-44500000 (500000 samples)\n",
      "Processing chunk 44500000-45000000 (500000 samples)\n",
      "Processing chunk 45000000-45129630 (129630 samples)\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub2-instance1_B005/array_05_V1.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub2-instance1_B005/array_06_V1.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub2-instance1_B005/array_07_V1.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub2-instance1_B005/array_08_V1.npy\n",
      "Completed processing Hub2-instance1_B005.ns6\n",
      "Processing /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub2-instance2_B005.ns6\n",
      "Processing chunk 0-500000 (500000 samples)\n",
      "Processing chunk 500000-1000000 (500000 samples)\n",
      "Processing chunk 1000000-1500000 (500000 samples)\n",
      "Processing chunk 1500000-2000000 (500000 samples)\n",
      "Processing chunk 2000000-2500000 (500000 samples)\n",
      "Processing chunk 2500000-3000000 (500000 samples)\n",
      "Processing chunk 3000000-3500000 (500000 samples)\n",
      "Processing chunk 3500000-4000000 (500000 samples)\n",
      "Processing chunk 4000000-4500000 (500000 samples)\n",
      "Processing chunk 4500000-5000000 (500000 samples)\n",
      "Processing chunk 5000000-5500000 (500000 samples)\n",
      "Processing chunk 5500000-6000000 (500000 samples)\n",
      "Processing chunk 6000000-6500000 (500000 samples)\n",
      "Processing chunk 6500000-7000000 (500000 samples)\n",
      "Processing chunk 7000000-7500000 (500000 samples)\n",
      "Processing chunk 7500000-8000000 (500000 samples)\n",
      "Processing chunk 8000000-8500000 (500000 samples)\n",
      "Processing chunk 8500000-9000000 (500000 samples)\n",
      "Processing chunk 9000000-9500000 (500000 samples)\n",
      "Processing chunk 9500000-10000000 (500000 samples)\n",
      "Processing chunk 10000000-10500000 (500000 samples)\n",
      "Processing chunk 10500000-11000000 (500000 samples)\n",
      "Processing chunk 11000000-11500000 (500000 samples)\n",
      "Processing chunk 11500000-12000000 (500000 samples)\n",
      "Processing chunk 12000000-12500000 (500000 samples)\n",
      "Processing chunk 12500000-13000000 (500000 samples)\n",
      "Processing chunk 13000000-13500000 (500000 samples)\n",
      "Processing chunk 13500000-14000000 (500000 samples)\n",
      "Processing chunk 14000000-14500000 (500000 samples)\n",
      "Processing chunk 14500000-15000000 (500000 samples)\n",
      "Processing chunk 15000000-15500000 (500000 samples)\n",
      "Processing chunk 15500000-16000000 (500000 samples)\n",
      "Processing chunk 16000000-16500000 (500000 samples)\n",
      "Processing chunk 16500000-17000000 (500000 samples)\n",
      "Processing chunk 17000000-17500000 (500000 samples)\n",
      "Processing chunk 17500000-18000000 (500000 samples)\n",
      "Processing chunk 18000000-18500000 (500000 samples)\n",
      "Processing chunk 18500000-19000000 (500000 samples)\n",
      "Processing chunk 19000000-19500000 (500000 samples)\n",
      "Processing chunk 19500000-20000000 (500000 samples)\n",
      "Processing chunk 20000000-20500000 (500000 samples)\n",
      "Processing chunk 20500000-21000000 (500000 samples)\n",
      "Processing chunk 21000000-21500000 (500000 samples)\n",
      "Processing chunk 21500000-22000000 (500000 samples)\n",
      "Processing chunk 22000000-22500000 (500000 samples)\n",
      "Processing chunk 22500000-23000000 (500000 samples)\n",
      "Processing chunk 23000000-23500000 (500000 samples)\n",
      "Processing chunk 23500000-24000000 (500000 samples)\n",
      "Processing chunk 24000000-24500000 (500000 samples)\n",
      "Processing chunk 24500000-25000000 (500000 samples)\n",
      "Processing chunk 25000000-25500000 (500000 samples)\n",
      "Processing chunk 25500000-26000000 (500000 samples)\n",
      "Processing chunk 26000000-26500000 (500000 samples)\n",
      "Processing chunk 26500000-27000000 (500000 samples)\n",
      "Processing chunk 27000000-27500000 (500000 samples)\n",
      "Processing chunk 27500000-28000000 (500000 samples)\n",
      "Processing chunk 28000000-28500000 (500000 samples)\n",
      "Processing chunk 28500000-29000000 (500000 samples)\n",
      "Processing chunk 29000000-29500000 (500000 samples)\n",
      "Processing chunk 29500000-30000000 (500000 samples)\n",
      "Processing chunk 30000000-30500000 (500000 samples)\n",
      "Processing chunk 30500000-31000000 (500000 samples)\n",
      "Processing chunk 31000000-31500000 (500000 samples)\n",
      "Processing chunk 31500000-32000000 (500000 samples)\n",
      "Processing chunk 32000000-32500000 (500000 samples)\n",
      "Processing chunk 32500000-33000000 (500000 samples)\n",
      "Processing chunk 33000000-33500000 (500000 samples)\n",
      "Processing chunk 33500000-34000000 (500000 samples)\n",
      "Processing chunk 34000000-34500000 (500000 samples)\n",
      "Processing chunk 34500000-35000000 (500000 samples)\n",
      "Processing chunk 35000000-35500000 (500000 samples)\n",
      "Processing chunk 35500000-36000000 (500000 samples)\n",
      "Processing chunk 36000000-36500000 (500000 samples)\n",
      "Processing chunk 36500000-37000000 (500000 samples)\n",
      "Processing chunk 37000000-37500000 (500000 samples)\n",
      "Processing chunk 37500000-38000000 (500000 samples)\n",
      "Processing chunk 38000000-38500000 (500000 samples)\n",
      "Processing chunk 38500000-39000000 (500000 samples)\n",
      "Processing chunk 39000000-39500000 (500000 samples)\n",
      "Processing chunk 39500000-40000000 (500000 samples)\n",
      "Processing chunk 40000000-40500000 (500000 samples)\n",
      "Processing chunk 40500000-41000000 (500000 samples)\n",
      "Processing chunk 41000000-41500000 (500000 samples)\n",
      "Processing chunk 41500000-42000000 (500000 samples)\n",
      "Processing chunk 42000000-42500000 (500000 samples)\n",
      "Processing chunk 42500000-43000000 (500000 samples)\n",
      "Processing chunk 43000000-43500000 (500000 samples)\n",
      "Processing chunk 43500000-44000000 (500000 samples)\n",
      "Processing chunk 44000000-44500000 (500000 samples)\n",
      "Processing chunk 44500000-45000000 (500000 samples)\n",
      "Processing chunk 45000000-45084750 (84750 samples)\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub2-instance2_B005/array_13_IT.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub2-instance2_B005/array_14_V4.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub2-instance2_B005/array_15_V4.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_5/processed_data/Hub2-instance2_B005/array_16_V4.npy\n",
      "Completed processing Hub2-instance2_B005.ns6\n",
      "All files processed successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "date = 20240115\n",
    "block = 5\n",
    "monkey = 'monkeyF'\n",
    "datadir_gen = f'/media/ubuntu/sda/Monkey/sorted_result/{date}/Block_{block}/'\n",
    "mapping_file = f'/media/ubuntu/sda/Monkey/TVSD/monkeyF/_logs/1024chns_mapping_20220105.mat'\n",
    "\n",
    "os.makedirs(f'/media/ubuntu/sda/Monkey/sorted_result/{date}/Block_{block}/', exist_ok=True)\n",
    "os.makedirs(f'/media/ubuntu/sda/Monkey/sorted_result/{date}/Block_{block}/processed_data', exist_ok=True)\n",
    "\n",
    "file_list = [\n",
    "    f'Hub1-instance1_B00{block}.ns6',\n",
    "    f'Hub1-instance2_B00{block}.ns6',\n",
    "    f'Hub2-instance1_B00{block}.ns6',\n",
    "    f'Hub2-instance2_B00{block}.ns6'\n",
    "]\n",
    "\n",
    "# 加载映射文件\n",
    "mapping_data = sio.loadmat(mapping_file)\n",
    "mapping = mapping_data['mapping'].flatten() - 1  # 转换为0-based索引\n",
    "\n",
    "# 定义脑区映射\n",
    "if monkey == 'monkeyN':\n",
    "    rois = np.ones(1024)  # V1\n",
    "    rois[512:768] = 2  # V4 (513-768)\n",
    "    rois[768:1024] = 3  # IT (769-1024)\n",
    "else:\n",
    "    rois = np.ones(1024)  # V1\n",
    "    rois[512:832] = 3  # IT (513-832)\n",
    "    rois[832:1024] = 2  # V4 (833-1024)\n",
    "\n",
    "output_dir = Path(datadir_gen) / 'processed_data'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 设置块大小（根据可用内存调整）\n",
    "chunk_size = 500000  # 每次处理的样本数\n",
    "\n",
    "# 处理每个文件\n",
    "for file_idx, file_name in enumerate(file_list):\n",
    "    file_path = f'/media/ubuntu/sda/Monkey/TVSD/monkeyF/{date}/Block_{block}/{file_name}'\n",
    "    print(f'Processing {file_path}')\n",
    "    \n",
    "    # 读取文件\n",
    "    recording = se.read_blackrock(file_path)\n",
    "    \n",
    "    # 处理多段数据\n",
    "    if recording.get_num_segments() > 1:\n",
    "        recording_list = []\n",
    "        for i in range(recording.get_num_segments()):\n",
    "            recording_list.append(recording.select_segments(i))\n",
    "        recording = si.concatenate_recordings(recording_list)\n",
    "    \n",
    "    # 获取采样率和样本数\n",
    "    sample_rate = recording.get_sampling_frequency()\n",
    "    n_samples = recording.get_num_samples()\n",
    "    \n",
    "    # 获取通道ID列表（字符串类型）\n",
    "    channel_ids = np.array([str(i) for i in range(1, 257)])\n",
    "    \n",
    "    # 确定当前文件在映射中的位置\n",
    "    if 'Hub1-instance1' in file_name:\n",
    "        file_start_idx = 0\n",
    "    elif 'Hub2-instance1' in file_name:\n",
    "        file_start_idx = 256\n",
    "    elif 'Hub1-instance2' in file_name:\n",
    "        file_start_idx = 512\n",
    "    elif 'Hub2-instance2' in file_name:\n",
    "        file_start_idx = 768\n",
    "    else:\n",
    "        raise ValueError(f'Unknown file type: {file_name}')\n",
    "    \n",
    "    # 创建文件输出目录\n",
    "    file_output_dir = output_dir / file_name.replace('.ns6', '')\n",
    "    file_output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # 为每个阵列创建内存映射文件（每个文件有4个阵列）\n",
    "    array_files = []\n",
    "    array_info = []\n",
    "    \n",
    "    # 每个文件有256个通道，分成4组，每组64个通道\n",
    "    for array_idx in range(4):\n",
    "        # 确定阵列的主要脑区\n",
    "        start_chan = file_start_idx + array_idx * 64\n",
    "        end_chan = start_chan + 64\n",
    "        \n",
    "        array_roi_counts = np.bincount(rois[start_chan:end_chan].astype(int))\n",
    "        primary_roi = np.argmax(array_roi_counts)\n",
    "        \n",
    "        if primary_roi == 1:\n",
    "            roi_name = 'V1'\n",
    "        elif primary_roi == 2:\n",
    "            roi_name = 'V4'\n",
    "        else:\n",
    "            roi_name = 'IT'\n",
    "        \n",
    "        output_file = file_output_dir / f'array_{file_start_idx//64 + array_idx + 1:02d}_{roi_name}.npy'\n",
    "        \n",
    "        # 创建内存映射文件\n",
    "        mmap_array = np.lib.format.open_memmap(\n",
    "            output_file, mode='w+', dtype=np.float32, shape=(64, n_samples)\n",
    "        )\n",
    "        array_files.append(mmap_array)\n",
    "        array_info.append({'roi_name': roi_name, 'output_file': output_file})\n",
    "    \n",
    "    # 分块处理数据\n",
    "    for start in range(0, n_samples, chunk_size):\n",
    "        end = min(start + chunk_size, n_samples)\n",
    "        chunk_size_actual = end - start\n",
    "        \n",
    "        print(f'Processing chunk {start}-{end} ({chunk_size_actual} samples)')\n",
    "        \n",
    "        # 获取当前块的数据\n",
    "        chunk_data = recording.get_traces(start_frame=start, end_frame=end)\n",
    "        \n",
    "        # 处理当前文件的每个通道\n",
    "        for i in range(256):\n",
    "            # 使用正确的通道ID获取数据\n",
    "            channel_id = str(i + 1)  # 转换为字符串，因为Recording使用字符串ID\n",
    "            channel_idx_in_recording = np.where(channel_ids == channel_id)[0][0]\n",
    "            \n",
    "            # 确定通道属于哪个阵列（在当前文件的4个阵列中）\n",
    "            array_idx = i // 64\n",
    "            channel_in_array = i % 64\n",
    "            \n",
    "            # 将数据写入对应阵列的内存映射文件\n",
    "            array_files[array_idx][channel_in_array, start:end] = chunk_data[:, channel_idx_in_recording]\n",
    "    \n",
    "    # 保存并关闭内存映射文件\n",
    "    for array_idx, mmap_array in enumerate(array_files):\n",
    "        mmap_array.flush()\n",
    "        del mmap_array  # 释放内存映射\n",
    "        print(f'Saved {array_info[array_idx][\"output_file\"]}')\n",
    "    \n",
    "    print(f'Completed processing {file_name}')\n",
    "\n",
    "print('All files processed successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "442bf6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,883,320 samples \n",
      "                         1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,883,320 samples \n",
      "                          1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmp1u5ysv7q/0DMUSPKF\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:25<00:00, 14.37it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,883,320 samples \n",
      "                       1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [01:21<00:00,  7.59it/s]\n",
      "100%|██████████| 8/8 [05:52<00:00, 44.01s/it]\n",
      "100%|██████████| 615/615 [00:19<00:00, 32.35it/s]\n",
      "100%|██████████| 8/8 [00:44<00:00,  5.57s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 28928.51it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:36<00:00, 33.78it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 50.52it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:04<00:00, 294.99it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 813.66it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:46<00:00, 11.58it/s]\n",
      "Fitting PCA: 100%|██████████| 57/57 [00:00<00:00, 80.12it/s]\n",
      "Projecting waveforms: 100%|██████████| 57/57 [00:00<00:00, 4376.42it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [01:08<00:00, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_04_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,883,320 samples \n",
      "                         1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,883,320 samples \n",
      "                          1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpkrrmyqit/0D9UERB4\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:56<00:00, 21.74it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,883,320 samples \n",
      "                       1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [00:59<00:00, 10.34it/s]\n",
      "100%|██████████| 8/8 [07:53<00:00, 59.24s/it]\n",
      "100%|██████████| 615/615 [00:37<00:00, 16.32it/s]\n",
      "100%|██████████| 8/8 [01:53<00:00, 14.13s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 30066.70it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:33<00:00, 36.28it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 53.63it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:06<00:00, 204.21it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1068.64it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:47<00:00, 11.47it/s]\n",
      "Fitting PCA: 100%|██████████| 62/62 [00:03<00:00, 16.70it/s]\n",
      "Projecting waveforms: 100%|██████████| 62/62 [00:00<00:00, 4045.28it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [01:35<00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_02_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,883,320 samples \n",
      "                         1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,883,320 samples \n",
      "                          1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpoe11c8v5/8D3WKGZT\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:51<00:00, 23.78it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,883,320 samples \n",
      "                       1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [00:50<00:00, 12.19it/s]\n",
      "100%|██████████| 8/8 [06:20<00:00, 47.60s/it]\n",
      "100%|██████████| 615/615 [00:29<00:00, 20.52it/s]\n",
      "100%|██████████| 8/8 [01:34<00:00, 11.79s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 29282.52it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:33<00:00, 37.18it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 52.74it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:05<00:00, 224.29it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1045.47it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:48<00:00, 11.33it/s]\n",
      "Fitting PCA: 100%|██████████| 66/66 [00:00<00:00, 248.20it/s]\n",
      "Projecting waveforms: 100%|██████████| 66/66 [00:00<00:00, 3811.01it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [01:29<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_01_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,883,320 samples \n",
      "                         1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,883,320 samples \n",
      "                          1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpgr3e9ztx/V5THLIKF\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:52<00:00, 23.44it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,883,320 samples \n",
      "                       1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [00:52<00:00, 11.80it/s]\n",
      "100%|██████████| 8/8 [03:59<00:00, 29.98s/it]\n",
      "100%|██████████| 615/615 [00:19<00:00, 30.75it/s]\n",
      "100%|██████████| 8/8 [01:05<00:00,  8.13s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 33526.52it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:31<00:00, 38.88it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 52.84it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:04<00:00, 282.99it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1054.12it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:48<00:00, 11.29it/s]\n",
      "Fitting PCA: 100%|██████████| 52/52 [00:00<00:00, 260.57it/s]\n",
      "Projecting waveforms: 100%|██████████| 52/52 [00:00<00:00, 4398.76it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [01:04<00:00, 19.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_03_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,880,855 samples \n",
      "                         1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,880,855 samples \n",
      "                          1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpo67a5hxm/O9J5C7MJ\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:51<00:00, 23.76it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,880,855 samples \n",
      "                       1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [00:52<00:00, 11.66it/s]\n",
      "100%|██████████| 8/8 [05:09<00:00, 38.66s/it]\n",
      "100%|██████████| 615/615 [00:22<00:00, 27.58it/s]\n",
      "100%|██████████| 8/8 [01:17<00:00,  9.63s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 35831.57it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:32<00:00, 38.36it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 53.52it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:04<00:00, 296.35it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 843.68it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:48<00:00, 11.37it/s]\n",
      "Fitting PCA: 100%|██████████| 50/50 [00:06<00:00,  7.44it/s]\n",
      "Projecting waveforms: 100%|██████████| 50/50 [00:00<00:00, 3792.73it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [01:02<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_09_IT.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,880,855 samples \n",
      "                         1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,880,855 samples \n",
      "                          1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpvtvfvca1/CBZ3FVUF\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:53<00:00, 22.82it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,880,855 samples \n",
      "                       1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [01:10<00:00,  8.66it/s]\n",
      "100%|██████████| 8/8 [05:04<00:00, 38.11s/it]\n",
      "100%|██████████| 615/615 [00:18<00:00, 33.73it/s]\n",
      "100%|██████████| 8/8 [00:49<00:00,  6.22s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 34001.37it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:33<00:00, 36.23it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 54.62it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:03<00:00, 318.35it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1086.90it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:48<00:00, 11.36it/s]\n",
      "Fitting PCA: 100%|██████████| 52/52 [00:04<00:00, 10.92it/s]\n",
      "Projecting waveforms: 100%|██████████| 52/52 [00:00<00:00, 3477.36it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [00:58<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_11_IT.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,880,855 samples \n",
      "                         1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,880,855 samples \n",
      "                          1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpsf5cat4b/CFFHUVE0\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:52<00:00, 23.34it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,880,855 samples \n",
      "                       1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [00:52<00:00, 11.63it/s]\n",
      "100%|██████████| 8/8 [04:27<00:00, 33.47s/it]\n",
      "100%|██████████| 615/615 [00:15<00:00, 39.83it/s]\n",
      "100%|██████████| 8/8 [00:41<00:00,  5.25s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 36013.42it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:30<00:00, 40.63it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 55.43it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:03<00:00, 400.39it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1078.02it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:49<00:00, 11.26it/s]\n",
      "Fitting PCA: 100%|██████████| 46/46 [00:11<00:00,  4.09it/s]\n",
      "Projecting waveforms: 100%|██████████| 46/46 [00:00<00:00, 2611.12it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [00:45<00:00, 27.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_12_IT.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,880,855 samples \n",
      "                         1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,880,855 samples \n",
      "                          1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpv7abvque/3QL57OK3\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:55<00:00, 22.15it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,880,855 samples \n",
      "                       1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [01:10<00:00,  8.71it/s]\n",
      " 12%|█▎        | 1/8 [00:14<01:40, 14.37s/it]/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/scipy/sparse/_index.py:151: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 8/8 [04:22<00:00, 32.87s/it]\n",
      "100%|██████████| 615/615 [00:15<00:00, 40.28it/s]\n",
      "100%|██████████| 8/8 [00:33<00:00,  4.19s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 36507.83it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:28<00:00, 43.29it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 53.71it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:02<00:00, 425.48it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1032.52it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:45<00:00, 11.62it/s]\n",
      "Fitting PCA: 100%|██████████| 46/46 [00:00<00:00, 243.70it/s]\n",
      "Projecting waveforms: 100%|██████████| 46/46 [00:00<00:00, 4312.43it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [00:39<00:00, 31.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_10_IT.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,880,945 samples \n",
      "                         1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,880,945 samples \n",
      "                          1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmp1lgn7w76/2MOX90WY\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:53<00:00, 22.92it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,880,945 samples \n",
      "                       1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [00:54<00:00, 11.29it/s]\n",
      "100%|██████████| 8/8 [04:00<00:00, 30.12s/it]\n",
      "100%|██████████| 615/615 [00:15<00:00, 39.24it/s]\n",
      "100%|██████████| 8/8 [00:40<00:00,  5.01s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 38042.87it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:50<00:00, 24.58it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 50.89it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:03<00:00, 398.86it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1090.86it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [02:20<00:00,  8.77it/s]\n",
      "Fitting PCA: 100%|██████████| 45/45 [00:00<00:00, 264.20it/s]\n",
      "Projecting waveforms: 100%|██████████| 45/45 [00:00<00:00, 4374.33it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [00:44<00:00, 27.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_13_IT.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,880,945 samples \n",
      "                         1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,880,945 samples \n",
      "                          1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpe0_59x2f/6P8KTEHH\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:53<00:00, 23.12it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,880,945 samples \n",
      "                       1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [00:54<00:00, 11.18it/s]\n",
      "100%|██████████| 8/8 [06:21<00:00, 47.71s/it]\n",
      "100%|██████████| 615/615 [00:38<00:00, 15.94it/s]\n",
      "100%|██████████| 8/8 [02:45<00:00, 20.70s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 22650.61it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:40<00:00, 30.39it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 53.16it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:07<00:00, 166.50it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 879.36it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:56<00:00, 10.52it/s]\n",
      "Fitting PCA: 100%|██████████| 85/85 [00:02<00:00, 38.07it/s]\n",
      "Projecting waveforms: 100%|██████████| 85/85 [00:00<00:00, 2722.87it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [01:51<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_16_V4.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,880,945 samples \n",
      "                         1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,880,945 samples \n",
      "                          1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpmwiqu8gp/3VPS5KL3\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:52<00:00, 23.29it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,880,945 samples \n",
      "                       1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [00:50<00:00, 12.10it/s]\n",
      "100%|██████████| 8/8 [05:53<00:00, 44.25s/it]\n",
      "100%|██████████| 615/615 [00:17<00:00, 35.78it/s]\n",
      "100%|██████████| 8/8 [00:51<00:00,  6.43s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 33159.11it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:36<00:00, 33.98it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 52.30it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:03<00:00, 337.80it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1060.57it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:1565: RuntimeWarning: invalid value encountered in sqrt\n",
      "  std_noise = np.sqrt(std_noise**2 - total_variance)\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [02:00<00:00, 10.24it/s]\n",
      "Fitting PCA: 100%|██████████| 53/53 [00:00<00:00, 281.13it/s]\n",
      "Projecting waveforms: 100%|██████████| 53/53 [00:00<00:00, 3963.66it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [00:52<00:00, 23.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_14_V4.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,880,945 samples \n",
      "                         1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,880,945 samples \n",
      "                          1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpofa_ngvh/5Z7F0SHY\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:52<00:00, 23.60it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,880,945 samples \n",
      "                       1,229.36s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [00:52<00:00, 11.71it/s]\n",
      "100%|██████████| 8/8 [05:09<00:00, 38.69s/it]\n",
      "100%|██████████| 615/615 [00:24<00:00, 25.40it/s]\n",
      "100%|██████████| 8/8 [01:25<00:00, 10.72s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 27714.18it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:56<00:00, 21.96it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 53.72it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:05<00:00, 235.63it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 881.16it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:56<00:00, 10.57it/s]\n",
      "Fitting PCA: 100%|██████████| 67/67 [00:00<00:00, 115.71it/s]\n",
      "Projecting waveforms: 100%|██████████| 67/67 [00:00<00:00, 3853.63it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [01:19<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_15_V4.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,883,257 samples \n",
      "                         1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,883,257 samples \n",
      "                          1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmp933adcge/BX1FLMV6\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:52<00:00, 23.47it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,883,257 samples \n",
      "                       1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [01:10<00:00,  8.76it/s]\n",
      "100%|██████████| 8/8 [08:48<00:00, 66.09s/it]\n",
      "100%|██████████| 615/615 [00:37<00:00, 16.32it/s]\n",
      "100%|██████████| 8/8 [03:01<00:00, 22.63s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 23044.19it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [01:24<00:00, 14.56it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 53.67it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:06<00:00, 179.16it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 846.17it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [02:37<00:00,  7.79it/s]\n",
      "Fitting PCA: 100%|██████████| 71/71 [00:00<00:00, 95.19it/s] \n",
      "Projecting waveforms: 100%|██████████| 71/71 [00:00<00:00, 2814.38it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [01:46<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_07_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,883,257 samples \n",
      "                         1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,883,257 samples \n",
      "                          1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmp9hvpej91/PHPS1SS5\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:53<00:00, 23.20it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,883,257 samples \n",
      "                       1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [01:06<00:00,  9.25it/s]\n",
      "100%|██████████| 8/8 [04:15<00:00, 31.96s/it]\n",
      "100%|██████████| 615/615 [00:20<00:00, 29.60it/s]\n",
      "100%|██████████| 8/8 [00:45<00:00,  5.72s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 25694.76it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:29<00:00, 41.94it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 54.91it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:03<00:00, 321.88it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1041.05it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:53<00:00, 10.86it/s]\n",
      "Fitting PCA: 100%|██████████| 47/47 [00:01<00:00, 23.65it/s]\n",
      "Projecting waveforms: 100%|██████████| 47/47 [00:00<00:00, 3639.81it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [00:52<00:00, 23.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_05_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,883,257 samples \n",
      "                         1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,883,257 samples \n",
      "                          1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpwuq1f0hx/Y3QIPLN6\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:53<00:00, 23.07it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,883,257 samples \n",
      "                       1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [01:00<00:00, 10.15it/s]\n",
      "100%|██████████| 8/8 [05:03<00:00, 37.90s/it]\n",
      "100%|██████████| 615/615 [00:21<00:00, 29.23it/s]\n",
      "100%|██████████| 8/8 [00:51<00:00,  6.46s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 32773.83it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:48<00:00, 25.45it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 52.45it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:04<00:00, 296.52it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 935.00it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:48<00:00, 11.38it/s]\n",
      "Fitting PCA: 100%|██████████| 48/48 [00:00<00:00, 96.49it/s] \n",
      "Projecting waveforms: 100%|██████████| 48/48 [00:00<00:00, 3741.78it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [00:58<00:00, 20.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_08_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 36,883,257 samples \n",
      "                         1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 36,883,257 samples \n",
      "                          1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpz2ym9dn1/6RBJ2PAE\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [00:52<00:00, 23.49it/s]\n",
      "/tmp/ipykernel_302613/1029500336.py:27: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 36,883,257 samples \n",
      "                       1,229.44s (20.49 minutes) - float32 dtype - 8.79 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 615/615 [01:10<00:00,  8.77it/s]\n",
      "100%|██████████| 8/8 [06:20<00:00, 47.59s/it]\n",
      "100%|██████████| 615/615 [00:37<00:00, 16.28it/s]\n",
      "100%|██████████| 8/8 [01:44<00:00, 13.10s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 1230/1230 [00:00<00:00, 29182.47it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 1230/1230 [00:26<00:00, 46.23it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 51.98it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 1230/1230 [00:05<00:00, 207.77it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 999.43it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 1230/1230 [01:47<00:00, 11.48it/s]\n",
      "Fitting PCA: 100%|██████████| 64/64 [00:00<00:00, 149.91it/s]\n",
      "Projecting waveforms: 100%|██████████| 64/64 [00:00<00:00, 3864.55it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 1230/1230 [01:28<00:00, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240115/Block_1/sort/array_06_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "date = 20240115\n",
    "block = 1\n",
    "for file in os.listdir(f\"/media/ubuntu/sda/Monkey/sorted_result/{date}/Block_{block}/processed_data\"):\n",
    "    for array in os.listdir(f\"/media/ubuntu/sda/Monkey/sorted_result/{date}/Block_{block}/processed_data/{file}\"):\n",
    "        recording = np.load(f\"/media/ubuntu/sda/Monkey/sorted_result/{date}/Block_{block}/processed_data/{file}/{array}\")\n",
    "        recording = se.NumpyRecording(recording.T, sampling_frequency=30000)\n",
    "        from probeinterface import write_probeinterface, read_probeinterface\n",
    "\n",
    "        probe_30channel = read_probeinterface('/media/ubuntu/sda/Monkey/scripts/probe.json')\n",
    "        probe_30channel.set_global_device_channel_indices([i for i in range(64)])\n",
    "        recording_recorded = recording.set_probegroup(probe_30channel)\n",
    "\n",
    "        recording_cmr = recording_recorded\n",
    "        recording_f = spre.bandpass_filter(recording_recorded, freq_min=300, freq_max=3000)\n",
    "        print(recording_f)\n",
    "        recording_cmr = spre.common_reference(recording_f, reference=\"global\", operator=\"median\")\n",
    "        print(recording_cmr)\n",
    "\n",
    "        # this computes and saves the recording after applying the preprocessing chain\n",
    "        recording_preprocessed = recording_cmr.save(format=\"binary\")\n",
    "        print(recording_preprocessed)\n",
    "        os.makedirs(f\"/media/ubuntu/sda/Monkey/sorted_result/{date}/Block_{block}/sort\", exist_ok=True)\n",
    "\n",
    "        os.makedirs(f\"/media/ubuntu/sda/Monkey/sorted_result/{date}/Block_{block}/sort/{array}\", exist_ok=True)\n",
    "        output_folder = f\"/media/ubuntu/sda/Monkey/sorted_result/{date}/Block_{block}/sort/{array}\"\n",
    "        sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n",
    "        analyzer_kilosort4 = si.create_sorting_analyzer(sorting=sorting_kilosort4, recording=recording_preprocessed, format='binary_folder', folder=output_folder + '/analyzer_kilosort4_binary')\n",
    "\n",
    "        extensions_to_compute = [\n",
    "                    \"random_spikes\",\n",
    "                    \"waveforms\",\n",
    "                    \"noise_levels\",\n",
    "                    \"templates\",\n",
    "                    \"spike_amplitudes\",\n",
    "                    \"unit_locations\",\n",
    "                    \"spike_locations\",\n",
    "                    \"correlograms\",\n",
    "                    \"template_similarity\"\n",
    "                ]\n",
    "\n",
    "        extension_params = {\n",
    "            \"unit_locations\": {\"method\": \"center_of_mass\"},\n",
    "            \"spike_locations\": {\"ms_before\": 0.1},\n",
    "            \"correlograms\": {\"bin_ms\": 0.1},\n",
    "            \"template_similarity\": {\"method\": \"cosine_similarity\"}\n",
    "        }\n",
    "\n",
    "        analyzer_kilosort4.compute(extensions_to_compute, extension_params=extension_params)\n",
    "\n",
    "        qm_params = sqm.get_default_qm_params()\n",
    "        analyzer_kilosort4.compute(\"quality_metrics\", qm_params)\n",
    "\n",
    "        import spikeinterface.exporters as sexp\n",
    "        sexp.export_to_phy(analyzer_kilosort4, output_folder + \"/phy_folder_for_kilosort\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12fcf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = np.load(\"/media/ubuntu/sda/Monkey/TVSD/monkeyF/20240112/Block_1/processed_data/Hub1-instance1_B001/array_01_V1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = se.NumpyRecording(recording.T, sampling_frequency=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14635242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probeinterface import write_probeinterface, read_probeinterface\n",
    "\n",
    "probe_30channel = read_probeinterface('/media/ubuntu/sda/Monkey/probe.json')\n",
    "probe_30channel.set_global_device_channel_indices([i for i in range(64)])\n",
    "recording_recorded = recording.set_probegroup(probe_30channel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f71a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 7,031,518 samples \n",
      "                         234.38s (3.91 minutes) - float32 dtype - 1.68 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 7,031,518 samples \n",
      "                          234.38s (3.91 minutes) - float32 dtype - 1.68 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpq3oq4adi/UC8PBUQH\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 235/235 [00:11<00:00, 21.15it/s]\n",
      "/tmp/ipykernel_1458373/1382817715.py:11: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 7,031,518 samples \n",
      "                       234.38s (3.91 minutes) - float32 dtype - 1.68 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:09<00:00, 11.83it/s]\n",
      "100%|██████████| 8/8 [00:21<00:00,  2.66s/it]\n",
      "100%|██████████| 118/118 [00:03<00:00, 31.27it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 235/235 [00:00<00:00, 5650.40it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n"
     ]
    }
   ],
   "source": [
    "recording_cmr = recording_recorded\n",
    "recording_f = spre.bandpass_filter(recording_recorded, freq_min=300, freq_max=3000)\n",
    "print(recording_f)\n",
    "recording_cmr = spre.common_reference(recording_f, reference=\"global\", operator=\"median\")\n",
    "print(recording_cmr)\n",
    "\n",
    "# this computes and saves the recording after applying the preprocessing chain\n",
    "recording_preprocessed = recording_cmr.save(format=\"binary\")\n",
    "print(recording_preprocessed)\n",
    "output_folder = '/media/ubuntu/sda/Monkey/test'\n",
    "sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n",
    "analyzer_kilosort4 = si.create_sorting_analyzer(sorting=sorting_kilosort4, recording=recording_preprocessed, format='binary_folder', folder=output_folder + '/analyzer_kilosort4_binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e35e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute_waveforms (no parallelization): 100%|██████████| 235/235 [00:10<00:00, 22.62it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 50.80it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 235/235 [00:01<00:00, 231.21it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 884.63it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 235/235 [00:24<00:00,  9.40it/s]\n",
      "Fitting PCA: 100%|██████████| 64/64 [00:12<00:00,  5.21it/s]\n",
      "Projecting waveforms: 100%|██████████| 64/64 [00:00<00:00, 2211.66it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 235/235 [00:16<00:00, 13.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/test/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extensions_to_compute = [\n",
    "            \"random_spikes\",\n",
    "            \"waveforms\",\n",
    "            \"noise_levels\",\n",
    "            \"templates\",\n",
    "            \"spike_amplitudes\",\n",
    "            \"unit_locations\",\n",
    "            \"spike_locations\",\n",
    "            \"correlograms\",\n",
    "            \"template_similarity\"\n",
    "        ]\n",
    "\n",
    "extension_params = {\n",
    "    \"unit_locations\": {\"method\": \"center_of_mass\"},\n",
    "    \"spike_locations\": {\"ms_before\": 0.1},\n",
    "    \"correlograms\": {\"bin_ms\": 0.1},\n",
    "    \"template_similarity\": {\"method\": \"cosine_similarity\"}\n",
    "}\n",
    "\n",
    "analyzer_kilosort4.compute(extensions_to_compute, extension_params=extension_params)\n",
    "\n",
    "qm_params = sqm.get_default_qm_params()\n",
    "analyzer_kilosort4.compute(\"quality_metrics\", qm_params)\n",
    "\n",
    "import spikeinterface.exporters as sexp\n",
    "sexp.export_to_phy(analyzer_kilosort4, output_folder + \"/phy_folder_for_kilosort\", verbose=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike_sorting_jct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
