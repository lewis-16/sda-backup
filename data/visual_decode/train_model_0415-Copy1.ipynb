{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"KEY\"\n",
    "os.environ[\"WANDB_MODE\"] = 'offline'\n",
    "from itertools import combinations\n",
    "\n",
    "import clip\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import tqdm\n",
    "\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "import csv\n",
    "from torch import Tensor\n",
    "import itertools\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_binned_spiketrains(trigger_time_df, spike_inf_df, target_image):\n",
    "    \"\"\"\n",
    "    生成指定image下的分箱脉冲矩阵\n",
    "    \n",
    "    参数\n",
    "    ----\n",
    "    trigger_time_df : pd.DataFrame\n",
    "        列包括：start, end, image, date, order\n",
    "    spike_inf_df : pd.DataFrame\n",
    "        列包括：time, neuron, date\n",
    "    target_image : str/int\n",
    "        目标图像标识\n",
    "    \n",
    "    返回\n",
    "    ----\n",
    "    binned_data : list of ndarray\n",
    "        [\n",
    "            # Trial 1 的矩阵 (neurons × 100 bins)\n",
    "            array([[n0_bin1_count, n0_bin2_count, ...],\n",
    "                   [n1_bin1_count, n1_bin2_count, ...],\n",
    "                   ...]),\n",
    "            # Trial 2\n",
    "            ...\n",
    "        ]\n",
    "    \"\"\"\n",
    "    # =====================================\n",
    "    # 步骤 1: 筛选目标试次并转换时间单位\n",
    "    # =====================================\n",
    "    mask = (trigger_time_df['image'] == target_image)\n",
    "    target_triggers = trigger_time_df[mask].sort_values('order')\n",
    "    \n",
    "    # 转换时间单位 (0.1ms → 秒)\n",
    "    target_triggers = target_triggers.copy()\n",
    "    target_triggers['start'] = target_triggers['start'] * 0.1e-3\n",
    "    target_triggers['end'] = target_triggers['end'] * 0.1e-3\n",
    "\n",
    "    # =====================================\n",
    "    # 步骤 2: 处理神经脉冲数据\n",
    "    # =====================================\n",
    "    target_spikes = spike_inf_df.copy()\n",
    "    target_spikes['time'] = target_spikes['time'] * 0.1e-3 \n",
    "    \n",
    "    # 获取所有唯一神经元ID并排序（基于完整数据集）\n",
    "    all_neuron_ids = sorted(spike_inf_df['Neuron'].unique()) if not spike_inf_df.empty else []\n",
    "\n",
    "    # =====================================\n",
    "    # 步骤 3: 分箱处理每个试次\n",
    "    # =====================================\n",
    "    binned_data = []\n",
    "    for _, trial in target_triggers.iterrows():\n",
    "        trial_start = trial['start']\n",
    "        trial_end = trial['end']\n",
    "        trial_duration = trial_end - trial_start\n",
    "        \n",
    "        spike_mask = (target_spikes['time'] >= trial_start) & (target_spikes['time'] < trial_end)\n",
    "        trial_spikes = target_spikes[spike_mask].copy()\n",
    "        trial_spikes['rel_time'] = trial_spikes['time'] - trial_start\n",
    "        \n",
    "        bin_matrix = np.zeros((len(all_neuron_ids), 100), dtype=int)\n",
    "        \n",
    "        neuron_groups = trial_spikes.groupby('Neuron')\n",
    "        for neuron_idx, neuron_id in enumerate(all_neuron_ids):\n",
    "            if neuron_id in neuron_groups.groups:\n",
    "                group = neuron_groups.get_group(neuron_id)\n",
    "                times = group['rel_time'].values\n",
    "                \n",
    "                counts, _ = np.histogram(times, bins=100, range=(0, trial_duration))\n",
    "                bin_matrix[neuron_idx] = counts\n",
    "                \n",
    "        binned_data.append(bin_matrix)\n",
    "    \n",
    "    return binned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EPDataset(Dataset):\n",
    "    def __init__(self, EP_data, labels, features, img_paths):\n",
    "        self.img_paths = img_paths  \n",
    "        self.EP_data = EP_data\n",
    "        self.labels = labels\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.EP_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        EP_tensor = torch.tensor(self.EP_data[idx].T, dtype=torch.float32) \n",
    "        label = torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
    "        feature = self.features[idx]\n",
    "        return EP_tensor, label, feature, self.img_paths[idx]\n",
    "\n",
    "def extract_features(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_paths = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for neuro, _, _, paths in dataloader:\n",
    "            neuro = neuro.to(device)\n",
    "            _, features = model(neuro)\n",
    "            all_features.append(features.cpu())\n",
    "            all_paths.extend(paths)\n",
    "    \n",
    "    return torch.cat(all_features), all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfig:\n",
    "    def __init__(self,\n",
    "                 input_neuron=25,        \n",
    "                 time_bins=20,          \n",
    "                 d_model = 150,          \n",
    "                 nhead=10,                \n",
    "                 num_transformer_layers=1, \n",
    "                 conv_channels=64,      \n",
    "                 num_conv_blocks=3,      \n",
    "                 num_classes=117,        \n",
    "                 residual_dims=[256, 512, 1024], \n",
    "                 use_positional_encoding=True,  \n",
    "                 dim_feedforward_ratio=4,      \n",
    "                 activation='relu',\n",
    "                 use_neuron_masking=True,  \n",
    "                 mask_ratio=0,\n",
    "                 mask_replacement='zero'):\n",
    "        \n",
    "        # Transformer \n",
    "        self.transformer = {\n",
    "            'd_model': d_model,\n",
    "            'nhead': nhead,\n",
    "            'num_layers': num_transformer_layers,\n",
    "            'dim_feedforward': d_model * dim_feedforward_ratio,\n",
    "            'activation': activation\n",
    "        }\n",
    "        \n",
    "        # cnn\n",
    "        self.convolution = {\n",
    "            'channels': conv_channels,\n",
    "            'num_blocks': num_conv_blocks,\n",
    "            'kernel_size': (3, 3),\n",
    "            'pool_size': (2, 2)\n",
    "        }\n",
    "        \n",
    "        # resnet\n",
    "        self.residual = {\n",
    "            'dims': residual_dims,\n",
    "            'skip_connection': True\n",
    "        }\n",
    "        \n",
    "        self.masking = {\n",
    "            'enabled': use_neuron_masking,\n",
    "            'ratio': mask_ratio,\n",
    "            'replacement': mask_replacement\n",
    "        }\n",
    "\n",
    "        self.input_dim = input_neuron\n",
    "        self.time_steps = time_bins\n",
    "        self.num_classes = num_classes\n",
    "        self.positional_encoding = use_positional_encoding\n",
    "        self.lr = 2e-4\n",
    "        self.epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuronMasker(nn.Module):\n",
    "    def __init__(self, mask_ratio=0.15, replacement='random'):\n",
    "        super().__init__()\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.replacement = replacement\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            if x is None:\n",
    "                raise ValueError(\"Input tensor x is None\")\n",
    "                \n",
    "            batch_size, seq_len, feat_dim = x.shape\n",
    "            mask = torch.rand(batch_size, 1, feat_dim, device=x.device) < self.mask_ratio\n",
    "            mask = mask.expand_as(x)\n",
    "            \n",
    "            if self.replacement == 'zero':\n",
    "                x_masked = x.masked_fill(mask, 0)\n",
    "            elif self.replacement == 'random':\n",
    "                random_values = torch.randn_like(x) * 0.02\n",
    "                x_masked = x.masked_scatter(mask, random_values)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid replacement: {self.replacement}\")\n",
    "            \n",
    "            return x_masked \n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "class ResidualLinearBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.norm = nn.LayerNorm(output_dim)\n",
    "        self.activation = nn.GELU()\n",
    "        self.downsample = nn.Linear(input_dim, output_dim) if input_dim != output_dim else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.downsample(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        return x + residual\n",
    "\n",
    "class TimeTransformerConvModel(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.input_proj = nn.Linear(config.input_dim, config.transformer['d_model'])\n",
    "        self.pos_encoder = PositionalEncoding(config.transformer['d_model']) if config.positional_encoding else nn.Identity()\n",
    "        \n",
    "        transformer_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config.transformer['d_model'],\n",
    "            nhead=config.transformer['nhead'],\n",
    "            dim_feedforward=config.transformer['dim_feedforward'],\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(transformer_layer, config.transformer['num_layers'])\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential()\n",
    "        in_channels = 1\n",
    "        for _ in range(config.convolution['num_blocks']):\n",
    "            self.conv_blocks.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, config.convolution['channels'], \n",
    "                            kernel_size=config.convolution['kernel_size'], padding='same'),\n",
    "                    nn.BatchNorm2d(config.convolution['channels']),\n",
    "                    nn.ELU(),\n",
    "                    nn.MaxPool2d(kernel_size=config.convolution['pool_size'])\n",
    "                )\n",
    "            )\n",
    "            in_channels = config.convolution['channels']\n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(config.convolution['channels'], config.num_classes)\n",
    "        \n",
    "        self.residual_layers = nn.Sequential()\n",
    "        current_dim = config.convolution['channels']\n",
    "        for dim in config.residual['dims']:\n",
    "            self.residual_layers.append(ResidualLinearBlock(current_dim, dim))\n",
    "            current_dim = dim\n",
    "        if current_dim != 1024:\n",
    "            self.residual_layers.append(nn.Linear(current_dim, 1024))\n",
    "            self.residual_layers.append(nn.LayerNorm(1024))\n",
    "\n",
    "\n",
    "        self.masker = NeuronMasker(\n",
    "            mask_ratio=self.config.masking['ratio'],\n",
    "            replacement=self.config.masking['replacement']\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.masker(x)  # [B, T, D]\n",
    "        #print(x)\n",
    "        x = self.input_proj(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv_blocks(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.flatten(1)\n",
    "        \n",
    "        logits = self.classifier(x)\n",
    "        features = self.residual_layers(x)\n",
    "        \n",
    "        return logits, features\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(1)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskLoss(nn.Module):\n",
    "    def __init__(self, alpha=0, temp=0.07):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha      # 分类损失权重\n",
    "        self.temp = temp\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.temp = temp\n",
    "        \n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def contrastive_loss(self, h_neuro, h_img):\n",
    "        h_neuro = F.normalize(h_neuro, dim=1) + 1e-10\n",
    "        h_img = F.normalize(h_img, dim=1) + 1e-10\n",
    "        \n",
    "        logits_ab = torch.matmul(h_neuro, h_img.T) / self.temp\n",
    "        logits_ba = torch.matmul(h_img, h_neuro.T) / self.temp\n",
    "        \n",
    "        labels = torch.arange(h_neuro.size(0), device=h_neuro.device)\n",
    "        loss_ab = F.cross_entropy(logits_ab, labels)\n",
    "        loss_ba = F.cross_entropy(logits_ba, labels)\n",
    "        \n",
    "        return (loss_ab + loss_ba) / 2\n",
    "    \n",
    "    def forward(self, logits, labels, img_feature, features):\n",
    "        loss_cls = self.ce_loss(logits, labels)\n",
    "        loss_cont = self.contrastive_loss(features, img_feature)\n",
    "        total_loss = self.alpha * loss_cls + (1 - self.alpha) * loss_cont\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, device, criterion, config):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (neuro, labels, img_feature, _) in enumerate(dataloader):\n",
    "        neuro = neuro.to(device)\n",
    "        labels = labels.to(device)\n",
    "        img_feature = img_feature.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits, features = model(neuro)\n",
    "        loss = criterion(logits, labels, img_feature, features)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), \n",
    "            max_norm=3.0,                   \n",
    "            norm_type=2.0                   \n",
    "        )\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 统计指标\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "    train_loss = total_loss / len(dataloader)\n",
    "    train_accuracy = correct / total\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, dataloader, device, criterion, config, image_cluster):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    correct_2way = 0\n",
    "    correct_4way = 0\n",
    "    correct_10way = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 从 DataFrame 创建聚类映射字典\n",
    "    cluster_2_map = torch.tensor(image_cluster[\"2_cluster\"].values, device=device)\n",
    "    cluster_4_map = torch.tensor(image_cluster[\"4_cluster\"].values, device=device)\n",
    "    cluster_10_map = torch.tensor(image_cluster[\"10_cluster\"].values, device=device)\n",
    "    \n",
    "    for neuro, labels, img_feature, _ in dataloader:\n",
    "        neuro = neuro.to(device)\n",
    "        labels = labels.to(device)\n",
    "        img_feature = img_feature.to(device)\n",
    "        \n",
    "        logits, features = model(neuro)\n",
    "        \n",
    "        loss = criterion(logits, labels, img_feature, features)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # （Top-1 和 Top-5）\n",
    "        _, predicted_top1 = torch.max(logits, 1)\n",
    "        correct_top1 += (predicted_top1 == labels).sum().item()\n",
    "        _, predicted_top5 = logits.topk(5, dim=1)\n",
    "        correct_top5 += torch.sum(predicted_top5.eq(labels.view(-1, 1))).item()\n",
    "        \n",
    "        # (2-way, 4-way, 10-way)\n",
    "        cluster_2_pred = cluster_2_map[predicted_top1]\n",
    "        cluster_4_pred = cluster_4_map[predicted_top1]\n",
    "        cluster_10_pred = cluster_10_map[predicted_top1]\n",
    "        \n",
    "        cluster_2_true = cluster_2_map[labels]\n",
    "        cluster_4_true = cluster_4_map[labels]\n",
    "        cluster_10_true = cluster_10_map[labels]\n",
    "        \n",
    "        correct_2way += (cluster_2_pred == cluster_2_true).sum().item()\n",
    "        correct_4way += (cluster_4_pred == cluster_4_true).sum().item()\n",
    "        correct_10way += (cluster_10_pred == cluster_10_true).sum().item()\n",
    "        \n",
    "        total += labels.size(0)\n",
    "    \n",
    "    test_loss = total_loss / len(dataloader)\n",
    "    test_accuracy = correct_top1 / total\n",
    "    top5_accuracy = correct_top5 / total\n",
    "    accuracy_2way = correct_2way / total\n",
    "    accuracy_4way = correct_4way / total\n",
    "    accuracy_10way = correct_10way / total\n",
    "    \n",
    "    return test_loss, test_accuracy, top5_accuracy, accuracy_2way, accuracy_4way, accuracy_10way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train_loop(config, model, train_loader, test_loader, device, image_cluster):\n",
    "    optimizer = AdamW(model.parameters(), lr=config.lr)\n",
    "    criterion = MultitaskLoss(alpha=0.7, temp=0.07)\n",
    "    \n",
    "    train_losses, train_accs = [], []\n",
    "    test_losses, test_accs, test_top5, acc_2way, acc_4way, acc_10way = [], [], [], [], [], []\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        train_loss, train_acc = train_model(\n",
    "            model=model,\n",
    "            dataloader=train_loader,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            criterion=criterion,\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        test_loss, test_acc, top5_acc, accuracy_2way, accuracy_4way, accuracy_10way = evaluate_model(\n",
    "            model=model,\n",
    "            dataloader=test_loader,\n",
    "            device=device,\n",
    "            criterion=criterion,\n",
    "            config=config,\n",
    "            image_cluster = image_cluster\n",
    "        )\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "        test_top5.append(top5_acc)\n",
    "        acc_2way.append(accuracy_2way)\n",
    "        acc_4way.append(accuracy_4way)\n",
    "        acc_10way.append(accuracy_10way)\n",
    "        \n",
    "        \n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            best_epoch = epoch\n",
    "        \n",
    "        # 打印日志\n",
    "        #print(f\"Epoch {epoch+1}/{config.epochs}\")\n",
    "        #print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2%}\")\n",
    "        #print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2%} | Top-5 Acc: {top5_acc:.2%}\")\n",
    "        #print(f\"2-way Acc: {accuracy_2way:.2%} | 4-way Acc: {accuracy_4way:.2%} | 10-way Acc: {accuracy_10way:.2%}\")\n",
    "        #print(\"-\" * 60)\n",
    "        \n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label=\"Train\")\n",
    "    plt.plot(test_losses, label=\"Test\")\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label=\"Train Acc\")\n",
    "    plt.plot(test_accs, label=\"Test Acc\")\n",
    "    plt.plot(test_top5, label=\"Test Top-5\")\n",
    "    plt.title(\"Accuracy Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        \"best_test_acc\": best_acc,\n",
    "        \"final_top5_acc\": test_top5[-1],\n",
    "        \"train_history\": {\n",
    "            \"loss\": train_losses,\n",
    "            \"accuracy\": train_accs\n",
    "        },\n",
    "        \"test_history\": {\n",
    "            \"loss\": test_losses,\n",
    "            \"accuracy\": test_accs,\n",
    "            \"top5_accuracy\": test_top5,\n",
    "            \"acc_2way\": acc_2way,\n",
    "            \"acc_4way\": acc_4way,\n",
    "            \"acc_10way\": acc_10way\n",
    "        },\n",
    "        \"best_epoch\": best_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_order = ['021322', '022522', '031722', '042422', \n",
    "              '052422', '062422', '072322', '082322', \n",
    "              '092422', '102122', '112022', '122022', \n",
    "              #'012123', \n",
    "              '022223', '032123', '042323']\n",
    "date_order_num = [int(i) for i in date_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_time = pd.read_csv(\"/root/autodl-tmp/trigger_time.csv\")\n",
    "with open(\"/root/autodl-tmp/image_feature_list.pkl\", 'rb') as f:\n",
    "    image_feature_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "\n",
    "test_month = [date_order[14]]\n",
    "all_spike_inf = pd.read_csv(f\"/root/autodl-tmp/closed_loop/spike_042323.tsv\", sep=\"\\t\")\n",
    "date_order_temp = date_order[:15]\n",
    "\n",
    "EP_data_dict = {}\n",
    "for date in date_order_temp:\n",
    "    temp = trigger_time[trigger_time['date'] == int(date)]\n",
    "    temp_spike = all_spike_inf[all_spike_inf['date'] == int(date)]\n",
    "\n",
    "    for image in range(1, 118):\n",
    "        num = 1\n",
    "        spike_train = generate_binned_spiketrains(temp, temp_spike, image)\n",
    "        for i in range(len(spike_train)):\n",
    "            EP_data_dict[f\"{date}_{image}_{num}\"] = [spike_train[i], date, image - 1]\n",
    "            num += 1\n",
    "\n",
    "for i in EP_data_dict.keys():\n",
    "    EP_data_dict[i].append(image_feature_list[EP_data_dict[i][2]])\n",
    "\n",
    "EP_data_train_dict = {}\n",
    "EP_data_test_dict = {}\n",
    "\n",
    "for i in EP_data_dict.keys():\n",
    "    if EP_data_dict[i][1] in test_month:\n",
    "        EP_data_test_dict[i] = EP_data_dict[i]\n",
    "    else:\n",
    "        EP_data_train_dict[i] = EP_data_dict[i]\n",
    "\n",
    "current_input_neuron = EP_data_train_dict['021322_100_1'][0].shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP_data_train_EP_data = [item[0] for item in EP_data_train_dict.values()]\n",
    "EP_data_train_image = [item[2] for item in EP_data_train_dict.values()]  \n",
    "EP_data_train_feature = [item[3] for item in EP_data_train_dict.values()]\n",
    "EP_data_train_img_path = ['/root/visual_decode/NaturalImages_new_2/' + str(item) + '.jpg' for item in EP_data_train_image]\n",
    "\n",
    "EP_data_test_EP_data = [item[0] for item in EP_data_test_dict.values()]\n",
    "EP_data_test_image = [item[2] for item in EP_data_test_dict.values()] \n",
    "EP_data_test_feature = [item[3] for item in EP_data_test_dict.values()]\n",
    "EP_data_test_img_path = ['/root/visual_decode/NaturalImages_new_2/' + str(item) + '.jpg' for item in EP_data_test_image]\n",
    "\n",
    "train_dataset = EPDataset(\n",
    "    EP_data_train_EP_data, EP_data_train_image, EP_data_train_feature,EP_data_train_img_path\n",
    ")\n",
    "test_dataset = EPDataset(\n",
    "    EP_data_test_EP_data, EP_data_test_image, EP_data_test_feature, EP_data_test_img_path\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "config = ModelConfig(input_neuron=current_input_neuron)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TimeTransformerConvModel(config).to(device)\n",
    "\n",
    "image_cluster = pd.read_csv(\"image_cluster.csv\")\n",
    "# results = main_train_loop(\n",
    "#     config=config,\n",
    "#     model=model,\n",
    "#     train_loader=train_loader,\n",
    "#     test_loader=test_loader,\n",
    "#     device=device,\n",
    "#     image_cluster = image_cluster\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ModelConfig(input_neuron=18)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TimeTransformerConvModel(config).to(device)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"/root/visual_decode/best_model.pth\"))\n",
    "features = extract_features(model, train_loader, device)\n",
    "torch.save(features, \"features.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGAdapter(nn.Module):\n",
    "    def __init__(self, input_dim=1024, output_dim=768, num_tokens=77):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048),  # 扩大维度\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, output_dim * num_tokens)  # 输出77*768\n",
    "        )\n",
    "        self.output_dim = output_dim\n",
    "        self.num_tokens = num_tokens\n",
    "\n",
    "    def forward(self, eeg_vector):\n",
    "        # eeg_vector: [batch_size, 1024]\n",
    "        x = self.projection(eeg_vector)  # [batch_size, 77*768]\n",
    "        x = x.view(-1, self.num_tokens, self.output_dim)  # [batch_size, 77, 768]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nStableDiffusionPipeline requires the transformers library but it was not found in your environment. You can install it with pip: `pip\ninstall transformers`\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StableDiffusionPipeline\n\u001b[0;32m----> 3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mStableDiffusionPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrunwayml/stable-diffusion-v1-5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m unet \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39munet\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mtokenizer\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/diffusers/utils/dummy_torch_and_transformers_objects.py:2147\u001b[0m, in \u001b[0;36mStableDiffusionPipeline.from_pretrained\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2145\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2147\u001b[0m     \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransformers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/diffusers/utils/import_utils.py:525\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m    523\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m--> 525\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersatileDiffusionTextToImagePipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersatileDiffusionPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnCLIPPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    533\u001b[0m ] \u001b[38;5;129;01mand\u001b[39;00m is_transformers_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    535\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to install `transformers>=4.25` in order to use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m pip install\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m --upgrade transformers \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    537\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: \nStableDiffusionPipeline requires the transformers library but it was not found in your environment. You can install it with pip: `pip\ninstall transformers`\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
    "unet = pipe.unet\n",
    "tokenizer = pipe.tokenizer\n",
    "text_encoder = pipe.text_encoder\n",
    "\n",
    "eeg_adapter = EEGAdapter()\n",
    "\n",
    "for param in unet.parameters():\n",
    "    param.requires_grad = False  \n",
    "\n",
    "for name, param in unet.named_parameters():\n",
    "    if \"attn2\" in name: \n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "noise_scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n",
    "optimizer = optim.AdamW(\n",
    "    list(eeg_adapter.parameters()) + list(unet.parameters()), \n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch in dataloader:\n",
    "        # 加载数据\n",
    "        images = batch[\"image\"]  # [batch, 3, 512, 512]\n",
    "        eeg_data = batch[\"eeg\"]  # [batch, 1024]\n",
    "\n",
    "        # 图像编码为潜变量\n",
    "        latents = pipe.vae.encode(images).latent_dist.sample()\n",
    "        latents = latents * 0.18215  # 缩放\n",
    "\n",
    "        # 添加噪声\n",
    "        noise = torch.randn_like(latents)\n",
    "        timesteps = torch.randint(0, 1000, (len(images),))\n",
    "        noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "        # 通过适配器生成条件向量\n",
    "        cond_embeddings = eeg_adapter(eeg_data)\n",
    "\n",
    "        # UNet预测噪声\n",
    "        noise_pred = unet(\n",
    "            noisy_latents, \n",
    "            timesteps, \n",
    "            encoder_hidden_states=cond_embeddings  # 注入电生理条件\n",
    "        ).sample\n",
    "\n",
    "        # 计算损失\n",
    "        loss = nn.functional.mse_loss(noise_pred, noise)\n",
    "        print(f\"Loss: {loss}\")\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
