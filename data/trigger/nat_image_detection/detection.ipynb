{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mu2net\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m U2NET  \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 加载预训练模型\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m U2NET(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from model.u2net import U2NET  \n",
    "\n",
    "# 加载预训练模型\n",
    "model = U2NET(3, 1)\n",
    "model.load_state_dict(torch.load('u2net.pth'))\n",
    "model.eval()\n",
    "\n",
    "def extract_main_object(image_path):\n",
    "    # 读取并预处理图像\n",
    "    gray_img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_rgb = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB)\n",
    "    img = cv2.resize(img_rgb, (320, 320))\n",
    "    img = img / 255.0\n",
    "    img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    # 推断显著图\n",
    "    with torch.no_grad():\n",
    "        saliency_map = model(img)[0].squeeze().numpy()\n",
    "    \n",
    "    # 二值化并提取中心区域\n",
    "    _, mask = cv2.threshold((saliency_map * 255).astype(np.uint8), 0, 255, cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # 筛选最大或中心连通域\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        center_x, center_y = x + w//2, y + h//2\n",
    "        # 检查是否位于图像中央区域（例如中心50%范围内）\n",
    "        if (0.25*320 < center_x < 0.75*320) and (0.25*320 < center_y < 0.75*320):\n",
    "            final_mask = cv2.drawContours(np.zeros_like(mask), [largest_contour], -1, 255, -1)\n",
    "            return cv2.resize(final_mask, (gray_img.shape[1], gray_img.shape[0]))\n",
    "    return None  # 未检测到显著中心物体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /home/ubuntu/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
      "100%|██████████| 170M/170M [00:15<00:00, 11.7MB/s] \n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection import MaskRCNN_ResNet50_FPN_Weights\n",
    "\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "model.eval()\n",
    "\n",
    "def extract_with_maskrcnn(image_path):\n",
    "    img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "    img_tensor = torch.tensor(img.transpose(2, 0, 1) / 255.0, dtype=torch.float32)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model([img_tensor])[0]\n",
    "    \n",
    "    # COCO类别ID（动物：1-25，植物：如'potted plant'为63）\n",
    "    target_classes = [i for i in range(1, 26)] + [63]\n",
    "    center = np.array([img.shape[1]//2, img.shape[0]//2])\n",
    "    \n",
    "    for score, label, mask, box in zip(predictions['scores'], predictions['labels'], \n",
    "                                      predictions['masks'], predictions['boxes']):\n",
    "        if score > 0.5 and label.item() in target_classes:\n",
    "            box_center = (box[:2] + box[2:]) / 2\n",
    "            # 检查是否靠近中心\n",
    "            if np.linalg.norm(box_center.numpy() - center) < max(img.shape)//4:\n",
    "                return mask[0].numpy() > 0.5\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
