{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb2591cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spikeinterface as si\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from scipy.stats import  pearsonr\n",
    "import neo\n",
    "from quantities import ms\n",
    "from elephant.statistics import instantaneous_rate\n",
    "from elephant.kernels import GaussianKernel\n",
    "import time\n",
    "\n",
    "#Pink dark ED7B85\n",
    "#Pink light F5B5B3\n",
    "#Blue dark 5E9FD1\n",
    "#Blue light A6C3E5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b2d79d",
   "metadata": {},
   "source": [
    "- Mouse6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d1993a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_order = ['021322', '022522', '031722', '042422', \n",
    "              '052422', '062422', '072322', '082322', \n",
    "              '092422', '102122', '112022', '122022', \n",
    "              '022223', '032123', '042323']\n",
    "\n",
    "date_order_num = [int(i) for i in date_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f267a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/data/paper_architecture/01_closed_loop/mouse6/pkl/cluster_042323.pkl\", \"rb\") as f:\n",
    "    cluster_inf = pickle.load(f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/data/paper_architecture/01_closed_loop/mouse6/pkl/spike_042323.pkl\", 'rb') as f:\n",
    "    spike_inf = pickle.load(f)\n",
    "\n",
    "\n",
    "cluster_inf = cluster_inf[cluster_inf['date'] != '012123']\n",
    "spike_inf = spike_inf[spike_inf['date'] != '012123']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b873ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_markers = {\n",
    "    '021322': 'o',\n",
    "    '082322': 's',\n",
    "    '122022': 'D',\n",
    "    '042323': '^'\n",
    "}\n",
    "\n",
    "unique_neurons = cluster_inf['Neuron'].unique()\n",
    "palette = sns.color_palette('tab10', len(unique_neurons))\n",
    "neuron_colors = {neuron: color for neuron, color in zip(unique_neurons, palette)}\n",
    "\n",
    "with PdfPages('/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/probe_group_view.pdf') as pdf:\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '1']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {1}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(-10, 60)\n",
    "    ax.set_ylim(-10, 110)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '2']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {2}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(140, 210)\n",
    "    ax.set_ylim(190, 310)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '3']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {3}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(240, 360)\n",
    "    ax.set_ylim(390, 510)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '4']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {4}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(440, 510)\n",
    "    ax.set_ylim(190, 310)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '5']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {5}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(590, 660)\n",
    "    ax.set_ylim(-10, 110)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6769b4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n",
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n",
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n",
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n",
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n"
     ]
    }
   ],
   "source": [
    "displacement_df_position_1 = pd.DataFrame()\n",
    "displacement_df_position_2 = pd.DataFrame()\n",
    "\n",
    "for neuron in cluster_inf['Neuron'].unique():\n",
    "    temp = cluster_inf[cluster_inf['Neuron'] == neuron]\n",
    "    displacement_1 = []\n",
    "    displacement_2 = []\n",
    "    for date in date_order:\n",
    "        displacement_1.append(temp[temp['date'] == date]['position_1'].values.mean() - temp[temp['date'] == '021322']['position_1'].values.mean())\n",
    "        displacement_2.append(temp[temp['date'] == date]['position_2'].values.mean() - temp[temp['date'] == '021322']['position_2'].values.mean())\n",
    "    displacement_df_position_1[neuron] = displacement_1\n",
    "    displacement_df_position_2[neuron] = displacement_2\n",
    "\n",
    "months_to_plot = [2, 6, 8, 12, 15]  \n",
    "n_months = len(months_to_plot)\n",
    "\n",
    "colors = sns.color_palette(\"viridis\", n_colors=n_months)\n",
    "\n",
    "with PdfPages('/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/displacement_kde.pdf') as pdf:\n",
    "    for idx, m in enumerate(months_to_plot):\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        ax.plot(0, 0, 'ko', markersize=8, zorder=10)  \n",
    "        data_month = pd.concat((\n",
    "            displacement_df_position_1.iloc[m-1, :], \n",
    "            displacement_df_position_2.iloc[m-1, :]), axis=1)\n",
    "        \n",
    "        sns.kdeplot(\n",
    "            x = displacement_df_position_1.iloc[m-1, :],\n",
    "            y=displacement_df_position_2.iloc[m-1, :],\n",
    "            ax=ax,\n",
    "            linewidth=1.5,\n",
    "            fill=False,  \n",
    "            label=f'Month {m}',\n",
    "            thresh=0.25,\n",
    "            levels=6,\n",
    "            common_norm=False  \n",
    "        )\n",
    "\n",
    "        ax.set_xlabel('Position Value', fontsize=12)\n",
    "        ax.set_ylabel('Density', fontsize=12)\n",
    "        ax.set_ylim(-10, 10)\n",
    "        ax.set_xlim(-10, 10)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e33f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_groups = cluster_inf.groupby('date')\n",
    "result_matrix = {}\n",
    "\n",
    "for date, group in date_groups:\n",
    "    neurons = group.set_index('Neuron')[['position_1', 'position_2']]\n",
    "    neuron_list = sorted(neurons.index.unique())\n",
    "    n = len(neuron_list)\n",
    "    \n",
    "    dist_matrix = np.zeros((n, n), dtype=float)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                dist_matrix[i][j] = 0 \n",
    "            else:\n",
    "                pos_i = neurons.loc[neuron_list[i]]\n",
    "                pos_j = neurons.loc[neuron_list[j]]\n",
    "                dist = np.sqrt((pos_i['position_1'].mean()-pos_j['position_1'].mean())**2 + (pos_i['position_2'].mean()-pos_j['position_2'].mean())**2)\n",
    "                dist_matrix[i][j] = dist\n",
    "    \n",
    "    result_matrix[date] = pd.DataFrame(dist_matrix, index=neuron_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba679d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "displacement_dict = {}\n",
    "for probe in cluster_inf['probe_group']:\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == probe]\n",
    "    month_groups = temp.groupby('date')\n",
    "\n",
    "    month_pairs = [('021322', '022522'),\n",
    "                ('021322', '062422'),\n",
    "                ('021322', '082322'),\n",
    "                ('021322', '122022'),\n",
    "                ('021322', '042323')]\n",
    "\n",
    "    all_neurons = sorted(temp['Neuron'].unique())\n",
    "    n_neurons = len(all_neurons)\n",
    "    n_pairs = len(month_pairs)\n",
    "\n",
    "    distance_matrix = np.full((n_pairs, n_neurons, n_neurons), np.nan)\n",
    "\n",
    "    for pair_idx, (month_a, month_b) in enumerate(month_pairs):\n",
    "        group_a = month_groups.get_group(month_a).set_index('Neuron')[['position_1', 'position_2']]\n",
    "        group_b = month_groups.get_group(month_b).set_index('Neuron')[['position_1', 'position_2']]\n",
    "        \n",
    "        for i, neuron_i in enumerate(all_neurons):\n",
    "            for j, neuron_j in enumerate(all_neurons):\n",
    "                if (neuron_i in group_a.index) and (neuron_j in group_b.index):\n",
    "                    pos_i = group_a.loc[neuron_i]\n",
    "                    pos_j = group_b.loc[neuron_j]\n",
    "                    distance = np.sqrt((pos_i['position_1'].mean()-pos_j['position_1'].mean())**2 + (pos_i['position_2'].mean()-pos_j['position_2'].mean())**2)\n",
    "                    distance_matrix[pair_idx, i, j] = distance\n",
    "    displacement_dict[probe] = distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c5edeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/hist_displacement.pdf\") as pdf:\n",
    "    for month in range(5):\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        df_1 = []\n",
    "        df_2 = []\n",
    "\n",
    "        for probe in displacement_dict.keys():\n",
    "            df_1.append([displacement_dict[probe][month, i, i] for i in range(displacement_dict[probe].shape[1])])\n",
    "            df_2.append(displacement_dict[probe].flatten())\n",
    "\n",
    "        df_1 = flattened_list = np.concatenate(df_1)\n",
    "        df_2 = flattened_list = np.concatenate(df_2)\n",
    "        sns.ecdfplot(df_1, color='#2980b9', label='Within-neuron displacement', linewidth=2, ax=ax)\n",
    "        sns.ecdfplot(df_2, color='orange', label='Across-neuron displacement', linewidth=2, ax=ax)\n",
    "\n",
    "        ax.spines['top'].set_visible(False) \n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_linewidth(1.5)  \n",
    "        ax.spines['bottom'].set_linewidth(1.5)\n",
    "        pdf.savefig()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f4b2e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_time = pd.read_csv(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/trigger/trigger_time_mouse6.tsv\", sep = '\\t').iloc[:, 1:]\n",
    "trigger_time = trigger_time[trigger_time['date'] != 12123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4878dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_dict = {}\n",
    "correlation_dict = {}\n",
    "\n",
    "for date in spike_inf['date'].unique():\n",
    "    spike_inf_temp = spike_inf[spike_inf['date'] == date]\n",
    "    firing_rate_dict[date] = {}\n",
    "    trigger_time_temp = trigger_time[trigger_time['date'] == int(date)]\n",
    "    for image in trigger_time_temp['image'].unique():\n",
    "        firing_rate_dict[date][image] = pd.DataFrame()\n",
    "        trigger_time_temp_temp = trigger_time_temp[trigger_time_temp['image'] == image]\n",
    "        for image_order in trigger_time_temp_temp['order'].sort_index().values.tolist():\n",
    "            trigger_time_temp_temp_temp = trigger_time_temp_temp[trigger_time_temp_temp['order'] == image_order]\n",
    "            temp = spike_inf_temp[(spike_inf_temp['time'] > int(trigger_time_temp_temp_temp['start'].values)) & (spike_inf_temp['time'] < int(trigger_time_temp_temp_temp['end'].values))]\n",
    "            firing_rate_dict[date][image] = pd.concat((firing_rate_dict[date][image], pd.DataFrame(temp['Neuron'].value_counts()).sort_index()), axis=1)\n",
    "        firing_rate_dict[date][image] = firing_rate_dict[date][image].fillna(0)\n",
    "\n",
    "    correlation_dict[date] = {}\n",
    "    for key in sorted(list(firing_rate_dict[date].keys())):\n",
    "        num = firing_rate_dict[date][key].shape[1]\n",
    "        correlation_dict[date][key] = np.zeros((num, num))\n",
    "        for i in range(num):\n",
    "            for j in range(num):\n",
    "                correlation_dict[date][key][i, j], _ = pearsonr(firing_rate_dict[date][key].iloc[:, i].values.tolist(), firing_rate_dict[date][key].iloc[:, j].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5536c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = []\n",
    "for date in correlation_dict.keys():\n",
    "    for image in range(1, 118):\n",
    "        mean = (correlation_dict[date][image].sum(axis = 0)-1)/(len(correlation_dict[date][image]) - 1)\n",
    "        for i in range(len(mean)):\n",
    "            if mean[i] <= 0.6:\n",
    "                outlier.append(f'{date}_{image}_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c5766a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find 595 outliers\n"
     ]
    }
   ],
   "source": [
    "print(f\"Find {len(outlier)} outliers\")\n",
    "\n",
    "outlier_set = set(outlier)\n",
    "\n",
    "trigger_time_clean = trigger_time.copy()\n",
    "\n",
    "trigger_time_clean['trial_index'] = trigger_time_clean.groupby(['date', 'image']).cumcount()\n",
    "\n",
    "trigger_time_clean['outlier_id'] = trigger_time_clean['date'].astype(str) + '_' + trigger_time_clean['image'].astype(str) + '_' + trigger_time_clean['trial_index'].astype(str)\n",
    "\n",
    "original_count = len(trigger_time_clean)\n",
    "trigger_time_clean = trigger_time_clean[~trigger_time_clean['outlier_id'].isin(outlier_set)]\n",
    "\n",
    "trigger_time_clean = trigger_time_clean.drop(['trial_index', 'outlier_id'], axis=1)\n",
    "\n",
    "removed_count = original_count - len(trigger_time_clean)\n",
    "\n",
    "trigger_time = trigger_time_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdafad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/media/ubuntu/sda/data/paper_architecture/02_consistency/outlier_mouse6.pkl', 'wb') as f:\n",
    "    pickle.dump(outlier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be7a32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_mean = pd.DataFrame()\n",
    "for date in correlation_dict.keys():\n",
    "    temp = []\n",
    "    for image, df in correlation_dict[date].items():\n",
    "        df = df.mean().mean()\n",
    "        temp.append(df)\n",
    "    correlation_mean = pd.concat((correlation_mean, pd.DataFrame(temp, columns=[date])),axis=1)\n",
    "\n",
    "correlation_mean = correlation_mean[date_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf6c3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/similarity_within_dates.pdf\") as pdf:\n",
    "    mean = correlation_mean.mean(axis=0)\n",
    "    std = correlation_mean.std(axis=0)\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.lineplot(x = range(15),\n",
    "                 y = mean * 100,\n",
    "                 color = 'black')\n",
    "    sns.scatterplot(x = range(15),\n",
    "                    y = mean * 100,\n",
    "                    size=30,\n",
    "                    color = \"black\",\n",
    "                    legend=False)\n",
    "    plt.fill_between(x  = range(15), \n",
    "                     y1=(mean - std) * 100,\n",
    "                     y2=(mean + std) * 100,\n",
    "                     color = 'grey',\n",
    "                     alpha = 0.2)\n",
    "    plt.xticks([])\n",
    "    plt.ylim(0, 100)\n",
    "    plt.ylabel(None)\n",
    "    pdf.savefig()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edf254c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_similarity_dict = {}\n",
    "for date in spike_inf['date'].unique():\n",
    "    mean_similarity_dict[date] = {}\n",
    "    for key in sorted(list(firing_rate_dict[date].keys())):\n",
    "        mean_similarity = np.mean(correlation_dict[date][key])\n",
    "        mean_similarity_dict[date][key] = mean_similarity\n",
    "\n",
    "mean_similarity_df = pd.DataFrame(mean_similarity_dict).T\n",
    "\n",
    "mean_similarity_df = mean_similarity_df.loc[date_order]\n",
    "mean_similarity_df.index = date_order  \n",
    "\n",
    "with PdfPages('/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/ER_similarity_lineplot.pdf') as pdf:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    for key in mean_similarity_df.columns:\n",
    "        ax.plot(mean_similarity_df.index, mean_similarity_df[key], color = '#F5B5B3')\n",
    "    \n",
    "    sns.lineplot(x = range(15),\n",
    "                 y = mean,\n",
    "                 color = 'black', linewidth = 4)\n",
    "    \n",
    "    ax.set_title('Mean Similarity Over Time for Each Image')\n",
    "    ax.set_ylim(0, 1)    \n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17a7cefd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m start = row[\u001b[33m'\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m'\u001b[39m] - \u001b[32m5000\u001b[39m\n\u001b[32m     20\u001b[39m end = row[\u001b[33m'\u001b[39m\u001b[33mend\u001b[39m\u001b[33m'\u001b[39m] + \u001b[32m10000\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m filtered_spikes = neuron_df[(\u001b[43mneuron_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m) \n\u001b[32m     23\u001b[39m                           & (neuron_df[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m] >= start)\n\u001b[32m     24\u001b[39m                           & (neuron_df[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m] <= end)]\n\u001b[32m     26\u001b[39m relative_spikes = filtered_spikes[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m] - start\n\u001b[32m     27\u001b[39m relative_spikes = relative_spikes.values / \u001b[32m10\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/spike_sorting/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/spike_sorting/lib/python3.11/site-packages/pandas/core/arraylike.py:40\u001b[39m, in \u001b[36mOpsMixin.__eq__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__eq__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/spike_sorting/lib/python3.11/site-packages/pandas/core/series.py:6130\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6127\u001b[39m lvalues = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   6128\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6130\u001b[39m res_values = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(res_values, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/spike_sorting/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:344\u001b[39m, in \u001b[36mcomparison_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m lvalues.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     res_values = \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    347\u001b[39m     res_values = _na_arithmetic_op(lvalues, rvalues, op, is_cmp=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/spike_sorting/lib/python3.11/site-packages/pandas/core/ops/array_ops.py:129\u001b[39m, in \u001b[36mcomp_method_OBJECT_ARRAY\u001b[39m\u001b[34m(op, x, y)\u001b[39m\n\u001b[32m    127\u001b[39m     result = libops.vec_compare(x.ravel(), y.ravel(), op)\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     result = \u001b[43mlibops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.reshape(x.shape)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "image_mean_spike_rate_data = {}\n",
    "gk = GaussianKernel(25 * ms)\n",
    "\n",
    "\n",
    "for image in range(1, 118):\n",
    "    image_dict = {}\n",
    "    \n",
    "    for date in date_order:\n",
    "        neuron_data = []\n",
    "        \n",
    "        for neuron in spike_inf['Neuron'].unique():\n",
    "            neuron_df = spike_inf[spike_inf['Neuron'] == neuron]\n",
    "            trigger_time_temp = trigger_time[(trigger_time['image'] == image) \n",
    "                                            & (trigger_time['date'] == int(date))]\n",
    "            \n",
    "            trial_rates = [] \n",
    "            \n",
    "            for _, row in trigger_time_temp.iterrows():\n",
    "                start = row['start'] - 5000\n",
    "                end = row['end'] + 10000\n",
    "                \n",
    "                filtered_spikes = neuron_df[(neuron_df['date'] == date) \n",
    "                                          & (neuron_df['time'] >= start)\n",
    "                                          & (neuron_df['time'] <= end)]\n",
    "                \n",
    "                relative_spikes = filtered_spikes['time'] - start\n",
    "                relative_spikes = relative_spikes.values / 10\n",
    "                temp_spiketrain = neo.SpikeTrain(relative_spikes.astype(int) * ms, t_stop=2000, t_start=0)\n",
    "                inst_rate = instantaneous_rate(temp_spiketrain, kernel=gk, sampling_period=10*ms).magnitude\n",
    "                trial_rates.append(inst_rate)\n",
    "            \n",
    "            if trial_rates:\n",
    "                mean_rate = np.mean(trial_rates, axis=0)\n",
    "            \n",
    "            neuron_data.append(mean_rate)\n",
    "        \n",
    "        neuron_data = np.stack(neuron_data)\n",
    "        image_dict[date] = neuron_data\n",
    "    \n",
    "    image_mean_spike_rate_data[image] = image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/image_mean_spike_rate_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(image_mean_spike_rate_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af2c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/image_mean_spike_rate_data.pkl\", 'rb') as f:\n",
    "    image_mean_spike_rate_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa6bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "# def create_fill_polygons(x, z, y_pos, color, alpha=0.6):\n",
    "#     \"\"\"\n",
    "#     创建填充多边形的3D集合\n",
    "#     \"\"\"\n",
    "#     verts = []\n",
    "#     for i in range(len(x)-1):\n",
    "#         verts.append([\n",
    "#             (x[i], y_pos-0.3, 0),    \n",
    "#             (x[i], y_pos-0.3, z[i]), \n",
    "#             (x[i+1], y_pos-0.3, z[i+1]),\n",
    "#             (x[i+1], y_pos-0.3, 0), \n",
    "#             (x[i], y_pos-0.3, 0)    \n",
    "#         ])\n",
    "#     return Poly3DCollection(verts, alpha=alpha, facecolors=color, edgecolors='none')\n",
    "\n",
    "# def plot_neuron_3d_fill(ax, time_bins, values, y_pos):\n",
    "#     \"\"\"\n",
    "#     绘制单个神经元的3D填充折线图\n",
    "#     \"\"\"\n",
    "#     n_bins = len(time_bins)\n",
    "#     q1 = n_bins//4 \n",
    "#     q3 = 3*n_bins//4 \n",
    "    \n",
    "#     x_deep = time_bins[q1:q3]\n",
    "#     z_deep = values[q1:q3]\n",
    "#     deep_poly = create_fill_polygons(x_deep, z_deep, y_pos, '#5E9FD1', alpha=0.8)\n",
    "#     ax.add_collection3d(deep_poly)\n",
    "    \n",
    "#     if q1 > 0:\n",
    "#         x_light1 = time_bins[:q1 + 1]\n",
    "#         z_light1 = values[:q1 + 1]\n",
    "#         light_poly1 = create_fill_polygons(x_light1, z_light1, y_pos, '#A6C3E5')\n",
    "#         ax.add_collection3d(light_poly1)\n",
    "    \n",
    "#     if q3 < n_bins:\n",
    "#         x_light2 = time_bins[q3 - 1:]\n",
    "#         z_light2 = values[q3 - 1:]\n",
    "#         light_poly2 = create_fill_polygons(x_light2, z_light2, y_pos, '#A6C3E5')\n",
    "#         ax.add_collection3d(light_poly2)\n",
    "    \n",
    "#     ax.plot(time_bins, [y_pos - 0.3] * len(time_bins), values, \n",
    "#            color='black', lw=1.8, alpha=0.95)\n",
    "\n",
    "# def generate_filled_pdf_improved(image_data, target_dates, filename):\n",
    "#     \"\"\"\n",
    "#     参数:\n",
    "#     image_data: 字典，第一级key为image，第二级key为date，值为(n_neuron, 100, 1)的numpy数组\n",
    "#     target_dates: 要绘制的日期列表\n",
    "#     filename: 输出PDF文件名\n",
    "#     \"\"\"\n",
    "#     with PdfPages(filename) as pdf:\n",
    "#         for img_num, img_data in image_data.items():\n",
    "#             sample_date = next(iter(img_data.keys()))\n",
    "#             n_neurons = img_data[sample_date].shape[0]\n",
    "            \n",
    "#             n_cols = int(np.ceil(np.sqrt(n_neurons)))\n",
    "#             n_rows = int(np.ceil(n_neurons / n_cols))\n",
    "            \n",
    "#             fig = plt.figure(figsize=(n_cols * 5, n_rows * 3.5))\n",
    "#             fig.suptitle(f'Image {img_num}', y=0.95, fontsize=12)\n",
    "            \n",
    "#             time_bins = np.arange(100)\n",
    "            \n",
    "#             for neuron_idx in range(n_neurons):\n",
    "#                 ax = fig.add_subplot(n_rows, n_cols, neuron_idx + 1, projection='3d')\n",
    "                \n",
    "#                 for y_pos, date in enumerate(target_dates):\n",
    "#                     if date in img_data:\n",
    "#                         values = img_data[date][neuron_idx, :, 0]\n",
    "                        \n",
    "#                         plot_neuron_3d_fill(ax, time_bins, values, y_pos)\n",
    "                \n",
    "#                 ax.set_xlim(time_bins.min(), time_bins.max())\n",
    "#                 ax.set_ylim(-0.5, len(target_dates) - 0.5)\n",
    "#                 ax.set_zlim(0, np.max([img_data[d][neuron_idx, :, 0].max() for d in target_dates if d in img_data]) * 1.2)\n",
    "                \n",
    "#                 ax.set_yticks([])\n",
    "#                 ax.set_yticklabels([])\n",
    "#                 ax.set_xticks([])\n",
    "#                 ax.set_xticklabels([])\n",
    "#                 ax.set_zticks([])\n",
    "#                 ax.set_zticklabels([])\n",
    "\n",
    "                \n",
    "#                 ax.set_title(f'Neuron {neuron_idx + 1}', fontsize=9, pad=8)\n",
    "#                 ax.grid(False)\n",
    "#                 ax.set_box_aspect((1, 2.1, 0.9))\n",
    "#                 ax.view_init(elev=35, azim=-60)\n",
    "#                 ax.set_facecolor('white')\n",
    "#                 ax.xaxis.pane.set_edgecolor('white')\n",
    "#                 ax.yaxis.pane.set_edgecolor('white')\n",
    "#                 ax.zaxis.pane.set_edgecolor('white')\n",
    "                \n",
    "#                 ax.xaxis.pane.fill = False\n",
    "#                 ax.yaxis.pane.fill = False\n",
    "#                 ax.zaxis.pane.fill = False\n",
    "                \n",
    "#                 ax.xaxis.line.set_color((1.0, 1.0, 1.0, 0.0))\n",
    "#                 ax.yaxis.line.set_color((1.0, 1.0, 1.0, 0.0))\n",
    "#                 ax.zaxis.line.set_color((1.0, 1.0, 1.0, 0.0))\n",
    "                \n",
    "#                 ax.set_facecolor('white')\n",
    "#                 fig.patch.set_facecolor('white')\n",
    "                \n",
    "#                 ax.set_xticks([])\n",
    "#                 ax.set_zticks([])\n",
    "            \n",
    "#             plt.tight_layout()\n",
    "#             pdf.savefig(fig, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "#             plt.close()\n",
    "            \n",
    "\n",
    "# generate_filled_pdf_improved(image_mean_spike_rate_data, ['021322', '022522', '042422', '062422', '082322', '102122', '122022', '042323'], \"/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/neural_response_3d_month1_8.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed4c9bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理 18456 个trials...\n",
      "Progress: 0/18456\n",
      "Progress: 5000/18456\n",
      "Progress: 10000/18456\n",
      "Progress: 15000/18456\n"
     ]
    }
   ],
   "source": [
    "# 优化版本3: 最简单但高效的版本 - 减少重复计算\n",
    "spike_inf['date'] = spike_inf['date'].astype(int)\n",
    "\n",
    "def process_trials_efficient(trigger_time, spike_inf, gk):\n",
    "    spike_grouped = spike_inf.groupby(['Neuron', 'date'])\n",
    "    \n",
    "    spike_dict = {}\n",
    "    for (neuron, date), group in spike_grouped:\n",
    "        key = (neuron, date)\n",
    "        spike_dict[key] = group['time'].values\n",
    "    \n",
    "    trial_spike_rate_data_efficient = []\n",
    "    unique_neurons = spike_inf['Neuron'].unique()\n",
    "    \n",
    "    print(f\"处理 {len(trigger_time)} 个trials...\")\n",
    "    for idx, (_, row) in enumerate(trigger_time.iterrows()):\n",
    "        if idx % 5000 == 0:\n",
    "            print(f\"Progress: {idx}/{len(trigger_time)}\")\n",
    "            \n",
    "        start = row['start']\n",
    "        end = row['end'] + 5000\n",
    "        date = row['date']\n",
    "        \n",
    "        neuron_data = []\n",
    "        \n",
    "        for neuron in unique_neurons:\n",
    "            key = (neuron, date)\n",
    "            if key in spike_dict:\n",
    "                neuron_times = spike_dict[key]\n",
    "                valid_spikes = neuron_times[(neuron_times >= start) & (neuron_times <= end)]\n",
    "            else:\n",
    "                valid_spikes = np.array([])\n",
    "            \n",
    "            if len(valid_spikes) == 0:\n",
    "                rates = np.zeros(40)\n",
    "            else:\n",
    "                relative_spikes = (valid_spikes - start) / 10\n",
    "                temp_spiketrain = neo.SpikeTrain(relative_spikes.astype(int) * ms, t_stop=1000, t_start=0)\n",
    "                rates = instantaneous_rate(temp_spiketrain, kernel=gk, sampling_period=25*ms).magnitude.flatten()\n",
    "            neuron_data.append(rates)\n",
    "        \n",
    "        trial_data = np.stack(neuron_data)\n",
    "        trial_spike_rate_data_efficient.append(trial_data)\n",
    "    \n",
    "    \n",
    "    return trial_spike_rate_data_efficient\n",
    "\n",
    "gk = GaussianKernel(50 * ms)\n",
    "trial_spike_rate_data_efficient = process_trials_efficient(trigger_time, spike_inf, gk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2560036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_date = list(trigger_time['date'])\n",
    "trial_image = list(trigger_time['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9c27216",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/data_for_train/mouse6/trial_spike_rate_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(trial_spike_rate_data_efficient, f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/data_for_train/mouse6/trial_date.pkl\", 'wb') as f:\n",
    "    pickle.dump(trial_date, f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/data_for_train/mouse6/trial_image.pkl\", 'wb') as f:\n",
    "    pickle.dump(trial_image, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba511a45",
   "metadata": {},
   "source": [
    "- Mouse5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2498e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_order = ['030222', '042422', '052322', '062322', '082422', \n",
    "              '092222', '102522', '112822', '122322', \n",
    "              '012123', '022423', '032323', '042323', '052423', '062323', '072123']\n",
    "date_order_num = [int(i) for i in date_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e61359d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/data/paper_architecture/01_closed_loop/mouse5/pkl/cluster_072123.pkl\", \"rb\") as f:\n",
    "    cluster_inf = pickle.load(f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/data/paper_architecture/01_closed_loop/mouse5/pkl/spike_072123.pkl\", 'rb') as f:\n",
    "    spike_inf = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "799c1a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2040767/1417255880.py:17: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:17: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:17: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:17: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:28: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend().remove()\n",
      "/tmp/ipykernel_2040767/1417255880.py:55: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:55: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:55: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:55: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:66: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend().remove()\n",
      "/tmp/ipykernel_2040767/1417255880.py:74: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:74: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:74: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:74: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:85: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend().remove()\n",
      "/tmp/ipykernel_2040767/1417255880.py:93: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:93: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:93: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:93: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/1417255880.py:104: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend().remove()\n"
     ]
    }
   ],
   "source": [
    "date_markers = {\n",
    "    '030222': 'o',\n",
    "    '062322': 's',\n",
    "    '102522': 'D',\n",
    "    '072123': '^'\n",
    "}\n",
    "\n",
    "unique_neurons = cluster_inf['Neuron'].unique()\n",
    "palette = sns.color_palette('tab10', len(unique_neurons))\n",
    "neuron_colors = {neuron: color for neuron, color in zip(unique_neurons, palette)}\n",
    "\n",
    "with PdfPages('/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/probe_group_view_mouse5.pdf') as pdf:\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '1']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {1}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(-10, 60)\n",
    "    ax.set_ylim(-10, 110)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '2']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {2}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(140, 210)\n",
    "    ax.set_ylim(190, 310)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '3']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {3}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(240, 360)\n",
    "    ax.set_ylim(390, 510)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '4']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {4}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(440, 510)\n",
    "    ax.set_ylim(190, 310)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '5']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {5}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(590, 660)\n",
    "    ax.set_ylim(-10, 110)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60a7ddbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n",
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n",
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n",
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n",
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n"
     ]
    }
   ],
   "source": [
    "displacement_df_position_1 = pd.DataFrame()\n",
    "displacement_df_position_2 = pd.DataFrame()\n",
    "\n",
    "for neuron in cluster_inf['Neuron'].unique():\n",
    "    temp = cluster_inf[cluster_inf['Neuron'] == neuron]\n",
    "    displacement_1 = []\n",
    "    displacement_2 = []\n",
    "    for date in date_order:\n",
    "        displacement_1.append(temp[temp['date'] == date]['position_1'].values.mean() - temp[temp['date'] == '030222']['position_1'].values.mean())\n",
    "        displacement_2.append(temp[temp['date'] == date]['position_2'].values.mean() - temp[temp['date'] == '030222']['position_2'].values.mean())\n",
    "    displacement_df_position_1[neuron] = displacement_1\n",
    "    displacement_df_position_2[neuron] = displacement_2\n",
    "\n",
    "months_to_plot = [2, 6, 8, 12, 15]  \n",
    "n_months = len(months_to_plot)\n",
    "\n",
    "colors = sns.color_palette(\"viridis\", n_colors=n_months)\n",
    "\n",
    "with PdfPages('/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/displacement_kde_mouse5.pdf') as pdf:\n",
    "    for idx, m in enumerate(months_to_plot):\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        ax.plot(0, 0, 'ko', markersize=8, zorder=10)  \n",
    "        data_month = pd.concat((\n",
    "            displacement_df_position_1.iloc[m-1, :], \n",
    "            displacement_df_position_2.iloc[m-1, :]), axis=1)\n",
    "        \n",
    "        sns.kdeplot(\n",
    "            x = displacement_df_position_1.iloc[m-1, :],\n",
    "            y=displacement_df_position_2.iloc[m-1, :],\n",
    "            ax=ax,\n",
    "            linewidth=1.5,\n",
    "            fill=False,  \n",
    "            label=f'Month {m}',\n",
    "            thresh=0.25,\n",
    "            levels=6,\n",
    "            common_norm=False  \n",
    "        )\n",
    "\n",
    "        ax.set_xlabel('Position Value', fontsize=12)\n",
    "        ax.set_ylabel('Density', fontsize=12)\n",
    "        ax.set_ylim(-10, 10)\n",
    "        ax.set_xlim(-10, 10)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e113216",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_groups = cluster_inf.groupby('date')\n",
    "result_matrix = {}\n",
    "\n",
    "for date, group in date_groups:\n",
    "    neurons = group.set_index('Neuron')[['position_1', 'position_2']]\n",
    "    neuron_list = sorted(neurons.index.unique())\n",
    "    n = len(neuron_list)\n",
    "    \n",
    "    dist_matrix = np.zeros((n, n), dtype=float)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                dist_matrix[i][j] = 0 \n",
    "            else:\n",
    "                pos_i = neurons.loc[neuron_list[i]]\n",
    "                pos_j = neurons.loc[neuron_list[j]]\n",
    "                dist = np.sqrt((pos_i['position_1'].mean()-pos_j['position_1'].mean())**2 + (pos_i['position_2'].mean()-pos_j['position_2'].mean())**2)\n",
    "                dist_matrix[i][j] = dist\n",
    "    \n",
    "    result_matrix[date] = pd.DataFrame(dist_matrix, index=neuron_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f090d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacement_dict = {}\n",
    "for probe in cluster_inf['probe_group']:\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == probe]\n",
    "    month_groups = temp.groupby('date')\n",
    "\n",
    "    month_pairs = [('030222', '042422'),\n",
    "                ('030222', '082422'),\n",
    "                ('030222', '122322'),\n",
    "                ('030222', '032323'),\n",
    "                ('030222', '072123')]\n",
    "\n",
    "    all_neurons = sorted(temp['Neuron'].unique())\n",
    "    n_neurons = len(all_neurons)\n",
    "    n_pairs = len(month_pairs)\n",
    "\n",
    "    distance_matrix = np.full((n_pairs, n_neurons, n_neurons), np.nan)\n",
    "\n",
    "    for pair_idx, (month_a, month_b) in enumerate(month_pairs):\n",
    "        group_a = month_groups.get_group(month_a).set_index('Neuron')[['position_1', 'position_2']]\n",
    "        group_b = month_groups.get_group(month_b).set_index('Neuron')[['position_1', 'position_2']]\n",
    "        \n",
    "        for i, neuron_i in enumerate(all_neurons):\n",
    "            for j, neuron_j in enumerate(all_neurons):\n",
    "                if (neuron_i in group_a.index) and (neuron_j in group_b.index):\n",
    "                    pos_i = group_a.loc[neuron_i]\n",
    "                    pos_j = group_b.loc[neuron_j]\n",
    "                    distance = np.sqrt((pos_i['position_1'].mean()-pos_j['position_1'].mean())**2 + (pos_i['position_2'].mean()-pos_j['position_2'].mean())**2)\n",
    "                    distance_matrix[pair_idx, i, j] = distance\n",
    "    displacement_dict[probe] = distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "132089f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/hist_displacement_mouse5.pdf\") as pdf:\n",
    "    for month in range(5):\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        df_1 = []\n",
    "        df_2 = []\n",
    "\n",
    "        for probe in displacement_dict.keys():\n",
    "            df_1.append([displacement_dict[probe][month, i, i] for i in range(displacement_dict[probe].shape[1])])\n",
    "            df_2.append(displacement_dict[probe].flatten())\n",
    "\n",
    "        df_1 = flattened_list = np.concatenate(df_1)\n",
    "        df_2 = flattened_list = np.concatenate(df_2)\n",
    "        sns.ecdfplot(df_1, color='#2980b9', label='Within-neuron displacement', linewidth=2, ax=ax)\n",
    "        sns.ecdfplot(df_2, color='orange', label='Across-neuron displacement', linewidth=2, ax=ax)\n",
    "\n",
    "        ax.spines['top'].set_visible(False) \n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_linewidth(1.5)  \n",
    "        ax.spines['bottom'].set_linewidth(1.5)\n",
    "        pdf.savefig()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa1ac899",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_time = pd.read_csv(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/trigger/trigger_time_mouse5.tsv\", sep = '\\t').iloc[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27eec304",
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_dict = {}\n",
    "correlation_dict = {}\n",
    "\n",
    "for date in spike_inf['date'].unique():\n",
    "    spike_inf_temp = spike_inf[spike_inf['date'] == date]\n",
    "    firing_rate_dict[date] = {}\n",
    "    trigger_time_temp = trigger_time[trigger_time['date'] == int(date)]\n",
    "    for image in trigger_time_temp['image'].unique():\n",
    "        firing_rate_dict[date][image] = pd.DataFrame()\n",
    "        trigger_time_temp_temp = trigger_time_temp[trigger_time_temp['image'] == image]\n",
    "        for image_order in trigger_time_temp_temp['order'].sort_index().values.tolist():\n",
    "            trigger_time_temp_temp_temp = trigger_time_temp_temp[trigger_time_temp_temp['order'] == image_order]\n",
    "            temp = spike_inf_temp[(spike_inf_temp['time'] > int(trigger_time_temp_temp_temp['start'].values)) & (spike_inf_temp['time'] < int(trigger_time_temp_temp_temp['end'].values))]\n",
    "            firing_rate_dict[date][image] = pd.concat((firing_rate_dict[date][image], pd.DataFrame(temp['Neuron'].value_counts()).sort_index()), axis=1)\n",
    "        firing_rate_dict[date][image] = firing_rate_dict[date][image].fillna(0)\n",
    "\n",
    "    correlation_dict[date] = {}\n",
    "    for key in sorted(list(firing_rate_dict[date].keys())):\n",
    "        num = firing_rate_dict[date][key].shape[1]\n",
    "        correlation_dict[date][key] = np.zeros((num, num))\n",
    "        for i in range(num):\n",
    "            for j in range(num):\n",
    "                correlation_dict[date][key][i, j], _ = pearsonr(firing_rate_dict[date][key].iloc[:, i].values.tolist(), firing_rate_dict[date][key].iloc[:, j].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "816b4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_mean = pd.DataFrame()\n",
    "for date in correlation_dict.keys():\n",
    "    temp = []\n",
    "    for image, df in correlation_dict[date].items():\n",
    "        df = df.mean().mean()\n",
    "        temp.append(df)\n",
    "    correlation_mean = pd.concat((correlation_mean, pd.DataFrame(temp, columns=[date])),axis=1)\n",
    "\n",
    "correlation_mean = correlation_mean[date_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ba88d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理 19305 个trials...\n",
      "Progress: 0/19305\n",
      "Progress: 5000/19305\n",
      "Progress: 10000/19305\n",
      "Progress: 15000/19305\n"
     ]
    }
   ],
   "source": [
    "# 优化版本3: 最简单但高效的版本 - 减少重复计算\n",
    "spike_inf['date'] = spike_inf['date'].astype(int)\n",
    "\n",
    "def process_trials_efficient(trigger_time, spike_inf, gk):\n",
    "    spike_grouped = spike_inf.groupby(['Neuron', 'date'])\n",
    "    \n",
    "    spike_dict = {}\n",
    "    for (neuron, date), group in spike_grouped:\n",
    "        key = (neuron, date)\n",
    "        spike_dict[key] = group['time'].values\n",
    "    \n",
    "    trial_spike_rate_data_efficient = []\n",
    "    unique_neurons = spike_inf['Neuron'].unique()\n",
    "    \n",
    "    print(f\"处理 {len(trigger_time)} 个trials...\")\n",
    "    for idx, (_, row) in enumerate(trigger_time.iterrows()):\n",
    "        if idx % 5000 == 0:\n",
    "            print(f\"Progress: {idx}/{len(trigger_time)}\")\n",
    "            \n",
    "        start = row['start']\n",
    "        end = row['end'] + 5000\n",
    "        date = row['date']\n",
    "        \n",
    "        neuron_data = []\n",
    "        \n",
    "        for neuron in unique_neurons:\n",
    "            key = (neuron, date)\n",
    "            if key in spike_dict:\n",
    "                neuron_times = spike_dict[key]\n",
    "                valid_spikes = neuron_times[(neuron_times >= start) & (neuron_times <= end)]\n",
    "            else:\n",
    "                valid_spikes = np.array([])\n",
    "            \n",
    "            if len(valid_spikes) == 0:\n",
    "                rates = np.zeros(40)\n",
    "            else:\n",
    "                relative_spikes = (valid_spikes - start) / 10\n",
    "                temp_spiketrain = neo.SpikeTrain(relative_spikes.astype(int) * ms, t_stop=1000, t_start=0)\n",
    "                rates = instantaneous_rate(temp_spiketrain, kernel=gk, sampling_period=25*ms).magnitude.flatten()\n",
    "            neuron_data.append(rates)\n",
    "        \n",
    "        trial_data = np.stack(neuron_data)\n",
    "        trial_spike_rate_data_efficient.append(trial_data)\n",
    "    \n",
    "    \n",
    "    return trial_spike_rate_data_efficient\n",
    "\n",
    "gk = GaussianKernel(50 * ms)\n",
    "trial_spike_rate_data_efficient = process_trials_efficient(trigger_time, spike_inf, gk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "413abc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_date = list(trigger_time['date'])\n",
    "trial_image = list(trigger_time['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff6832c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/data_for_train/mouse5/trial_spike_rate_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(trial_spike_rate_data_efficient, f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/data_for_train/mouse5/trial_date.pkl\", 'wb') as f:\n",
    "    pickle.dump(trial_date, f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/data_for_train/mouse5/trial_image.pkl\", 'wb') as f:\n",
    "    pickle.dump(trial_image, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54078274",
   "metadata": {},
   "source": [
    "- Mouse11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b0983f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_order = ['021722', '030122', '032322', '042322', '052322', '052422', \n",
    "              '062422', '072422', '082422', '092222', '102522', '112822', '122322', '012123', \n",
    "              '022423', '032323', '042323', '052423', '062323', '072123']\n",
    "date_order_num = [int(i) for i in date_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5240460",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/data/paper_architecture/01_closed_loop/mouse11/pkl/cluster_072123.pkl\", \"rb\") as f:\n",
    "    cluster_inf = pickle.load(f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/data/paper_architecture/01_closed_loop/mouse11/pkl/spike_072123.pkl\", 'rb') as f:\n",
    "    spike_inf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3af2b40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2040767/896860880.py:17: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/896860880.py:17: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/896860880.py:17: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/896860880.py:17: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.scatterplot(\n",
      "/tmp/ipykernel_2040767/896860880.py:28: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend().remove()\n"
     ]
    }
   ],
   "source": [
    "date_markers = {\n",
    "    '021722': 'o',\n",
    "    '052422': 's',\n",
    "    '112822': 'D',\n",
    "    '072123': '^'\n",
    "}\n",
    "\n",
    "unique_neurons = cluster_inf['Neuron'].unique()\n",
    "palette = sns.color_palette('tab10', len(unique_neurons))\n",
    "neuron_colors = {neuron: color for neuron, color in zip(unique_neurons, palette)}\n",
    "\n",
    "with PdfPages('/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/probe_group_view_mouse11.pdf') as pdf:\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '1']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {1}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(-10, 60)\n",
    "    ax.set_ylim(-10, 110)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '2']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {2}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(140, 210)\n",
    "    ax.set_ylim(190, 310)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '3']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {3}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(240, 360)\n",
    "    ax.set_ylim(390, 510)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '4']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {4}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(440, 510)\n",
    "    ax.set_ylim(190, 310)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '5']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {5}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(590, 660)\n",
    "    ax.set_ylim(-10, 110)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f72c0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n",
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n",
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n",
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n",
      "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/seaborn/distributions.py:1176: UserWarning: The following kwargs were not used by contour: 'linewidth'\n",
      "  cset = contour_func(\n"
     ]
    }
   ],
   "source": [
    "displacement_df_position_1 = pd.DataFrame()\n",
    "displacement_df_position_2 = pd.DataFrame()\n",
    "\n",
    "for neuron in cluster_inf['Neuron'].unique():\n",
    "    temp = cluster_inf[cluster_inf['Neuron'] == neuron]\n",
    "    displacement_1 = []\n",
    "    displacement_2 = []\n",
    "    for date in date_order:\n",
    "        displacement_1.append(temp[temp['date'] == date]['position_1'].values.mean() - temp[temp['date'] == '021722']['position_1'].values.mean())\n",
    "        displacement_2.append(temp[temp['date'] == date]['position_2'].values.mean() - temp[temp['date'] == '021722']['position_2'].values.mean())\n",
    "    displacement_df_position_1[neuron] = displacement_1\n",
    "    displacement_df_position_2[neuron] = displacement_2\n",
    "\n",
    "months_to_plot = [2, 6, 8, 12, 15]  \n",
    "n_months = len(months_to_plot)\n",
    "\n",
    "colors = sns.color_palette(\"viridis\", n_colors=n_months)\n",
    "\n",
    "with PdfPages('/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/displacement_kde_mouse11.pdf') as pdf:\n",
    "    for idx, m in enumerate(months_to_plot):\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        ax.plot(0, 0, 'ko', markersize=8, zorder=10)  \n",
    "        data_month = pd.concat((\n",
    "            displacement_df_position_1.iloc[m-1, :], \n",
    "            displacement_df_position_2.iloc[m-1, :]), axis=1)\n",
    "        \n",
    "        sns.kdeplot(\n",
    "            x = displacement_df_position_1.iloc[m-1, :],\n",
    "            y=displacement_df_position_2.iloc[m-1, :],\n",
    "            ax=ax,\n",
    "            linewidth=1.5,\n",
    "            fill=False,  \n",
    "            label=f'Month {m}',\n",
    "            thresh=0.25,\n",
    "            levels=6,\n",
    "            common_norm=False  \n",
    "        )\n",
    "\n",
    "        ax.set_xlabel('Position Value', fontsize=12)\n",
    "        ax.set_ylabel('Density', fontsize=12)\n",
    "        ax.set_ylim(-10, 10)\n",
    "        ax.set_xlim(-10, 10)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7dfd7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_groups = cluster_inf.groupby('date')\n",
    "result_matrix = {}\n",
    "\n",
    "for date, group in date_groups:\n",
    "    neurons = group.set_index('Neuron')[['position_1', 'position_2']]\n",
    "    neuron_list = sorted(neurons.index.unique())\n",
    "    n = len(neuron_list)\n",
    "    \n",
    "    dist_matrix = np.zeros((n, n), dtype=float)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                dist_matrix[i][j] = 0 \n",
    "            else:\n",
    "                pos_i = neurons.loc[neuron_list[i]]\n",
    "                pos_j = neurons.loc[neuron_list[j]]\n",
    "                dist = np.sqrt((pos_i['position_1'].mean()-pos_j['position_1'].mean())**2 + (pos_i['position_2'].mean()-pos_j['position_2'].mean())**2)\n",
    "                dist_matrix[i][j] = dist\n",
    "    \n",
    "    result_matrix[date] = pd.DataFrame(dist_matrix, index=neuron_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dcbf506",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacement_dict = {}\n",
    "for probe in cluster_inf['probe_group']:\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == probe]\n",
    "    month_groups = temp.groupby('date')\n",
    "\n",
    "    month_pairs = [('021722', '052422'),\n",
    "                ('021722', '102522'),\n",
    "                ('021722', '012123'),\n",
    "                ('021722', '042323'),\n",
    "                ('021722', '072123')]\n",
    "\n",
    "    all_neurons = sorted(temp['Neuron'].unique())\n",
    "    n_neurons = len(all_neurons)\n",
    "    n_pairs = len(month_pairs)\n",
    "\n",
    "    distance_matrix = np.full((n_pairs, n_neurons, n_neurons), np.nan)\n",
    "\n",
    "    for pair_idx, (month_a, month_b) in enumerate(month_pairs):\n",
    "        group_a = month_groups.get_group(month_a).set_index('Neuron')[['position_1', 'position_2']]\n",
    "        group_b = month_groups.get_group(month_b).set_index('Neuron')[['position_1', 'position_2']]\n",
    "        \n",
    "        for i, neuron_i in enumerate(all_neurons):\n",
    "            for j, neuron_j in enumerate(all_neurons):\n",
    "                if (neuron_i in group_a.index) and (neuron_j in group_b.index):\n",
    "                    pos_i = group_a.loc[neuron_i]\n",
    "                    pos_j = group_b.loc[neuron_j]\n",
    "                    distance = np.sqrt((pos_i['position_1'].mean()-pos_j['position_1'].mean())**2 + (pos_i['position_2'].mean()-pos_j['position_2'].mean())**2)\n",
    "                    distance_matrix[pair_idx, i, j] = distance\n",
    "    displacement_dict[probe] = distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41f9a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/hist_displacement_mouse11.pdf\") as pdf:\n",
    "    for month in range(5):\n",
    "        fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        df_1 = []\n",
    "        df_2 = []\n",
    "\n",
    "        for probe in displacement_dict.keys():\n",
    "            df_1.append([displacement_dict[probe][month, i, i] for i in range(displacement_dict[probe].shape[1])])\n",
    "            df_2.append(displacement_dict[probe].flatten())\n",
    "\n",
    "        df_1 = flattened_list = np.concatenate(df_1)\n",
    "        df_2 = flattened_list = np.concatenate(df_2)\n",
    "        sns.ecdfplot(df_1, color='#2980b9', label='Within-neuron displacement', linewidth=2, ax=ax)\n",
    "        sns.ecdfplot(df_2, color='orange', label='Across-neuron displacement', linewidth=2, ax=ax)\n",
    "\n",
    "        ax.spines['top'].set_visible(False) \n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_linewidth(1.5)  \n",
    "        ax.spines['bottom'].set_linewidth(1.5)\n",
    "        pdf.savefig()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86acce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_time = pd.read_csv(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/trigger/trigger_time_mouse11.tsv\", sep = '\\t').iloc[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78205d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_dict = {}\n",
    "correlation_dict = {}\n",
    "\n",
    "for date in spike_inf['date'].unique():\n",
    "    spike_inf_temp = spike_inf[spike_inf['date'] == date]\n",
    "    firing_rate_dict[date] = {}\n",
    "    trigger_time_temp = trigger_time[trigger_time['date'] == int(date)]\n",
    "    for image in trigger_time_temp['image'].unique():\n",
    "        firing_rate_dict[date][image] = pd.DataFrame()\n",
    "        trigger_time_temp_temp = trigger_time_temp[trigger_time_temp['image'] == image]\n",
    "        for image_order in trigger_time_temp_temp['order'].sort_index().values.tolist():\n",
    "            trigger_time_temp_temp_temp = trigger_time_temp_temp[trigger_time_temp_temp['order'] == image_order]\n",
    "            temp = spike_inf_temp[(spike_inf_temp['time'] > int(trigger_time_temp_temp_temp['start'].values)) & (spike_inf_temp['time'] < int(trigger_time_temp_temp_temp['end'].values))]\n",
    "            firing_rate_dict[date][image] = pd.concat((firing_rate_dict[date][image], pd.DataFrame(temp['Neuron'].value_counts()).sort_index()), axis=1)\n",
    "        firing_rate_dict[date][image] = firing_rate_dict[date][image].fillna(0)\n",
    "\n",
    "    correlation_dict[date] = {}\n",
    "    for key in sorted(list(firing_rate_dict[date].keys())):\n",
    "        num = firing_rate_dict[date][key].shape[1]\n",
    "        correlation_dict[date][key] = np.zeros((num, num))\n",
    "        for i in range(num):\n",
    "            for j in range(num):\n",
    "                correlation_dict[date][key][i, j], _ = pearsonr(firing_rate_dict[date][key].iloc[:, i].values.tolist(), firing_rate_dict[date][key].iloc[:, j].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1d1e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_mean = pd.DataFrame()\n",
    "for date in correlation_dict.keys():\n",
    "    temp = []\n",
    "    for image, df in correlation_dict[date].items():\n",
    "        df = df.mean().mean()\n",
    "        temp.append(df)\n",
    "    correlation_mean = pd.concat((correlation_mean, pd.DataFrame(temp, columns=[date])),axis=1)\n",
    "\n",
    "correlation_mean = correlation_mean[date_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d69fb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = []\n",
    "for date in correlation_dict.keys():\n",
    "    for image in range(1, 118):\n",
    "        mean = (correlation_dict[date][image].sum(axis = 0)-1)/(len(correlation_dict[date][image]) - 1)\n",
    "        for i in range(len(mean)):\n",
    "            if mean[i] <= 0.6:\n",
    "                outlier.append(f'{date}_{image}_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a70be6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find 12970 outliers\n"
     ]
    }
   ],
   "source": [
    "print(f\"Find {len(outlier)} outliers\")\n",
    "\n",
    "outlier_set = set(outlier)\n",
    "\n",
    "trigger_time_clean = trigger_time.copy()\n",
    "\n",
    "trigger_time_clean['trial_index'] = trigger_time_clean.groupby(['date', 'image']).cumcount()\n",
    "\n",
    "trigger_time_clean['outlier_id'] = trigger_time_clean['date'].astype(str) + '_' + trigger_time_clean['image'].astype(str) + '_' + trigger_time_clean['trial_index'].astype(str)\n",
    "\n",
    "original_count = len(trigger_time_clean)\n",
    "trigger_time_clean = trigger_time_clean[~trigger_time_clean['outlier_id'].isin(outlier_set)]\n",
    "\n",
    "trigger_time_clean = trigger_time_clean.drop(['trial_index', 'outlier_id'], axis=1)\n",
    "\n",
    "removed_count = original_count - len(trigger_time_clean)\n",
    "\n",
    "trigger_time = trigger_time_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbd891cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/media/ubuntu/sda/data/paper_architecture/02_consistency/outlier_mouse11.pkl', 'wb') as f:\n",
    "    pickle.dump(outlier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f78c7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理 23277 个trials...\n",
      "Progress: 0/23277\n",
      "Progress: 5000/23277\n",
      "Progress: 10000/23277\n",
      "Progress: 15000/23277\n",
      "Progress: 20000/23277\n"
     ]
    }
   ],
   "source": [
    "spike_inf['date'] = spike_inf['date'].astype(int)\n",
    "\n",
    "def process_trials_efficient(trigger_time, spike_inf, gk):\n",
    "    spike_grouped = spike_inf.groupby(['Neuron', 'date'])\n",
    "    \n",
    "    spike_dict = {}\n",
    "    for (neuron, date), group in spike_grouped:\n",
    "        key = (neuron, date)\n",
    "        spike_dict[key] = group['time'].values\n",
    "    \n",
    "    trial_spike_rate_data_efficient = []\n",
    "    unique_neurons = spike_inf['Neuron'].unique()\n",
    "    \n",
    "    print(f\"处理 {len(trigger_time)} 个trials...\")\n",
    "    for idx, (_, row) in enumerate(trigger_time.iterrows()):\n",
    "        if idx % 5000 == 0:\n",
    "            print(f\"Progress: {idx}/{len(trigger_time)}\")\n",
    "            \n",
    "        start = row['start']\n",
    "        end = row['end'] + 5000\n",
    "        date = row['date']\n",
    "        \n",
    "        neuron_data = []\n",
    "        \n",
    "        for neuron in unique_neurons:\n",
    "            key = (neuron, date)\n",
    "            if key in spike_dict:\n",
    "                neuron_times = spike_dict[key]\n",
    "                valid_spikes = neuron_times[(neuron_times >= start) & (neuron_times <= end)]\n",
    "            else:\n",
    "                valid_spikes = np.array([])\n",
    "            \n",
    "            if len(valid_spikes) == 0:\n",
    "                rates = np.zeros(40)\n",
    "            else:\n",
    "                relative_spikes = (valid_spikes - start) / 10\n",
    "                temp_spiketrain = neo.SpikeTrain(relative_spikes.astype(int) * ms, t_stop=1000, t_start=0)\n",
    "                rates = instantaneous_rate(temp_spiketrain, kernel=gk, sampling_period=25*ms).magnitude.flatten()\n",
    "            neuron_data.append(rates)\n",
    "        \n",
    "        trial_data = np.stack(neuron_data)\n",
    "        trial_spike_rate_data_efficient.append(trial_data)\n",
    "    \n",
    "    \n",
    "    return trial_spike_rate_data_efficient\n",
    "\n",
    "gk = GaussianKernel(50 * ms)\n",
    "trial_spike_rate_data_efficient = process_trials_efficient(trigger_time, spike_inf, gk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cce68df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_date = list(trigger_time['date'])\n",
    "trial_image = list(trigger_time['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abde5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/data_for_train/mouse11/trial_spike_rate_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(trial_spike_rate_data_efficient, f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/data_for_train/mouse11/trial_date.pkl\", 'wb') as f:\n",
    "    pickle.dump(trial_date, f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/data_for_train/mouse11/trial_image.pkl\", 'wb') as f:\n",
    "    pickle.dump(trial_image, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab904f",
   "metadata": {},
   "source": [
    "- mouse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5b36002",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_order = ['031722', '042322', '052322', '062422', '072322', '082322', \n",
    "              '092222', '102522', '112822', '122022', '012123', '022223']\n",
    "date_order_num = [int(i) for i in date_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db785c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/data/paper_architecture/01_closed_loop/mouse2/pkl/cluster_022223.pkl\", \"rb\") as f:\n",
    "    cluster_inf = pickle.load(f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/data/paper_architecture/01_closed_loop/mouse2/pkl/spike_022223.pkl\", 'rb') as f:\n",
    "    spike_inf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "370e9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_markers = {\n",
    "    '031722': 'o',\n",
    "    '062422': 's',\n",
    "    '102522': 'D',\n",
    "    '022223': '^'\n",
    "}\n",
    "\n",
    "unique_neurons = cluster_inf['Neuron'].unique()\n",
    "palette = sns.color_palette('tab10', len(unique_neurons))\n",
    "neuron_colors = {neuron: color for neuron, color in zip(unique_neurons, palette)}\n",
    "\n",
    "with PdfPages('/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/probe_group_view_mouse2.pdf') as pdf:\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '1']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {1}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(-10, 60)\n",
    "    ax.set_ylim(-10, 110)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '2']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {2}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(140, 210)\n",
    "    ax.set_ylim(190, 310)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '3']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {3}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(240, 360)\n",
    "    ax.set_ylim(390, 510)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '4']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {4}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(440, 510)\n",
    "    ax.set_ylim(190, 310)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "    temp = cluster_inf[cluster_inf['probe_group'] == '5']\n",
    "    fig, ax = plt.subplots(figsize=(3, 5))\n",
    "    for date, marker in date_markers.items():\n",
    "        date_data = temp[temp['date'] == date]\n",
    "        sns.scatterplot(\n",
    "            x='position_1', y='position_2', hue='Neuron', style='date',\n",
    "            markers={date: marker}, data=date_data, ax=ax, palette=neuron_colors, s=300\n",
    "        )\n",
    "    ax.set_title(f'Probe Group: {5}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.set_xlim(590, 660)\n",
    "    ax.set_ylim(-10, 110)\n",
    "    ax.legend().remove()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29529fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displacement_df_position_1 = pd.DataFrame()\n",
    "# displacement_df_position_2 = pd.DataFrame()\n",
    "\n",
    "# for neuron in cluster_inf['Neuron'].unique():\n",
    "#     temp = cluster_inf[cluster_inf['Neuron'] == neuron]\n",
    "#     displacement_1 = []\n",
    "#     displacement_2 = []\n",
    "#     for date in date_order:\n",
    "#         displacement_1.append(temp[temp['date'] == date]['position_1'].values.mean() - temp[temp['date'] == '031722']['position_1'].values.mean())\n",
    "#         displacement_2.append(temp[temp['date'] == date]['position_2'].values.mean() - temp[temp['date'] == '031722']['position_2'].values.mean())\n",
    "#     displacement_df_position_1[neuron] = displacement_1\n",
    "#     displacement_df_position_2[neuron] = displacement_2\n",
    "\n",
    "# months_to_plot = [2, 6, 8, 12, 15]  \n",
    "# n_months = len(months_to_plot)\n",
    "\n",
    "# colors = sns.color_palette(\"viridis\", n_colors=n_months)\n",
    "\n",
    "# with PdfPages('/media/ubuntu/sda/data/paper_architecture/02_consistency/figure/displacement_kde_mouse2.pdf') as pdf:\n",
    "#     for idx, m in enumerate(months_to_plot):\n",
    "#         fig, ax = plt.subplots(figsize=(5, 5))\n",
    "#         ax.plot(0, 0, 'ko', markersize=8, zorder=10)  \n",
    "#         data_month = pd.concat((\n",
    "#             displacement_df_position_1.iloc[m-1, :], \n",
    "#             displacement_df_position_2.iloc[m-1, :]), axis=1)\n",
    "        \n",
    "#         sns.kdeplot(\n",
    "#             x = displacement_df_position_1.iloc[m-1, :],\n",
    "#             y=displacement_df_position_2.iloc[m-1, :],\n",
    "#             ax=ax,\n",
    "#             linewidth=1.5,\n",
    "#             fill=False,  \n",
    "#             label=f'Month {m}',\n",
    "#             thresh=0.25,\n",
    "#             levels=6,\n",
    "#             common_norm=False  \n",
    "#         )\n",
    "\n",
    "#         ax.set_xlabel('Position Value', fontsize=12)\n",
    "#         ax.set_ylabel('Density', fontsize=12)\n",
    "#         ax.set_ylim(-10, 10)\n",
    "#         ax.set_xlim(-10, 10)\n",
    "#         ax.spines['top'].set_visible(False)\n",
    "#         ax.spines['right'].set_visible(False)\n",
    "#         ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         pdf.savefig()\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f3cc8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_groups = cluster_inf.groupby('date')\n",
    "result_matrix = {}\n",
    "\n",
    "for date, group in date_groups:\n",
    "    neurons = group.set_index('Neuron')[['position_1', 'position_2']]\n",
    "    neuron_list = sorted(neurons.index.unique())\n",
    "    n = len(neuron_list)\n",
    "    \n",
    "    dist_matrix = np.zeros((n, n), dtype=float)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                dist_matrix[i][j] = 0 \n",
    "            else:\n",
    "                pos_i = neurons.loc[neuron_list[i]]\n",
    "                pos_j = neurons.loc[neuron_list[j]]\n",
    "                dist = np.sqrt((pos_i['position_1'].mean()-pos_j['position_1'].mean())**2 + (pos_i['position_2'].mean()-pos_j['position_2'].mean())**2)\n",
    "                dist_matrix[i][j] = dist\n",
    "    \n",
    "    result_matrix[date] = pd.DataFrame(dist_matrix, index=neuron_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "708fa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_time = pd.read_csv(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/trigger/trigger_time_mouse2.tsv\", sep = '\\t').iloc[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "201dd8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "firing_rate_dict = {}\n",
    "correlation_dict = {}\n",
    "\n",
    "for date in spike_inf['date'].unique():\n",
    "    spike_inf_temp = spike_inf[spike_inf['date'] == date]\n",
    "    firing_rate_dict[date] = {}\n",
    "    trigger_time_temp = trigger_time[trigger_time['date'] == int(date)]\n",
    "    for image in trigger_time_temp['image'].unique():\n",
    "        firing_rate_dict[date][image] = pd.DataFrame()\n",
    "        trigger_time_temp_temp = trigger_time_temp[trigger_time_temp['image'] == image]\n",
    "        for image_order in trigger_time_temp_temp['order'].sort_index().values.tolist():\n",
    "            trigger_time_temp_temp_temp = trigger_time_temp_temp[trigger_time_temp_temp['order'] == image_order]\n",
    "            temp = spike_inf_temp[(spike_inf_temp['time'] > int(trigger_time_temp_temp_temp['start'].values)) & (spike_inf_temp['time'] < int(trigger_time_temp_temp_temp['end'].values))]\n",
    "            firing_rate_dict[date][image] = pd.concat((firing_rate_dict[date][image], pd.DataFrame(temp['Neuron'].value_counts()).sort_index()), axis=1)\n",
    "        firing_rate_dict[date][image] = firing_rate_dict[date][image].fillna(0)\n",
    "\n",
    "    correlation_dict[date] = {}\n",
    "    for key in sorted(list(firing_rate_dict[date].keys())):\n",
    "        num = firing_rate_dict[date][key].shape[1]\n",
    "        correlation_dict[date][key] = np.zeros((num, num))\n",
    "        for i in range(num):\n",
    "            for j in range(num):\n",
    "                correlation_dict[date][key][i, j], _ = pearsonr(firing_rate_dict[date][key].iloc[:, i].values.tolist(), firing_rate_dict[date][key].iloc[:, j].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f30a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_mean = pd.DataFrame()\n",
    "for date in correlation_dict.keys():\n",
    "    temp = []\n",
    "    for image, df in correlation_dict[date].items():\n",
    "        df = df.mean().mean()\n",
    "        temp.append(df)\n",
    "    correlation_mean = pd.concat((correlation_mean, pd.DataFrame(temp, columns=[date])),axis=1)\n",
    "\n",
    "correlation_mean = correlation_mean[date_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbf3e592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理 14040 个trials...\n",
      "Progress: 0/14040\n",
      "Progress: 5000/14040\n",
      "Progress: 10000/14040\n"
     ]
    }
   ],
   "source": [
    "spike_inf['date'] = spike_inf['date'].astype(int)\n",
    "\n",
    "def process_trials_efficient(trigger_time, spike_inf, gk):\n",
    "    spike_grouped = spike_inf.groupby(['Neuron', 'date'])\n",
    "    \n",
    "    spike_dict = {}\n",
    "    for (neuron, date), group in spike_grouped:\n",
    "        key = (neuron, date)\n",
    "        spike_dict[key] = group['time'].values\n",
    "    \n",
    "    trial_spike_rate_data_efficient = []\n",
    "    unique_neurons = spike_inf['Neuron'].unique()\n",
    "    \n",
    "    print(f\"处理 {len(trigger_time)} 个trials...\")\n",
    "    for idx, (_, row) in enumerate(trigger_time.iterrows()):\n",
    "        if idx % 5000 == 0:\n",
    "            print(f\"Progress: {idx}/{len(trigger_time)}\")\n",
    "            \n",
    "        start = row['start']\n",
    "        end = row['end'] + 5000\n",
    "        date = row['date']\n",
    "        \n",
    "        neuron_data = []\n",
    "        \n",
    "        for neuron in unique_neurons:\n",
    "            key = (neuron, date)\n",
    "            if key in spike_dict:\n",
    "                neuron_times = spike_dict[key]\n",
    "                valid_spikes = neuron_times[(neuron_times >= start) & (neuron_times <= end)]\n",
    "            else:\n",
    "                valid_spikes = np.array([])\n",
    "            \n",
    "            if len(valid_spikes) == 0:\n",
    "                rates = np.zeros(40)\n",
    "            else:\n",
    "                relative_spikes = (valid_spikes - start) / 10\n",
    "                temp_spiketrain = neo.SpikeTrain(relative_spikes.astype(int) * ms, t_stop=1000, t_start=0)\n",
    "                rates = instantaneous_rate(temp_spiketrain, kernel=gk, sampling_period=25*ms).magnitude.flatten()\n",
    "            neuron_data.append(rates)\n",
    "        \n",
    "        trial_data = np.stack(neuron_data)\n",
    "        trial_spike_rate_data_efficient.append(trial_data)\n",
    "    \n",
    "    \n",
    "    return trial_spike_rate_data_efficient\n",
    "\n",
    "gk = GaussianKernel(50 * ms)\n",
    "trial_spike_rate_data_efficient = process_trials_efficient(trigger_time, spike_inf, gk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d259a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_date = list(trigger_time['date'])\n",
    "trial_image = list(trigger_time['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9626845",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/data_for_train/mouse2/trial_spike_rate_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(trial_spike_rate_data_efficient, f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/data_for_train/mouse2/trial_date.pkl\", 'wb') as f:\n",
    "    pickle.dump(trial_date, f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/data/paper_architecture/02_consistency/data_for_train/mouse2/trial_image.pkl\", 'wb') as f:\n",
    "    pickle.dump(trial_image, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike_sorting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
