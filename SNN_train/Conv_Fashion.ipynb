{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "883b57c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 20:51:29.444847: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-23 20:51:29.472991: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-23 20:51:30.112648: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from spikingjelly.activation_based import neuron, functional, surrogate, layer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from torch.cuda import amp\n",
    "import sys\n",
    "import datetime\n",
    "from spikingjelly import visualizing\n",
    "import torch.utils.data as data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9c60ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad9bdcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_mnist('/media/ubuntu/sda/SNN_train/MNIST_fashion', kind='train')\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28)\n",
    "X_test, y_test = load_mnist('/media/ubuntu/sda/SNN_train/MNIST_fashion', kind='t10k')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28 , 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfd34e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3803279/1084373352.py:1: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "  X_train_tensor = torch.from_numpy(X_train).float()\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "y_test_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "train_dataset = data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e97928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fashion_SNN(nn.Module):\n",
    "    def __init__(self, T, channels):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.channels = channels\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            layer.Conv2d(1, channels, kernel_size=3, padding=1, bias=False),\n",
    "            layer.BatchNorm2d(channels),\n",
    "            neuron.LIFNode(surrogate_function=surrogate.ATan()),\n",
    "            layer.MaxPool2d(2, 2),\n",
    "\n",
    "            layer.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False),\n",
    "            layer.BatchNorm2d(channels),\n",
    "            neuron.LIFNode(surrogate_function=surrogate.ATan()),\n",
    "            layer.MaxPool2d(2, 2),\n",
    "\n",
    "            layer.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False),\n",
    "            layer.BatchNorm2d(channels),\n",
    "            neuron.LIFNode(surrogate_function=surrogate.ATan()),\n",
    "            layer.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            layer.Linear(channels * 3 * 3, 10, bias=False),\n",
    "            neuron.LIFNode(surrogate_function=surrogate.ATan())\n",
    "        )\n",
    "\n",
    "        functional.set_step_mode(self, step_mode='m')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_seq = x.unsqueeze(1).repeat(self.T, 1, 1, 1, 1)  # [N, C, H, W] -> [T, N, C, H, W]\n",
    "        batch_size = x_seq.shape[1]\n",
    "\n",
    "        x_seq = self.conv(x_seq)\n",
    "        x_seq = x_seq.reshape(self.T, batch_size, self.channels * 3 * 3)\n",
    "        x_seq = self.linear(x_seq)\n",
    "        fr = x_seq.mean(0)\n",
    "        return fr\n",
    "    \n",
    "net = fashion_SNN(T = 40, channels= 32)\n",
    "net = net.to('cuda')\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dab0283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Epoch 0\n",
      "Train acc: 0.7004333333333334; Test acc: 0.7933\n",
      "------------------------------------------------------------\n",
      "Epoch 1\n",
      "Train acc: 0.8208; Test acc: 0.8318\n",
      "------------------------------------------------------------\n",
      "Epoch 2\n",
      "Train acc: 0.8522833333333333; Test acc: 0.848\n",
      "------------------------------------------------------------\n",
      "Epoch 3\n",
      "Train acc: 0.8664666666666667; Test acc: 0.8629\n",
      "------------------------------------------------------------\n",
      "Epoch 4\n",
      "Train acc: 0.8765333333333334; Test acc: 0.8704\n",
      "------------------------------------------------------------\n",
      "Epoch 5\n",
      "Train acc: 0.8842333333333333; Test acc: 0.8749\n",
      "------------------------------------------------------------\n",
      "Epoch 6\n",
      "Train acc: 0.8891333333333333; Test acc: 0.8829\n",
      "------------------------------------------------------------\n",
      "Epoch 7\n",
      "Train acc: 0.893; Test acc: 0.8827\n",
      "------------------------------------------------------------\n",
      "Epoch 8\n",
      "Train acc: 0.8962833333333333; Test acc: 0.8856\n",
      "------------------------------------------------------------\n",
      "Epoch 9\n",
      "Train acc: 0.8995166666666666; Test acc: 0.8898\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "for epoch in range(10):\n",
    "    start_time = time.time()\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_samples = 0\n",
    "    for img, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        label_onehot = F.one_hot(label, 10).float()\n",
    "\n",
    "        out_fr = net(img)\n",
    "\n",
    "        loss = F.mse_loss(out_fr, label_onehot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_samples += label.numel()\n",
    "        train_loss += loss.item() * label.numel()\n",
    "        train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "\n",
    "        functional.reset_net(net)\n",
    "\n",
    "    train_time = time.time()\n",
    "    train_speed = train_samples / (train_time - start_time)\n",
    "    train_loss /= train_samples\n",
    "    train_acc /= train_samples\n",
    "\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    test_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for img, label in test_loader:\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            label_onehot = F.one_hot(label, 10).float()\n",
    "\n",
    "            out_fr = net(img)\n",
    "            loss = F.mse_loss(out_fr, label_onehot)\n",
    "\n",
    "            test_samples += label.numel()\n",
    "            test_loss += loss.item() * label.numel()\n",
    "            test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
    "            functional.reset_net(net)\n",
    "    test_time = time.time()\n",
    "    test_speed = test_samples / (test_time - train_time)\n",
    "    test_loss /= test_samples\n",
    "    test_acc /= test_samples\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    print(f'Train acc: {train_acc}; Test acc: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
