{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spikeinterface as si\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import sys\n",
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import time\n",
    "import pickle\n",
    "import networkx as nx\n",
    "# from function.Function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_array2_in_range_of_array1(array1, array2, threshold=5):\n",
    "\n",
    "    sorted_array1 = np.sort(array1)\n",
    "    array2 = np.sort(array2)\n",
    "    \n",
    "    lefts = array2 - threshold\n",
    "    rights = array2 + threshold\n",
    "    \n",
    "    left_indices = np.searchsorted(sorted_array1, lefts, side='left')\n",
    "    \n",
    "    right_indices = np.searchsorted(sorted_array1, rights, side='right')\n",
    "    \n",
    "    has_within_range = right_indices > left_indices\n",
    "    \n",
    "    count = np.sum(has_within_range)\n",
    "    \n",
    "    return count\n",
    "\n",
    "def label_array1_based_on_array2(array1, array2, threshold=5):\n",
    "    array_1 = np.sort(array1)\n",
    "    sorted_array2 = np.sort(array2)\n",
    "    \n",
    "    labels = np.zeros(len(array1), dtype=int)\n",
    "    \n",
    "    for i, value in enumerate(array1):\n",
    "        left = value - threshold\n",
    "        right = value + threshold\n",
    "        \n",
    "        left_index = np.searchsorted(sorted_array2, left, side='left')\n",
    "        right_index = np.searchsorted(sorted_array2, right, side='right')\n",
    "        \n",
    "        if right_index > left_index:\n",
    "            labels[i] = 1\n",
    "    \n",
    "    return labels\n",
    "def detect_local_maxima_in_window(data, window_size=20, std_multiplier=2):\n",
    "\n",
    "    \"\"\"\n",
    "    在每个滑动窗口范围内检测局部最大值的索引，并确保最大值大于两倍的标准差。\n",
    "\n",
    "    参数:\n",
    "    data : numpy.ndarray\n",
    "        输入数据，形状为 (n_rows, n_columns)。\n",
    "    window_size : int\n",
    "        滑动窗口的大小，用于定义局部范围，默认为 20。\n",
    "    std_multiplier : float\n",
    "        标准差的倍数，用于筛选局部最大值，默认为 2。\n",
    "\n",
    "    返回:\n",
    "    local_maxima_indices : list of numpy.ndarray\n",
    "        每行局部最大值的索引列表，每个元素是对应行局部最大值的索引数组。\n",
    "    \"\"\"\n",
    "    local_maxima_indices = []\n",
    "\n",
    "    for row in data:\n",
    "        maxima_indices = []\n",
    "        row_std = np.std(row.astype(np.float32))\n",
    "        threshold = std_multiplier * row_std\n",
    "\n",
    "        for start in range(0, len(row), window_size):\n",
    "            end = min(start + window_size, len(row))\n",
    "            window = np.abs(row[start:end])\n",
    "            \n",
    "            if len(window) > 0:\n",
    "                local_max_index = np.argmax(window)\n",
    "                local_max_value = window[local_max_index]\n",
    "                \n",
    "                if local_max_value > threshold:\n",
    "                    maxima_indices.append(start + local_max_index)  \n",
    "        \n",
    "        local_maxima_indices.extend(maxima_indices)\n",
    "        local_maxima_indices = list(set(local_maxima_indices))  \n",
    "\n",
    "    return local_maxima_indices\n",
    "\n",
    "\n",
    "def cluster_label_array1_based_on_array2(array1, array2, threshold=5):\n",
    "\n",
    "    \"\"\"\n",
    "    根据 array2 的 'time' 和 'cluster' 对 array1 进行标记。\n",
    "    如果 array1 中的某个值在 threshold 范围内存在于 array2 的 'time' 中，则标记为对应的 'cluster' 值，否则为 0。\n",
    "    \n",
    "    参数:\n",
    "    array1 : numpy.ndarray\n",
    "        要标记的数组。\n",
    "    array2 : numpy.ndarray\n",
    "        包含 'time' 和 'cluster' 的二维数组。\n",
    "        第一列为 'time'，第二列为 'cluster'。\n",
    "    threshold : int\n",
    "        判断范围的阈值。\n",
    "    \n",
    "    返回:\n",
    "    labels : numpy.ndarray\n",
    "        长度为 len(array1) 的标签数组，值为 array2 中的 'cluster' 或 0。\n",
    "    \"\"\"\n",
    "\n",
    "    array2 = np.array(array2.iloc[:, [5, 1]])\n",
    "    sorted_indices = np.argsort(array2[:, 0])\n",
    "    sorted_array2 = array2[sorted_indices]\n",
    "    \n",
    "    labels = np.zeros(len(array1), dtype=int)\n",
    "    \n",
    "    # 遍历 array1 中的每个元素\n",
    "    for i, value in enumerate(array1):\n",
    "        # 计算当前值的范围\n",
    "        left = value - threshold\n",
    "        right = value + threshold\n",
    "        \n",
    "        left_index = np.searchsorted(sorted_array2[:, 0], left, side='left')\n",
    "        right_index = np.searchsorted(sorted_array2[:, 0], right, side='right')\n",
    "        \n",
    "        # 如果范围内存在值，则标记为对应的 'cluster'\n",
    "        if right_index > left_index:\n",
    "            # 获取范围内的第一个匹配值的 'cluster'\n",
    "            labels[i] = sorted_array2[left_index, 1]\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def label_array1_based_on_array2(array1, array2, threshold=5):\n",
    "\n",
    "    \"\"\"\n",
    "    根据 array2 的值对 array1 进行标记。\n",
    "    如果 array1 中的某个值在 threshold 范围内存在于 array2 中，则标记为 1，否则为 0。\n",
    "    \n",
    "    参数:\n",
    "    array1 : numpy.ndarray\n",
    "        要标记的数组。\n",
    "    array2 : numpy.ndarray\n",
    "        用于判断的数组。\n",
    "    threshold : int\n",
    "        判断范围的阈值。\n",
    "    \n",
    "    返回:\n",
    "    labels : numpy.ndarray\n",
    "        长度为 len(array1) 的标签数组，值为 0 或 1。\n",
    "    \"\"\"\n",
    "    # 对 array2 进行排序以加速搜索\n",
    "    sorted_array2 = np.sort(array2)\n",
    "    \n",
    "    # 初始化标签数组，默认值为 0\n",
    "    labels = np.zeros(len(array1), dtype=int)\n",
    "    \n",
    "    # 遍历 array1 中的每个元素\n",
    "    for i, value in enumerate(array1):\n",
    "        # 计算当前值的范围\n",
    "        left = value - threshold\n",
    "        right = value + threshold\n",
    "        \n",
    "        # 使用二分搜索判断范围内是否存在值\n",
    "        left_index = np.searchsorted(sorted_array2, left, side='left')\n",
    "        right_index = np.searchsorted(sorted_array2, right, side='right')\n",
    "        \n",
    "        # 如果范围内存在值，则标记为 1\n",
    "        if right_index > left_index:\n",
    "            labels[i] = 1\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def extract_windows(data, indices, window_size=61):\n",
    "    \"\"\"\n",
    "    根据给定的时间点索引提取窗口。\n",
    "    \n",
    "    参数:\n",
    "    data : numpy.ndarray\n",
    "        输入数据，形状为 (n_channels, time)\n",
    "    indices : numpy.ndarray\n",
    "        时间点索引数组，用于指定需要提取窗口的中心点\n",
    "    window_size : int\n",
    "        窗口长度，默认为61（对应time-30到time+31）\n",
    "    \n",
    "    返回:\n",
    "    windows : numpy.ndarray\n",
    "        提取的窗口数据，形状为 (len(indices), n_channels, window_size)\n",
    "    \"\"\"\n",
    "    n_channels, time_length = data.shape\n",
    "    half_window = window_size // 2\n",
    "\n",
    "    if np.any(indices < half_window) or np.any(indices >= time_length - half_window):\n",
    "        raise ValueError(\"Some indices are out of bounds for the given window size.\")\n",
    "\n",
    "    windows = []\n",
    "    for idx in indices:\n",
    "        window = data[:, idx - half_window:idx + half_window + 1]\n",
    "        windows.append(window)\n",
    "\n",
    "    windows = np.array(windows)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_raw = se.MEArecRecordingExtractor(file_path='/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/02_Neuropixel_384_channels/data_generation/recording_neuropixels_type1.h5')\n",
    "probe_384channel = recording_raw.get_probegroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_raw = se.read_binary(file_paths='/media/ubuntu/sda/Spike_Sorting/paper_architecture/01_real_data/03_Neuropixel_384_channels_visual_stimuli/raw_data/810755807/spike_band.dat', sampling_frequency=30000, dtype=np.int16, num_channels=384)\n",
    "recording_raw = recording_raw.set_probegroup(probe_384channel)\n",
    "recording_f = spre.bandpass_filter(recording_raw, freq_min=300, freq_max=3000)\n",
    "recording_f = spre.common_reference(recording_f, reference=\"global\", operator=\"median\")\n",
    "recording_f = recording_f.time_slice(start_time=0, end_time= 1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_384channel = np.array(recording_raw.get_probegroup().to_dataframe().iloc[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=1e-5\n",
    "distance_threshold = 100\n",
    "dist_matrix = np.linalg.norm(probe_384channel[:, np.newaxis] - probe_384channel, axis=2)\n",
    "np.fill_diagonal(dist_matrix, 0)\n",
    "dist_matrix[dist_matrix < eps] = eps\n",
    "inv_dist = np.zeros_like(dist_matrix)\n",
    "\n",
    "inv_dist = np.where(dist_matrix > 0, 1, 0)\n",
    "np.fill_diagonal(inv_dist, 0)  \n",
    "if distance_threshold is not None:\n",
    "    inv_dist[dist_matrix > distance_threshold] = 0\n",
    "\n",
    "graph = nx.from_numpy_array(inv_dist)\n",
    "maximal_cliques = list(nx.find_cliques(graph))\n",
    "cliques_dict = {i: clique for i, clique in enumerate(maximal_cliques)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_inf = pd.read_csv(\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/01_real_data/03_Neuropixel_384_channels_visual_stimuli/spike_sorting/810755807/spike_inf.tsv\", index_col=0, sep='\\t')\n",
    "cluster_inf = pd.read_csv(\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/01_real_data/03_Neuropixel_384_channels_visual_stimuli/spike_sorting/810755807/cluster_inf.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "\n",
    "class Spike_Detection_MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, n_channels, time_window):\n",
    "        super(Spike_Detection_MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, 16)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(16, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "\n",
    "        self.n_channels = n_channels\n",
    "        self.time_window = time_window\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, self.n_channels * self.time_window)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_results = {}  \n",
    "unique_i_list = [] \n",
    "\n",
    "for i in sorted(cliques_dict.keys()):  \n",
    "    probe_center = np.mean(probe_384channel[cliques_dict[i]], axis=0) \n",
    "    distance_threshold = 100  \n",
    "    \n",
    "    distances = np.linalg.norm(cluster_inf.iloc[:, [-2, -1]] - probe_center, axis=1)\n",
    "    indices_within_range = cluster_inf['cluster_id'].values[np.where(distances <= distance_threshold)[0]]\n",
    "    if len(indices_within_range) != 0:\n",
    "        result_tuple = tuple(sorted(indices_within_range))  \n",
    "        \n",
    "        if result_tuple not in seen_results:\n",
    "            seen_results[result_tuple] = i  \n",
    "            unique_i_list.append(i)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [06:49<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:47<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:44<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:31<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 12...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:49<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 13...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:41<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 14...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:42<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 15...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:41<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 17...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:42<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 18...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:44<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:42<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 21...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:42<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 22...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:41<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 24...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:43<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 26...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:42<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 27...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:43<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 28...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:42<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 30...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:44<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:40<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 34...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:47<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 35...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:50<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 36...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:57<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 37...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:40<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 39...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:44<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 42...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:39<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 44...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:40<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 46...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:41<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 49...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:41<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 51...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:40<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 52...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:45<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 53...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:43<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 55...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:41<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 57...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:42<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 60...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:43<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 61...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:45<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 62...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:45<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 63...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:43<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 76...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:42<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 78...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:43<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 87...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:45<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 90...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:47<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 94...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:41<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 95...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:47<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 96...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:46<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 99...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:45<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:47<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 101...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:45<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 104...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:45<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 105...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:44<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 106...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:46<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 108...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:42<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 113...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:46<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 116...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:48<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 120...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:41<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 122...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:45<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 124...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:48<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 126...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:45<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 128...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:46<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 130...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:43<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 134...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:49<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 138...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:49<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 153...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:50<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 158...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:49<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 163...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:49<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 166...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:48<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 168...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:49<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 170...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:51<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 172...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:49<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 174...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:50<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 176...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:48<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 181...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:49<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing 183...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [04:50<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n"
     ]
    }
   ],
   "source": [
    "accuracy_dict = {}\n",
    "tpr_dict = {}\n",
    "tnr_dict = {}\n",
    "for clique_id in unique_i_list:\n",
    "    print(f'Processing {clique_id}...')\n",
    "    os.makedirs(f'/media/ubuntu/sda/Spike_Sorting/paper_architecture/01_real_data/03_Neuropixel_384_channels_visual_stimuli/spike_detection/train_result/810755807/{clique_id}', exist_ok=True)\n",
    "    accuracy_dict[clique_id] = []\n",
    "    tpr_dict[clique_id] = []\n",
    "    tnr_dict[clique_id] = []\n",
    "\n",
    "    clique = cliques_dict[clique_id]\n",
    "\n",
    "    total_frames = 1200 * 30000\n",
    "    chunk_size = 120000  \n",
    "    window_size = 41\n",
    "    half_window = window_size // 2\n",
    "\n",
    "    all_valid_indices = []\n",
    "    all_windows = []\n",
    "    for start_frame in tqdm(range(0, total_frames, chunk_size)):\n",
    "        end_frame = min(start_frame + chunk_size, total_frames)\n",
    "        \n",
    "        data_chunk = recording_f.get_traces(\n",
    "            start_frame=start_frame,\n",
    "            end_frame=end_frame,\n",
    "            channel_ids=[i for i in clique]\n",
    "        )  # shape: (n_channels, chunk_size)\n",
    "        \n",
    "        threshold_result = detect_local_maxima_in_window(\n",
    "            data_chunk.T,  \n",
    "            std_multiplier=1.5,\n",
    "            window_size= 80\n",
    "        )\n",
    "        \n",
    "        threshold_result = np.array(threshold_result) + start_frame\n",
    "        valid_indices = threshold_result[\n",
    "            (threshold_result >= start_frame + half_window + 1) & \n",
    "            (threshold_result < end_frame - half_window)\n",
    "        ]\n",
    "        \n",
    "        for idx in valid_indices:\n",
    "            rel_idx = idx - start_frame\n",
    "            window = data_chunk.T[:, rel_idx-half_window : rel_idx+half_window+1]\n",
    "            all_windows.append(window)\n",
    "        \n",
    "        all_valid_indices.extend(valid_indices)\n",
    "\n",
    "    all_valid_indices = np.array(all_valid_indices)\n",
    "    all_windows = np.stack(all_windows)  \n",
    "\n",
    "    clique = cliques_dict[clique_id]\n",
    "    probe_center = np.mean(probe_384channel[clique], axis=0) \n",
    "    distance_threshold = 100  \n",
    "\n",
    "    distances = np.linalg.norm(cluster_inf.iloc[:, [-2, -1]] - probe_center, axis=1)\n",
    "\n",
    "    indices_within_range = cluster_inf['cluster_id'].values[np.where(distances <= distance_threshold)[0]]\n",
    "    spike_inf_temp = spike_inf[spike_inf['cluster'].isin(indices_within_range)]\n",
    "\n",
    "    labels = label_array1_based_on_array2(all_valid_indices, spike_inf_temp['time'], threshold=1)\n",
    "    indices_0 = np.where(labels == 0)[0] \n",
    "    indices_1 = np.where(labels == 1)[0] \n",
    "    #print(len(indices_1) / len(spike_inf_temp))\n",
    "    target_0_count = len(indices_1) \n",
    "\n",
    "    if len(indices_0) > target_0_count:\n",
    "        sampled_indices_0 = np.random.choice(indices_0, target_0_count, replace=False)\n",
    "    else:\n",
    "        sampled_indices_0 = indices_0  \n",
    "\n",
    "    final_indices = np.concatenate([sampled_indices_0, indices_1])\n",
    "\n",
    "    np.random.shuffle(final_indices)\n",
    "\n",
    "    sampled_windows = all_windows[final_indices]\n",
    "    sampled_labels = labels[final_indices]\n",
    "\n",
    "    dataset = CustomDataset(sampled_windows, sampled_labels)\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    batch_size = 1024 \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    hidden_size1 = 128\n",
    "    hidden_size2 = 32\n",
    "    output_size = 1  \n",
    "    device = 'cuda'\n",
    "    input_size = sampled_windows.shape[1] * sampled_windows.shape[2]\n",
    "\n",
    "\n",
    "    criterion = nn.BCELoss()  \n",
    "\n",
    "    for trail in range(1, 6):\n",
    "        print(f\"Training for trail {trail}...\")\n",
    "\n",
    "        model = Spike_Detection_MLP(input_size, hidden_size1, hidden_size2, \n",
    "                                    output_size, n_channels=sampled_windows.shape[1], time_window= sampled_windows.shape[2])\n",
    "        model = model.to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        num_epochs = 50\n",
    "        tpr_best = 0\n",
    "        i = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_data, batch_labels in train_loader:\n",
    "                batch_labels = batch_labels.float().unsqueeze(1)\n",
    "\n",
    "                batch_data = batch_data.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "\n",
    "                outputs = model(batch_data)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "\n",
    "                predicted = (outputs > 0.5).float()  \n",
    "                total += batch_labels.size(0)\n",
    "                correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            #print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "            #print(f\"Train Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            true_positive = 0\n",
    "            true_negative = 0\n",
    "            false_positive = 0\n",
    "            false_negative = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_data, batch_labels in test_loader:\n",
    "                    batch_labels = batch_labels.float().unsqueeze(1)\n",
    "                    batch_data = batch_data.to(device)\n",
    "                    batch_labels = batch_labels.to(device)\n",
    "\n",
    "                    outputs = model(batch_data)\n",
    "                    predicted = (outputs > 0.5).float()  \n",
    "                    total += batch_labels.size(0)\n",
    "                    correct += (predicted == batch_labels).sum().item()\n",
    "                    true_positive += ((predicted == 1) & (batch_labels == 1)).sum().item()\n",
    "                    true_negative += ((predicted == 0) & (batch_labels == 0)).sum().item()\n",
    "                    false_positive += ((predicted == 1) & (batch_labels == 0)).sum().item()\n",
    "                    false_negative += ((predicted == 0) & (batch_labels == 1)).sum().item()\n",
    "\n",
    "            tpr = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "            tnr = true_negative / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0\n",
    "\n",
    "            #print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "            #print(f\"Test TPR: {100 * tpr:.2f}%\")\n",
    "            #print(f\"Test TNR: {100 * tnr:.2f}%\")\n",
    "\n",
    "            if tpr > tpr_best:\n",
    "                        tpr_best = tpr\n",
    "                        i = 0\n",
    "                        torch.save(model, f'/media/ubuntu/sda/Spike_Sorting/paper_architecture/01_real_data/03_Neuropixel_384_channels_visual_stimuli/spike_detection/train_result/810755807/{clique_id}/trail_{trail}.pth')\n",
    "                        #print(f\"Best model saved with TPR: {tpr_best:.4f}\")\n",
    "                        #print(\"_\" * 60)\n",
    "\n",
    "            else:\n",
    "                i += 1\n",
    "                if i == 3:\n",
    "                    #print(f\"Training stopped after {epoch+1} epochs with best TPR: {tpr_best:.4f}\")\n",
    "                    #print(\"_\" * 60)\n",
    "                    accuracy_dict[clique_id].append(correct/total * 100)\n",
    "                    tpr_dict[clique_id].append(tpr * 100)\n",
    "                    tnr_dict[clique_id].append(tnr * 100)\n",
    "                    break\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/01_real_data/03_Neuropixel_384_channels_visual_stimuli/spike_detection/eval_result/810755807/accuracy_dict.pkl\", 'wb') as f:\n",
    "    pickle.dump(accuracy_dict, f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/01_real_data/03_Neuropixel_384_channels_visual_stimuli/spike_detection/eval_result/810755807/tpr_dict.pkl\", 'wb') as f:\n",
    "    pickle.dump(tpr_dict, f)\n",
    "\n",
    "with open(\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/01_real_data/03_Neuropixel_384_channels_visual_stimuli/spike_detection/eval_result/810755807/tnr_dict.pkl\", 'wb') as f:\n",
    "    pickle.dump(tnr_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike_sorting_jct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
