{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spikeinterface as si\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import sys\n",
    "import spikeinterface as si\n",
    "import matplotlib.pyplot as plt\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.widgets as sw\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import json\n",
    "import probeinterface\n",
    "\n",
    "from probeinterface import Probe, ProbeGroup\n",
    "from probeinterface.plotting import plot_probe, plot_probegroup\n",
    "from probeinterface import generate_dummy_probe, generate_linear_probe\n",
    "from probeinterface import write_probeinterface, read_probeinterface\n",
    "from probeinterface import write_prb, read_prb\n",
    "from torch.nn.functional import max_pool1d\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.utils.data import Subset\n",
    "import networkx as nx\n",
    "\n",
    "# from function.Function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_array2_in_range_of_array1(array1, array2, threshold=5):\n",
    "\n",
    "    sorted_array1 = np.sort(array1)\n",
    "    \n",
    "    lefts = array2 - threshold\n",
    "    rights = array2 + threshold\n",
    "    \n",
    "    left_indices = np.searchsorted(sorted_array1, lefts, side='left')\n",
    "    \n",
    "    right_indices = np.searchsorted(sorted_array1, rights, side='right')\n",
    "    \n",
    "    has_within_range = right_indices > left_indices\n",
    "    \n",
    "    count = np.sum(has_within_range)\n",
    "    \n",
    "    return count\n",
    "\n",
    "\n",
    "def detect_local_maxima_in_window(data, window_size=20, std_multiplier=2):\n",
    "\n",
    "    \"\"\"\n",
    "    在每个滑动窗口范围内检测局部最大值的索引，并确保最大值大于两倍的标准差。\n",
    "\n",
    "    参数:\n",
    "    data : numpy.ndarray\n",
    "        输入数据，形状为 (n_rows, n_columns)。\n",
    "    window_size : int\n",
    "        滑动窗口的大小，用于定义局部范围，默认为 20。\n",
    "    std_multiplier : float\n",
    "        标准差的倍数，用于筛选局部最大值，默认为 2。\n",
    "\n",
    "    返回:\n",
    "    local_maxima_indices : list of numpy.ndarray\n",
    "        每行局部最大值的索引列表，每个元素是对应行局部最大值的索引数组。\n",
    "    \"\"\"\n",
    "    local_maxima_indices = []\n",
    "\n",
    "    for row in data:\n",
    "        maxima_indices = []\n",
    "        row_std = np.std(row.astype(np.float32))\n",
    "        threshold = std_multiplier * row_std\n",
    "\n",
    "        for start in range(0, len(row), window_size):\n",
    "            end = min(start + window_size, len(row))\n",
    "            window = row[start:end]\n",
    "            \n",
    "            if len(window) > 0:\n",
    "                local_max_index = np.argmax(window)\n",
    "                local_max_value = window[local_max_index]\n",
    "                \n",
    "                if local_max_value > threshold:\n",
    "                    maxima_indices.append(start + local_max_index)  \n",
    "        \n",
    "        local_maxima_indices.extend(maxima_indices)\n",
    "        local_maxima_indices = list(set(local_maxima_indices))  \n",
    "\n",
    "    return local_maxima_indices\n",
    "\n",
    "\n",
    "def cluster_label_array1_based_on_array2(array1, array2, threshold=5):\n",
    "\n",
    "    \"\"\"\n",
    "    根据 array2 的 'time' 和 'cluster' 对 array1 进行标记。\n",
    "    如果 array1 中的某个值在 threshold 范围内存在于 array2 的 'time' 中，则标记为对应的 'cluster' 值，否则为 0。\n",
    "    \n",
    "    参数:\n",
    "    array1 : numpy.ndarray\n",
    "        要标记的数组。\n",
    "    array2 : numpy.ndarray\n",
    "        包含 'time' 和 'cluster' 的二维数组。\n",
    "        第一列为 'time'，第二列为 'cluster'。\n",
    "    threshold : int\n",
    "        判断范围的阈值。\n",
    "    \n",
    "    返回:\n",
    "    labels : numpy.ndarray\n",
    "        长度为 len(array1) 的标签数组，值为 array2 中的 'cluster' 或 0。\n",
    "    \"\"\"\n",
    "\n",
    "    array2 = np.array(array2.iloc[:, [5, 1]])\n",
    "    sorted_indices = np.argsort(array2[:, 0])\n",
    "    sorted_array2 = array2[sorted_indices]\n",
    "    \n",
    "    labels = np.zeros(len(array1), dtype=int)\n",
    "    \n",
    "    # 遍历 array1 中的每个元素\n",
    "    for i, value in enumerate(array1):\n",
    "        # 计算当前值的范围\n",
    "        left = value - threshold\n",
    "        right = value + threshold\n",
    "        \n",
    "        left_index = np.searchsorted(sorted_array2[:, 0], left, side='left')\n",
    "        right_index = np.searchsorted(sorted_array2[:, 0], right, side='right')\n",
    "        \n",
    "        # 如果范围内存在值，则标记为对应的 'cluster'\n",
    "        if right_index > left_index:\n",
    "            # 获取范围内的第一个匹配值的 'cluster'\n",
    "            labels[i] = sorted_array2[left_index, 1]\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def label_array1_based_on_array2(array1, array2, threshold=5):\n",
    "\n",
    "    \"\"\"\n",
    "    根据 array2 的值对 array1 进行标记。\n",
    "    如果 array1 中的某个值在 threshold 范围内存在于 array2 中，则标记为 1，否则为 0。\n",
    "    \n",
    "    参数:\n",
    "    array1 : numpy.ndarray\n",
    "        要标记的数组。\n",
    "    array2 : numpy.ndarray\n",
    "        用于判断的数组。\n",
    "    threshold : int\n",
    "        判断范围的阈值。\n",
    "    \n",
    "    返回:\n",
    "    labels : numpy.ndarray\n",
    "        长度为 len(array1) 的标签数组，值为 0 或 1。\n",
    "    \"\"\"\n",
    "    # 对 array2 进行排序以加速搜索\n",
    "    sorted_array2 = np.sort(array2)\n",
    "    \n",
    "    # 初始化标签数组，默认值为 0\n",
    "    labels = np.zeros(len(array1), dtype=int)\n",
    "    \n",
    "    # 遍历 array1 中的每个元素\n",
    "    for i, value in enumerate(array1):\n",
    "        # 计算当前值的范围\n",
    "        left = value - threshold\n",
    "        right = value + threshold\n",
    "        \n",
    "        # 使用二分搜索判断范围内是否存在值\n",
    "        left_index = np.searchsorted(sorted_array2, left, side='left')\n",
    "        right_index = np.searchsorted(sorted_array2, right, side='right')\n",
    "        \n",
    "        # 如果范围内存在值，则标记为 1\n",
    "        if right_index > left_index:\n",
    "            labels[i] = 1\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def extract_windows(data, indices, window_size=61):\n",
    "    \"\"\"\n",
    "    根据给定的时间点索引提取窗口。\n",
    "    \n",
    "    参数:\n",
    "    data : numpy.ndarray\n",
    "        输入数据，形状为 (n_channels, time)\n",
    "    indices : numpy.ndarray\n",
    "        时间点索引数组，用于指定需要提取窗口的中心点\n",
    "    window_size : int\n",
    "        窗口长度，默认为61（对应time-30到time+31）\n",
    "    \n",
    "    返回:\n",
    "    windows : numpy.ndarray\n",
    "        提取的窗口数据，形状为 (len(indices), n_channels, window_size)\n",
    "    \"\"\"\n",
    "    n_channels, time_length = data.shape\n",
    "    half_window = window_size // 2\n",
    "\n",
    "    if np.any(indices < half_window) or np.any(indices >= time_length - half_window):\n",
    "        raise ValueError(\"Some indices are out of bounds for the given window size.\")\n",
    "\n",
    "    windows = []\n",
    "    for idx in indices:\n",
    "        window = data[:, idx - half_window:idx + half_window + 1]\n",
    "        windows.append(window)\n",
    "\n",
    "    windows = np.array(windows)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_raw = se.MEArecRecordingExtractor(file_path='/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/02_Neuropixel_384_channels/data_generation/recording_neuropixels_600s_350cells_fs10000.h5')\n",
    "\n",
    "recording_f = spre.bandpass_filter(recording_raw, freq_min=300, freq_max=3000)\n",
    "recording_f = spre.common_reference(recording_f, reference=\"global\", operator=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_384channel = np.array(recording_raw.get_probegroup().to_dataframe().iloc[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=1e-5\n",
    "distance_threshold = 200\n",
    "dist_matrix = np.linalg.norm(probe_384channel[:, np.newaxis] - probe_384channel, axis=2)\n",
    "np.fill_diagonal(dist_matrix, 0)\n",
    "dist_matrix[dist_matrix < eps] = eps\n",
    "inv_dist = np.zeros_like(dist_matrix)\n",
    "\n",
    "inv_dist = np.where(dist_matrix > 0, 1, 0)\n",
    "np.fill_diagonal(inv_dist, 0)  \n",
    "if distance_threshold is not None:\n",
    "    inv_dist[dist_matrix > distance_threshold] = 0\n",
    "\n",
    "graph = nx.from_numpy_array(inv_dist)\n",
    "maximal_cliques = list(nx.find_cliques(graph))\n",
    "cliques_dict = {i: clique for i, clique in enumerate(maximal_cliques)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_inf = pd.read_csv(\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/02_Neuropixel_384_channels/data_generation/recording_neuropixels_600s_350cells_fs10000.csv\")\n",
    "import MEArec\n",
    "regmec = MEArec.load_recordings(\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/02_Neuropixel_384_channels/data_generation/recording_neuropixels_600s_350cells_fs10000.h5\")\n",
    "cluster_inf = pd.read_csv(\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/02_Neuropixel_384_channels/data_generation/cluster_inf_recording_neuropixels_600s_350cells_fs10000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "\n",
    "class Spike_Detection_MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, n_channels, time_window):\n",
    "        super(Spike_Detection_MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, 16)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(16, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  \n",
    "\n",
    "        self.n_channels = n_channels\n",
    "        self.time_window = time_window\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, self.n_channels * self.time_window)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing clique 0 with 28 channels...\n",
      "Training for trail 1...\n",
      "Training for trail 2...\n",
      "Training for trail 3...\n",
      "Training for trail 4...\n",
      "Training for trail 5...\n",
      "Processing clique 1 with 28 channels...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_frame \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, total_frames, chunk_size):\n\u001b[1;32m     21\u001b[0m     end_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start_frame \u001b[38;5;241m+\u001b[39m chunk_size, total_frames)\n\u001b[0;32m---> 23\u001b[0m     data_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mrecording_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_frame\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclique\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape: (n_channels, chunk_size)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     threshold_result \u001b[38;5;241m=\u001b[39m detect_local_maxima_in_window(\n\u001b[1;32m     30\u001b[0m         data_chunk\u001b[38;5;241m.\u001b[39mT,  \n\u001b[1;32m     31\u001b[0m         std_multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     34\u001b[0m     threshold_result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(threshold_result) \u001b[38;5;241m+\u001b[39m start_frame\n",
      "File \u001b[0;32m~/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/baserecording.py:330\u001b[0m, in \u001b[0;36mBaseRecording.get_traces\u001b[0;34m(self, segment_index, start_frame, end_frame, channel_ids, order, return_scaled, cast_unsigned)\u001b[0m\n\u001b[1;32m    328\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mget_num_samples()\n\u001b[1;32m    329\u001b[0m end_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(end_frame, num_samples)) \u001b[38;5;28;01mif\u001b[39;00m end_frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_samples\n\u001b[0;32m--> 330\u001b[0m traces \u001b[38;5;241m=\u001b[39m \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/preprocessing/common_reference.py:187\u001b[0m, in \u001b[0;36mCommonReferenceRecordingSegment.get_traces\u001b[0;34m(self, start_frame, end_frame, channel_indices)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref_channel_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m         shift \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperator_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m         shift \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperator_func(traces[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref_channel_indices], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/lib/function_base.py:3927\u001b[0m, in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3845\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_median_dispatcher)\n\u001b[1;32m   3846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmedian\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, overwrite_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   3847\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3848\u001b[0m \u001b[38;5;124;03m    Compute the median along the specified axis.\u001b[39;00m\n\u001b[1;32m   3849\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3925\u001b[0m \n\u001b[1;32m   3926\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_median\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3928\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/lib/function_base.py:3823\u001b[0m, in \u001b[0;36m_ureduce\u001b[0;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[1;32m   3820\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[1;32m   3821\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[0;32m-> 3823\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/lib/function_base.py:3960\u001b[0m, in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3958\u001b[0m         part \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m   3959\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3960\u001b[0m     part \u001b[38;5;241m=\u001b[39m \u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m part\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m ():\n\u001b[1;32m   3963\u001b[0m     \u001b[38;5;66;03m# make 0-D arrays work\u001b[39;00m\n\u001b[1;32m   3964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m part\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/core/fromnumeric.py:771\u001b[0m, in \u001b[0;36mpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    770\u001b[0m     a \u001b[38;5;241m=\u001b[39m asanyarray(a)\u001b[38;5;241m.\u001b[39mcopy(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 771\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for clique_id, clique in cliques_dict.items():\n",
    "    print(f\"Processing clique {clique_id} with {len(clique)} channels...\")\n",
    "    \n",
    "    probe_center = np.mean(probe_384channel[clique], axis=0) \n",
    "    distance_threshold = 100  \n",
    "\n",
    "    distances = np.linalg.norm(cluster_inf.iloc[:, 1:3] - probe_center, axis=1)\n",
    "\n",
    "    indices_within_range = cluster_inf['Neuron'][np.where(distances <= distance_threshold)[0]].values\n",
    "    spike_inf_temp = spike_inf[spike_inf['Neuron'].isin(indices_within_range)]\n",
    "\n",
    "    total_frames = 600 * 10000\n",
    "    chunk_size = 100000  \n",
    "    window_size = 31\n",
    "    half_window = window_size // 2\n",
    "\n",
    "    all_valid_indices = []\n",
    "    all_windows = []\n",
    "\n",
    "    for start_frame in range(0, total_frames, chunk_size):\n",
    "        end_frame = min(start_frame + chunk_size, total_frames)\n",
    "        \n",
    "        data_chunk = recording_f.get_traces(\n",
    "            start_frame=start_frame,\n",
    "            end_frame=end_frame,\n",
    "            channel_ids=[str(i+1) for i in clique]\n",
    "        )  # shape: (n_channels, chunk_size)\n",
    "        \n",
    "        threshold_result = detect_local_maxima_in_window(\n",
    "            data_chunk.T,  \n",
    "            std_multiplier=0.7\n",
    "        )\n",
    "        \n",
    "        threshold_result = np.array(threshold_result) + start_frame\n",
    "        valid_indices = threshold_result[\n",
    "            (threshold_result >= start_frame + half_window + 1) & \n",
    "            (threshold_result < end_frame - half_window)\n",
    "        ]\n",
    "        \n",
    "        for idx in valid_indices:\n",
    "            rel_idx = idx - start_frame\n",
    "            window = data_chunk.T[:, rel_idx-half_window : rel_idx+half_window+1]\n",
    "            all_windows.append(window)\n",
    "        \n",
    "        all_valid_indices.extend(valid_indices)\n",
    "\n",
    "    all_valid_indices = np.array(all_valid_indices)\n",
    "    all_windows = np.stack(all_windows)  \n",
    "\n",
    "    distances = np.linalg.norm(cluster_inf.iloc[:, 1:3] - probe_center, axis=1)\n",
    "    indices_within_range = cluster_inf['Neuron'][distances <= distance_threshold].values\n",
    "    spike_inf_temp = spike_inf[spike_inf['Neuron'].isin(indices_within_range)]\n",
    "\n",
    "    labels = label_array1_based_on_array2(all_valid_indices, spike_inf_temp['time'], threshold=1)\n",
    "    indices_0 = np.where(labels == 0)[0] \n",
    "    indices_1 = np.where(labels == 1)[0] \n",
    "\n",
    "    target_0_count = len(indices_1) \n",
    "\n",
    "    if len(indices_0) > target_0_count:\n",
    "        sampled_indices_0 = np.random.choice(indices_0, target_0_count, replace=False)\n",
    "    else:\n",
    "        sampled_indices_0 = indices_0  \n",
    "\n",
    "    final_indices = np.concatenate([sampled_indices_0, indices_1])\n",
    "\n",
    "    np.random.shuffle(final_indices)\n",
    "\n",
    "    sampled_windows = all_windows[final_indices]\n",
    "    sampled_labels = labels[final_indices]\n",
    "\n",
    "    dataset = CustomDataset(sampled_windows, sampled_labels)\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    batch_size = 1024 \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    input_size = sampled_windows.shape[1] * sampled_windows.shape[2]\n",
    "\n",
    "    accuracy_list = []  \n",
    "    tpr_list = []\n",
    "    tnr_list = []\n",
    "\n",
    "    criterion = nn.BCELoss()  \n",
    "    \n",
    "    hidden_size1 = 128\n",
    "    hidden_size2 = 32\n",
    "    output_size = 1  \n",
    "    device = 'cuda'\n",
    "    \n",
    "    for trail in range(1, 6):\n",
    "        print(f\"Training for trail {trail}...\")\n",
    "\n",
    "        model = Spike_Detection_MLP(input_size, hidden_size1, hidden_size2, \n",
    "                                    output_size, n_channels=sampled_windows.shape[1], time_window= sampled_windows.shape[2])\n",
    "        model = model.to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        num_epochs = 50\n",
    "        tpr_best = 0\n",
    "        i = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch_data, batch_labels in train_loader:\n",
    "                batch_labels = batch_labels.float().unsqueeze(1)\n",
    "\n",
    "                batch_data = batch_data.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "\n",
    "                outputs = model(batch_data)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "\n",
    "                predicted = (outputs > 0.5).float()  \n",
    "                total += batch_labels.size(0)\n",
    "                correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            #print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "            #print(f\"Train Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            true_positive = 0\n",
    "            true_negative = 0\n",
    "            false_positive = 0\n",
    "            false_negative = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_data, batch_labels in test_loader:\n",
    "                    batch_labels = batch_labels.float().unsqueeze(1)\n",
    "                    batch_data = batch_data.to(device)\n",
    "                    batch_labels = batch_labels.to(device)\n",
    "\n",
    "                    outputs = model(batch_data)\n",
    "                    predicted = (outputs > 0.5).float()  \n",
    "                    total += batch_labels.size(0)\n",
    "                    correct += (predicted == batch_labels).sum().item()\n",
    "                    true_positive += ((predicted == 1) & (batch_labels == 1)).sum().item()\n",
    "                    true_negative += ((predicted == 0) & (batch_labels == 0)).sum().item()\n",
    "                    false_positive += ((predicted == 1) & (batch_labels == 0)).sum().item()\n",
    "                    false_negative += ((predicted == 0) & (batch_labels == 1)).sum().item()\n",
    "\n",
    "            tpr = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "            tnr = true_negative / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0\n",
    "\n",
    "            #print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "            #print(f\"Test TPR: {100 * tpr:.2f}%\")\n",
    "            #print(f\"Test TNR: {100 * tnr:.2f}%\")\n",
    "\n",
    "            # if tpr > tpr_best:\n",
    "            #             tpr_best = tpr\n",
    "            #             i = 0\n",
    "            #             torch.save(model, f'/media/ubuntu/sda/Spike_Sorting/simulation/Neuropixles/spike_detection_model/{trail}/clique_{clique_id}.pth')\n",
    "            #             #print(f\"Best model saved with TPR: {tpr_best:.4f}\")\n",
    "            #             #print(\"_\" * 60)\n",
    "\n",
    "            # else:\n",
    "            #     i += 1\n",
    "            #     if i == 3:\n",
    "            #         #print(f\"Training stopped after {epoch+1} epochs with best TPR: {tpr_best:.4f}\")\n",
    "            #         #print(\"_\" * 60)\n",
    "            #         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict = {}\n",
    "tpr_dict = {}\n",
    "tnr_dict = {}\n",
    "\n",
    "for clique_id, clique in cliques_dict.items():\n",
    "    print(f\"Processing clique {clique_id} with {len(clique)} channels...\")\n",
    "    \n",
    "    probe_center = np.mean(probe_384channel[clique], axis=0) \n",
    "    distance_threshold = 100  \n",
    "\n",
    "    distances = np.linalg.norm(cluster_inf.iloc[:, 1:3] - probe_center, axis=1)\n",
    "\n",
    "    indices_within_range = cluster_inf['Neuron'][np.where(distances <= distance_threshold)[0]].values\n",
    "    spike_inf_temp = spike_inf[spike_inf['Neuron'].isin(indices_within_range)]\n",
    "\n",
    "    total_frames = 600 * 10000\n",
    "    chunk_size = 100000  \n",
    "    window_size = 31\n",
    "    half_window = window_size // 2\n",
    "\n",
    "    all_valid_indices = []\n",
    "    all_windows = []\n",
    "\n",
    "    for start_frame in range(300 * 10000, total_frames, chunk_size):\n",
    "        end_frame = min(start_frame + chunk_size, total_frames)\n",
    "        \n",
    "        data_chunk = recording_f.get_traces(\n",
    "            start_frame=start_frame,\n",
    "            end_frame=end_frame,\n",
    "            channel_ids=[str(i+1) for i in clique]\n",
    "        )  # shape: (n_channels, chunk_size)\n",
    "        \n",
    "        threshold_result = detect_local_maxima_in_window(\n",
    "            data_chunk.T,  \n",
    "            std_multiplier=0.7\n",
    "        )\n",
    "        \n",
    "        threshold_result = np.array(threshold_result) + start_frame\n",
    "        valid_indices = threshold_result[\n",
    "            (threshold_result >= start_frame + half_window + 1) & \n",
    "            (threshold_result < end_frame - half_window)\n",
    "        ]\n",
    "        \n",
    "        for idx in valid_indices:\n",
    "            rel_idx = idx - start_frame\n",
    "            window = data_chunk.T[:, rel_idx-half_window : rel_idx+half_window+1]\n",
    "            all_windows.append(window)\n",
    "        \n",
    "        all_valid_indices.extend(valid_indices)\n",
    "\n",
    "    all_valid_indices = np.array(all_valid_indices)\n",
    "    all_windows = np.stack(all_windows)  \n",
    "\n",
    "    distances = np.linalg.norm(cluster_inf.iloc[:, 1:3] - probe_center, axis=1)\n",
    "    indices_within_range = cluster_inf['Neuron'][distances <= distance_threshold].values\n",
    "    spike_inf_temp = spike_inf[spike_inf['Neuron'].isin(indices_within_range)]\n",
    "\n",
    "    labels = label_array1_based_on_array2(all_valid_indices, spike_inf_temp['time'], threshold=1)\n",
    "    indices_0 = np.where(labels == 0)[0] \n",
    "    indices_1 = np.where(labels == 1)[0] \n",
    "\n",
    "    target_0_count = len(indices_1) \n",
    "\n",
    "    if len(indices_0) > target_0_count:\n",
    "        sampled_indices_0 = np.random.choice(indices_0, target_0_count, replace=False)\n",
    "    else:\n",
    "        sampled_indices_0 = indices_0  \n",
    "\n",
    "    final_indices = np.concatenate([sampled_indices_0, indices_1])\n",
    "\n",
    "    np.random.shuffle(final_indices)\n",
    "\n",
    "    sampled_windows = all_windows[final_indices]\n",
    "    sampled_labels = labels[final_indices]\n",
    "\n",
    "    dataset = CustomDataset(sampled_windows, sampled_labels)\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    batch_size = 1024 \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    input_size = sampled_windows.shape[1] * sampled_windows.shape[2]\n",
    "\n",
    "    criterion = nn.BCELoss()  \n",
    "    \n",
    "    hidden_size1 = 128\n",
    "    hidden_size2 = 32\n",
    "    output_size = 1  \n",
    "    device = 'cuda'\n",
    "    \n",
    "    accuracy_dict[clique_id] = []\n",
    "    tpr_dict[clique_id] = []\n",
    "    tnr_dict[clique_id] = []\n",
    "\n",
    "    for trail in range(1, 6):\n",
    "        print(f\"Training for trail {trail}...\")\n",
    "\n",
    "        model = torch.load(f\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/02_Neuropixel_384_channels/spike_detection/train_results/{trail}/clique_{clique_id}.pth\", weights_only=False)\n",
    "        model = model.to(device)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        true_positive = 0\n",
    "        true_negative = 0\n",
    "        false_positive = 0\n",
    "        false_negative = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_data, batch_labels in test_loader:\n",
    "                batch_labels = batch_labels.float().unsqueeze(1)\n",
    "                batch_data = batch_data.to(device)\n",
    "                batch_labels = batch_labels.to(device)\n",
    "\n",
    "                outputs = model(batch_data)\n",
    "                predicted = (outputs > 0.5).float()  \n",
    "                total += batch_labels.size(0)\n",
    "                correct += (predicted == batch_labels).sum().item()\n",
    "                true_positive += ((predicted == 1) & (batch_labels == 1)).sum().item()\n",
    "                true_negative += ((predicted == 0) & (batch_labels == 0)).sum().item()\n",
    "                false_positive += ((predicted == 1) & (batch_labels == 0)).sum().item()\n",
    "                false_negative += ((predicted == 0) & (batch_labels == 1)).sum().item()\n",
    "\n",
    "        tpr = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "        tnr = true_negative / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0\n",
    "        accuracy = correct/total\n",
    "        \n",
    "        accuracy_dict[clique_id].append(accuracy)\n",
    "        tpr_dict[clique_id].append(tpr)\n",
    "        tnr_dict[clique_id].append(tnr)\n",
    "        print(\"finished clique_id:\", clique_id, \"trail:\", trail)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike_sorting_jct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
