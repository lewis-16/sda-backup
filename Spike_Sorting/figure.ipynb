{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4a4cfe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spikeinterface as si\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7f3f55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/01_real_data/01_flexible_probe_30_channels/spike_detection/eval_results/accuracy_dict.pkl\", 'rb') as f:\n",
    "    accuracy_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2223ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame()\n",
    "for month in accuracy_dict.keys():\n",
    "    if month != '062422' and month != '122022':\n",
    "        accuracy = pd.concat((accuracy, pd.DataFrame(accuracy_dict[month])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c65c4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list = ['021322', '022522', '031722', '042422', '052422', '072322',\n",
    "       '082322', '092422', '102122', '112022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f03669ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.columns = month_list\n",
    "accuracy = accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "38763b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(\"figure/chronic_accuracy_boxplot.pdf\") as pdf:\n",
    "    plt.figure(figsize=(20, 1.5), dpi = 300)\n",
    "    sns.boxplot(data=accuracy, showfliers  = False, boxprops=dict(facecolor=\"#70A5D9\"), width=0.5)\n",
    "    plt.xticks([])\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6e262703",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "file_name = []\n",
    "for i in range(1, 6):\n",
    "    file_list = os.listdir(f'/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/01_Neuroxenus_32_channels/spike_detection/eval_results/setting_{i}')\n",
    "    for file in set(file_list):\n",
    "        with open(f\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/01_Neuroxenus_32_channels/spike_detection/eval_results/setting_{i}/{file}\", 'rb') as f:\n",
    "            accuracy_dict = pickle.load(f)\n",
    "        accuracy_list.append(accuracy_dict['accuracy'])\n",
    "        file_name.append(file.split(\".\")[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "11beac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame(accuracy_list)\n",
    "accuracy.index = file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "15099838",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_order = ['val_results_Neuronexus_32_setting_1_recording',\n",
    " 'val_results_Neuronexus_32_20_cell_recording',\n",
    " 'val_results_Neuronexus_32_30_cell_recording',\n",
    " 'val_results_Neuronexus_32_40_cell_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_overlapthreshold_00_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_overlapthreshold_02_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_overlapthreshold_04_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_overlapthreshold_06_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_overlapthreshold_08_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_overlapthreshold_10_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_min_distance_10_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_min_distance_15_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_min_distance_20_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_noise_level_0_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_noise_level_10_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_noise_level_20_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_noise_level_30_recording',\n",
    " 'val_results_Neuronexus_32_50_cell_noise_level_40_recording']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "73c99ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy.loc[file_name_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f532e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(\"figure/simulation_30channel_accuracy_boxplot.pdf\") as pdf:\n",
    "    plt.figure(figsize=(10, 1.5), dpi = 300)\n",
    "    sns.boxplot(data=accuracy.T * 100, showfliers  = False, boxprops=dict(facecolor=\"#70A5D9\"), width=0.5)\n",
    "    plt.xticks([])\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "39bb35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "file_name = []\n",
    "for i in range(1, 6):\n",
    "    file_list = os.listdir(f'/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/01_Neuroxenus_32_channels/spike_classification/eval_results/setting_{i}')\n",
    "    for file in file_list:\n",
    "        if file.split(\"_\")[-1] == '5.pkl':\n",
    "            with open(f\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/01_Neuroxenus_32_channels/spike_classification/eval_results/setting_{i}/{file}\", 'rb') as f:\n",
    "                accuracy_dict = pickle.load(f)\n",
    "            accuracy_list.append(accuracy_dict)\n",
    "            file_name.append(file.split(\".\")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b8f56a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_order = ['Neuronexus_32_50_cell_recordings_accuracy_5',\n",
    " 'Neuronexus_32_20_recording_accuracy_5',\n",
    " 'Neuronexus_32_30_recording_accuracy_5',\n",
    " 'Neuronexus_32_40_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_overlapthreshold_00_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_overlapthreshold_02_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_overlapthreshold_04_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_overlapthreshold_06_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_overlapthreshold_08_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_overlapthreshold_10_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_min_distance_10_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_min_distance_15_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_min_distance_20_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_noise_level_0_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_noise_level_10_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_noise_level_20_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_noise_level_30_recording_accuracy_5',\n",
    " 'Neuronexus_32_50_cell_noise_level_40_recording_accuracy_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d0069720",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame(accuracy_list)\n",
    "accuracy.index = file_name\n",
    "accuracy = accuracy.loc[file_name_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "93a6bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(\"figure/simulation_30channel_accuracy_boxplot_spike_classification.pdf\") as pdf:\n",
    "    plt.figure(figsize=(10, 1.5), dpi = 300)\n",
    "    sns.boxplot(data=accuracy.T * 100, showfliers  = False, boxprops=dict(facecolor=\"#70A5D9\"), width=0.5)\n",
    "    plt.xticks([])\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "35d98f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/02_Neuropixel_384_channels/spike_detection/accuracy_dict.pkl\", 'rb') as f:\n",
    "    accuracy_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f7fb36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "for i in accuracy_dict.keys():\n",
    "    accuracy_list.extend(accuracy_dict[i])\n",
    "\n",
    "accuracy_list = np.array(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f8c95d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_classification_list = []\n",
    "for clique in os.listdir(\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/02_Neuropixel_384_channels/spike_classification/eval_result\"):\n",
    "    for trail in os.listdir(f'/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/02_Neuropixel_384_channels/spike_classification/eval_result/{clique}'):\n",
    "        if trail == 'accuracy_5.pkl':\n",
    "            with open(f'/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/02_Neuropixel_384_channels/spike_classification/eval_result/{clique}/{trail}', 'rb') as f:\n",
    "                accuracy = pickle.load(f)\n",
    "            accuracy_classification_list.extend(accuracy)\n",
    "\n",
    "accuracy_classification_list = np.array(accuracy_classification_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "df73d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.vstack((accuracy_list, accuracy_classification_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9a72f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages(\"figure/simulation_384channel_boxplot.pdf\") as pdf:\n",
    "    plt.figure(figsize=(2, 1.5), dpi=300)\n",
    "    sns.boxplot(\n",
    "        data=accuracy.T * 100,\n",
    "        showfliers=False,\n",
    "        width=0.5,\n",
    "        palette=[\"#70A5D9\", \"#F0868C\"]\n",
    "    )\n",
    "    plt.xticks([])\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5dd2ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict = []\n",
    "for id in os.listdir(\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/01_real_data/03_Neuropixel_384_channels_visual_stimuli/spike_detection/eval_result\"):\n",
    "    accuracy_list = []\n",
    "    with open(f\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/01_real_data/03_Neuropixel_384_channels_visual_stimuli/spike_detection/eval_result/{id}/accuracy_dict.pkl\", 'rb') as f:\n",
    "        accuracy = pickle.load(f)\n",
    "\n",
    "        for i in accuracy.keys():\n",
    "            accuracy_list.extend(accuracy[i])\n",
    "\n",
    "    accuracy_dict.append(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bee0a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, group in enumerate(accuracy_dict):\n",
    "    for value in group:\n",
    "        data.append({'group': f'group_{i+1}', 'accuracy': value})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "with PdfPages(\"figure/simulation_384channel_real_boxplot.pdf\") as pdf:\n",
    "    plt.figure(figsize=(6, 3), dpi=300)\n",
    "    sns.boxplot(x='group', y='accuracy', data=df, showfliers=False, boxprops=dict(facecolor='#70A5D9'), width=0.5)\n",
    "    plt.xticks([])\n",
    "    plt.ylim(0, 105)\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "41f221b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spikeinterface as si\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import sys\n",
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import time\n",
    "import pickle\n",
    "import networkx as nx\n",
    "# from function.Function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4cd02bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_raw = se.MEArecRecordingExtractor(file_path='/media/ubuntu/sda/Spike_Sorting/paper_architecture/02_simulation_data/02_Neuropixel_384_channels/data_generation/recording_neuropixels_type1.h5')\n",
    "probe_384channel = recording_raw.get_probegroup()\n",
    "clique_num_df = []\n",
    "for id in [810755797, 810755799, 810755801, 810755803, 810755805, 810755807]:\n",
    "    cluster_inf = pd.read_csv(f\"/media/ubuntu/sda/Spike_Sorting/paper_architecture/01_real_data/03_Neuropixel_384_channels_visual_stimuli/spike_sorting/{id}/cluster_inf.csv\", index_col=0)\n",
    "    probe_384channel = np.array(recording_raw.get_probegroup().to_dataframe().iloc[:, 1:3])\n",
    "    clique_num = []\n",
    "    for distance_threshold in [60, 80, 100, 120, 140, 160, 180, 200]:\n",
    "        eps=1e-5\n",
    "        dist_matrix = np.linalg.norm(probe_384channel[:, np.newaxis] - probe_384channel, axis=2)\n",
    "        np.fill_diagonal(dist_matrix, 0)\n",
    "        dist_matrix[dist_matrix < eps] = eps\n",
    "        inv_dist = np.zeros_like(dist_matrix)\n",
    "\n",
    "        inv_dist = np.where(dist_matrix > 0, 1, 0)\n",
    "        np.fill_diagonal(inv_dist, 0)  \n",
    "        if distance_threshold is not None:\n",
    "            inv_dist[dist_matrix > distance_threshold] = 0\n",
    "\n",
    "        graph = nx.from_numpy_array(inv_dist)\n",
    "        maximal_cliques = list(nx.find_cliques(graph))\n",
    "        cliques_dict = {i: clique for i, clique in enumerate(maximal_cliques)}\n",
    "\n",
    "        seen_results = {}  \n",
    "        unique_i_list = [] \n",
    "\n",
    "        for i in sorted(cliques_dict.keys()):  \n",
    "            probe_center = np.mean(probe_384channel[cliques_dict[i]], axis=0) \n",
    "            distance_threshold = 100  \n",
    "            \n",
    "            distances = np.linalg.norm(cluster_inf.iloc[:, [-2, -1]] - probe_center, axis=1)\n",
    "            indices_within_range = cluster_inf['cluster_id'].values[np.where(distances <= distance_threshold)[0]]\n",
    "            if len(indices_within_range) != 0:\n",
    "                result_tuple = tuple(sorted(indices_within_range))  \n",
    "                \n",
    "                if result_tuple not in seen_results:\n",
    "                    seen_results[result_tuple] = i  \n",
    "                    unique_i_list.append(i)      \n",
    "        clique_num.append(len(unique_i_list)) \n",
    "    clique_num_df.append(clique_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike_sorting_jct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
