{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e5f4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import PIL.Image as PImage\n",
    "from torchvision.datasets.folder import DatasetFolder, IMG_EXTENSIONS\n",
    "from torchvision.transforms import InterpolationMode, transforms\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2fb2dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 391 test trials\n",
      "Loaded 100 images\n",
      "CSV Mode - Train set: 312\n",
      "CSV Mode - Val set: 79\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class IntegratedNeuronDataset(Dataset):\n",
    "    def __init__(self, neuro_data, labels, image_source):\n",
    "\n",
    "        self.neuro_data = neuro_data\n",
    "        self.labels = labels\n",
    "        \n",
    "        self.image_paths = image_source\n",
    "\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x * 2 - 1)  \n",
    "        ])\n",
    "        \n",
    "        self.empty_image_tensor = torch.zeros(3, 256, 256, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.neuro_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        neuro_tensor = torch.tensor(self.neuro_data[idx], dtype=torch.float32).T\n",
    "        \n",
    "        image_label = self.labels[idx]\n",
    "        \n",
    "        image_path = self.image_paths[idx]\n",
    "        try:\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            img = img.resize((256, 256))\n",
    "            img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "            img_tensor = torch.from_numpy(img_array).permute(2, 0, 1)\n",
    "            img_tensor = img_tensor * 2 - 1\n",
    "        except (FileNotFoundError, OSError) as e:\n",
    "            img_tensor = self.empty_image_tensor.clone()\n",
    "            print(f\"Warning: {image_path} not found or corrupted: {e}\")\n",
    "        \n",
    "        return neuro_tensor, img_tensor, image_label\n",
    "\n",
    "def load_firing_rate_data(firing_rate_path, train=True):\n",
    "    with open(firing_rate_path, 'rb')as f:\n",
    "        firing_rate = pickle.load(f)\n",
    "\n",
    "    firing_rate_list = []\n",
    "    label = []\n",
    "    \n",
    "    if train:\n",
    "        split_str = 'train'\n",
    "    else:\n",
    "        split_str = 'test'\n",
    "    \n",
    "    for key in firing_rate.keys():\n",
    "        if split_str in key:\n",
    "            firing_rate_data = firing_rate[key]['firing_rate']\n",
    "            if len(firing_rate_data.shape) == 2 and firing_rate_data.shape[0] == 244 and firing_rate_data.shape[1] == 20:\n",
    "                label.append(firing_rate[key]['image_id'])\n",
    "                firing_rate_list.append(firing_rate_data)\n",
    "            elif len(firing_rate_data.shape) == 2 and firing_rate_data.shape[0] == 244 and firing_rate_data.shape[1] == 21:\n",
    "                label.append(firing_rate[key]['image_id'])\n",
    "                firing_rate_list.append(firing_rate_data[:, :-1])\n",
    "    \n",
    "    print(f\"Loaded {len(firing_rate_list)} {split_str} trials\")\n",
    "    return firing_rate_list, label\n",
    "\n",
    "\n",
    "def load_image_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    image_labels = np.array(df.index) + 1\n",
    "    image_paths = df['local_path'].values\n",
    "    image_class = df['class'].values\n",
    "    \n",
    "    print(f\"Loaded {len(image_labels)} images\")\n",
    "    \n",
    "    return image_labels, image_paths, image_class\n",
    "\n",
    "\n",
    "def create_integrated_datasets(firing_rate_path=None, csv_path=None,\n",
    "                             test_size=0.2, random_state=42):\n",
    "    \n",
    "    neuro_data, labels = load_firing_rate_data(firing_rate_path, train=False)\n",
    "    image_labels, image_paths, _ = load_image_data(csv_path)\n",
    "    image_source = []\n",
    "\n",
    "    for label in labels:\n",
    "        image_source.append(image_paths[np.where(image_labels == int(label))[0]][0])\n",
    "    \n",
    "    train_indices, val_indices = train_test_split(\n",
    "        range(len(labels)), test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    train_dataset = IntegratedNeuronDataset(\n",
    "        neuro_data=[neuro_data[i] for i in train_indices],\n",
    "        labels=[labels[i] for i in train_indices],\n",
    "        image_source=[image_source[i] for i in train_indices],\n",
    "    )\n",
    "    \n",
    "    val_dataset = IntegratedNeuronDataset(\n",
    "        neuro_data=[neuro_data[i] for i in val_indices],\n",
    "        labels=[labels[i] for i in val_indices],\n",
    "        image_source=[image_source[i] for i in val_indices],\n",
    "    )\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "firing_rate_path = \"./firing_rate_summary_0112.pkl\"\n",
    "csv_path = \"/media/ubuntu/sda/Monkey/scripts/test_image.csv\"\n",
    "\n",
    "train_dataset_csv, val_dataset_csv = create_integrated_datasets(\n",
    "    firing_rate_path=firing_rate_path, \n",
    "    csv_path=csv_path\n",
    ")\n",
    "\n",
    "print(f\"CSV Mode - Train set: {len(train_dataset_csv)}\")\n",
    "print(f\"CSV Mode - Val set: {len(val_dataset_csv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0db3be0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28msetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreset_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m)     \u001b[38;5;66;03m# disable default parameter init for faster speed\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28msetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLayerNorm, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreset_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mself\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# disable default parameter init for faster speed\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VQVAE, build_vae_var\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEP_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelConfig\n\u001b[1;32m     13\u001b[0m ep_config \u001b[38;5;241m=\u001b[39m ModelConfig(\n\u001b[1;32m     14\u001b[0m         input_neuron\u001b[38;5;241m=\u001b[39mtrain_dataset_csv\u001b[38;5;241m.\u001b[39mneuro_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],  \u001b[38;5;66;03m# 244个神经元\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         time_bins\u001b[38;5;241m=\u001b[39mtrain_dataset_csv\u001b[38;5;241m.\u001b[39mneuro_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],    \u001b[38;5;66;03m# 20个时间bin\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m         epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     28\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import torch, torchvision\n",
    "import random\n",
    "import numpy as np\n",
    "import PIL.Image as PImage, PIL.ImageDraw as PImageDraw\n",
    "setattr(torch.nn.Linear, 'reset_parameters', lambda self: None)     # disable default parameter init for faster speed\n",
    "setattr(torch.nn.LayerNorm, 'reset_parameters', lambda self: None)  # disable default parameter init for faster speed\n",
    "from models import VQVAE, build_vae_var\n",
    "from models.EP_encoder import ModelConfig\n",
    "\n",
    "\n",
    "ep_config = ModelConfig(\n",
    "        input_neuron=train_dataset_csv.neuro_data[0].shape[0],  # 244个神经元\n",
    "        time_bins=train_dataset_csv.neuro_data[0].shape[1],    # 20个时间bin\n",
    "        d_model=150,\n",
    "        nhead=10,\n",
    "        num_transformer_layers=2, \n",
    "        conv_channels=64,\n",
    "        num_conv_blocks=3,\n",
    "        num_classes=117,\n",
    "        residual_dims=[256, 512, 1024],\n",
    "        use_positional_encoding=True,\n",
    "        dim_feedforward_ratio=4,\n",
    "        activation='relu',\n",
    "        lr=1e-5,  \n",
    "        epochs=50\n",
    "    )\n",
    "\n",
    "MODEL_DEPTH = 16    # TODO: =====> please specify MODEL_DEPTH <=====\n",
    "\n",
    "\n",
    "# download checkpoint\n",
    "vae_ckpt, var_ckpt = 'vae_ch160v4096z32.pth', f'var_d{MODEL_DEPTH}.pth'\n",
    "\n",
    "# build vae, var\n",
    "FOR_512_px = MODEL_DEPTH == 16\n",
    "# if FOR_512_px:\n",
    "#     patch_nums = (1, 2, 3, 4, 6, 9, 13, 18, 24, 32)\n",
    "# else:\n",
    "#     patch_nums = (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)\n",
    "\n",
    "patch_nums = (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "vae, var = build_vae_var(\n",
    "    V=4096, Cvae=32, ch=160, share_quant_resi=4,    # hard-coded VQVAE hyperparameters\n",
    "    device=device, patch_nums=patch_nums,\n",
    "    num_classes=1000, depth=MODEL_DEPTH, shared_aln=FOR_512_px,\n",
    "    config= ep_config\n",
    ")\n",
    "\n",
    "# load checkpoints\n",
    "vae.load_state_dict(torch.load(vae_ckpt, map_location='cpu'), strict=True)\n",
    "#var.load_state_dict(torch.load(var_ckpt, map_location='cpu'), strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfig:\n",
    "    batch_size = 8\n",
    "    num_workers = 0\n",
    "    image_size = 256\n",
    "    dataset_path = \"/disk1/jinchentao/visual_decode/visual_reconstruction\"\n",
    "    \n",
    "    # 多GPU配置\n",
    "    distributed = True\n",
    "    backend = 'nccl' \n",
    "    init_method = 'env://'\n",
    "    \n",
    "    vae_config = {\n",
    "        \"in_channel\": 3,\n",
    "        \"channel\": 128,\n",
    "        \"n_res_block\": 2,\n",
    "        \"n_res_channel\": 64,\n",
    "        \"embed_dim\": 64,\n",
    "        \"n_embed\": 8192,\n",
    "        \"decay\": 0.99\n",
    "    }\n",
    "    var_config = {\n",
    "        \"num_classes\": 1000,\n",
    "        \"depth\": 16,\n",
    "        \"embed_dim\": 1024,\n",
    "        \"num_heads\": 16,\n",
    "        \"mlp_ratio\": 4.0,\n",
    "        \"drop_rate\": 0.1,\n",
    "        \"attn_drop_rate\": 0.0,\n",
    "        \"drop_path_rate\": 0.1,\n",
    "        \"norm_eps\": 1e-6,\n",
    "        \"shared_aln\": True,\n",
    "        \"cond_drop_rate\": 0.1,\n",
    "        \"attn_l2_norm\": False,\n",
    "        \"patch_nums\": (1, 2, 3, 4, 5, 6, 8, 10, 13, 16),\n",
    "        \"flash_if_available\": True,\n",
    "        \"fused_if_available\": True,\n",
    "    }\n",
    "    \n",
    "    lr = 1e-4\n",
    "    weight_decay = 0.05\n",
    "    betas = (0.9, 0.95)\n",
    "    \n",
    "    epochs = 60\n",
    "    grad_accum = 1\n",
    "    label_smooth = 0.1\n",
    "    amp_enabled = True\n",
    "    \n",
    "    prog_epochs = 5 \n",
    "    prog_warmup_iters = 1000  \n",
    "    \n",
    "    log_interval = 50\n",
    "    eval_interval = 1\n",
    "    save_interval = 5\n",
    "    checkpoint_dir = \"checkpoints\"\n",
    "    log_dir = \"logs\"\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85abf09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VARTrainer(object):\n",
    "    def __init__(\n",
    "        self, device, patch_nums, resos,\n",
    "        vae_local, var_model,\n",
    "        optimizer: torch.optim.Optimizer, label_smooth: float,\n",
    "        amp_enabled: bool = False, rank: int = 0\n",
    "    ):\n",
    "        super(VARTrainer, self).__init__()\n",
    "        \n",
    "        self.var_model = var_model\n",
    "        self.vae_local = vae_local\n",
    "        self.quantize_local = vae_local.quantize\n",
    "        self.optimizer = optimizer\n",
    "        self.amp_enabled = amp_enabled\n",
    "        self.device = device\n",
    "        self.rank = rank\n",
    "        \n",
    "        # 修复：检查模型是否有rng属性\n",
    "        if hasattr(self.var_model, 'rng'):\n",
    "            self.var_model.rng = torch.Generator(device=device)\n",
    "        \n",
    "        self.label_smooth = label_smooth\n",
    "        self.train_loss = nn.CrossEntropyLoss(label_smoothing=label_smooth, reduction='none')\n",
    "        self.val_loss = nn.CrossEntropyLoss(label_smoothing=0.0, reduction='mean')\n",
    "        \n",
    "        self.L = sum(pn * pn for pn in patch_nums)\n",
    "        self.last_l = patch_nums[-1] * patch_nums[-1]\n",
    "        self.loss_weight = torch.ones(1, self.L, device=device) / self.L\n",
    "        \n",
    "        self.patch_nums, self.resos = patch_nums, resos\n",
    "        self.begin_ends = []\n",
    "        cur = 0\n",
    "        for i, pn in enumerate(patch_nums):\n",
    "            self.begin_ends.append((cur, cur + pn * pn))\n",
    "            cur += pn*pn\n",
    "        \n",
    "        self.prog_it = 0\n",
    "        self.last_prog_si = -1\n",
    "        self.first_prog = True\n",
    "        \n",
    "        # 使用新的GradScaler API\n",
    "        self.scaler = torch.amp.GradScaler('cuda', enabled=amp_enabled)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def eval_ep(self, ld_val: DataLoader):\n",
    "        tot = 0\n",
    "        L_mean, L_tail, acc_mean, acc_tail = 0, 0, 0, 0\n",
    "        stt = time.time()\n",
    "        training = self.var_model.training\n",
    "        self.var_model.eval()\n",
    "        \n",
    "        for neuron_activity, inp_B3HW, _  in ld_val:\n",
    "            B, V = neuron_activity.shape[0], self.vae_local.vocab_size\n",
    "            inp_B3HW = inp_B3HW.to(self.device)\n",
    "            neuron_activity = neuron_activity.to(self.device)\n",
    "            \n",
    "            # 修复：检查模型是否有img_to_idxBl方法\n",
    "            if hasattr(self.vae_local, 'img_to_idxBl'):\n",
    "                gt_idx_Bl: List[torch.Tensor] = self.vae_local.img_to_idxBl(inp_B3HW)\n",
    "                gt_BL = torch.cat(gt_idx_Bl, dim=1)\n",
    "                x_BLCv_wo_first_l = self.quantize_local.idxBl_to_var_input(gt_idx_Bl)\n",
    "            else:\n",
    "                # 如果没有img_to_idxBl方法，使用简化的处理\n",
    "                gt_BL = torch.zeros(B, self.L, dtype=torch.long, device=self.device)\n",
    "                x_BLCv_wo_first_l = torch.zeros(B, self.L, 32, device=self.device)\n",
    "            \n",
    "            logits_BLV = self.var_model(neuron_activity, x_BLCv_wo_first_l)\n",
    "            \n",
    "            L_mean += self.val_loss(logits_BLV.view(-1, V), gt_BL.view(-1)).item() * B\n",
    "            L_tail += self.val_loss(\n",
    "                logits_BLV[:, -self.last_l:].reshape(-1, V), \n",
    "                gt_BL[:, -self.last_l:].reshape(-1)\n",
    "            ).item() * B\n",
    "            acc_mean += (logits_BLV.argmax(dim=-1) == gt_BL).float().mean().item() * 100 * B\n",
    "            acc_tail += (\n",
    "                logits_BLV[:, -self.last_l:].argmax(dim=-1) == gt_BL[:, -self.last_l:]\n",
    "            ).float().mean().item() * 100 * B\n",
    "            tot += B\n",
    "        \n",
    "        self.var_model.train(training)\n",
    "        \n",
    "        L_mean /= tot\n",
    "        L_tail /= tot\n",
    "        acc_mean /= tot\n",
    "        acc_tail /= tot\n",
    "        \n",
    "        return L_mean, L_tail, acc_mean, acc_tail, tot, time.time()-stt\n",
    "\n",
    "    def train_step(\n",
    "        self, it: int, g_it: int, stepping: bool,\n",
    "        inp_B3HW: torch.Tensor, neuron_activity: torch.Tensor, prog_si: int, prog_wp_it: float\n",
    "    ):\n",
    "        # 修复：检查模型是否有prog_si属性\n",
    "        if hasattr(self.var_model, 'prog_si'):\n",
    "            self.var_model.prog_si = prog_si\n",
    "        if hasattr(self.vae_local.quantize, 'prog_si'):\n",
    "            self.vae_local.quantize.prog_si = prog_si\n",
    "            \n",
    "        if self.last_prog_si != prog_si:\n",
    "            if self.last_prog_si != -1: \n",
    "                self.first_prog = False\n",
    "            self.last_prog_si = prog_si\n",
    "            self.prog_it = 0\n",
    "        self.prog_it += 1\n",
    "        \n",
    "        prog_wp = max(min(self.prog_it / prog_wp_it, 1), 0.01)\n",
    "        if self.first_prog: \n",
    "            prog_wp = 1\n",
    "        if prog_si == len(self.patch_nums) - 1: \n",
    "            prog_si = -1 \n",
    "\n",
    "        B, V = neuron_activity.shape[0], self.vae_local.vocab_size\n",
    "        \n",
    "        # 使用新的autocast API\n",
    "        with torch.amp.autocast('cuda', enabled=False):\n",
    "            # 修复：检查模型是否有img_to_idxBl方法\n",
    "            if hasattr(self.vae_local, 'img_to_idxBl'):\n",
    "                gt_idx_Bl = self.vae_local.img_to_idxBl(inp_B3HW)\n",
    "                gt_BL = torch.cat(gt_idx_Bl, dim=1)\n",
    "                x_BLCv_wo_first_l = self.quantize_local.idxBl_to_var_input(gt_idx_Bl)\n",
    "            else:\n",
    "                # 如果没有img_to_idxBl方法，使用简化的处理\n",
    "                gt_BL = torch.zeros(B, self.L, dtype=torch.long, device=self.device)\n",
    "                x_BLCv_wo_first_l = torch.zeros(B, self.L, 32, device=self.device)\n",
    "            \n",
    "            logits_BLV = self.var_model(neuron_activity, x_BLCv_wo_first_l)\n",
    "\n",
    "            pred_BL = logits_BLV.argmax(dim=-1)\n",
    "            accuracy = (pred_BL == gt_BL).float().mean().item() * 100\n",
    "            loss = self.train_loss(logits_BLV.view(-1, V), gt_BL.view(-1)).view(B, -1)\n",
    "            \n",
    "            if prog_si >= 0:\n",
    "                bg, ed = self.begin_ends[prog_si]\n",
    "                lw = self.loss_weight[:, :ed].clone()\n",
    "                lw[:, bg:ed] *= prog_wp\n",
    "            else:\n",
    "                lw = self.loss_weight\n",
    "                \n",
    "            loss = loss.mul(lw).sum(dim=-1).mean()\n",
    "\n",
    "        self.scaler.scale(loss).backward()\n",
    "        \n",
    "        grad_norm = 0\n",
    "        if stepping:\n",
    "            self.scaler.unscale_(self.optimizer)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                self.var_model.parameters(), max_norm=1.0\n",
    "            ).item()\n",
    "            \n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            self.optimizer.zero_grad()\n",
    "        \n",
    "        # 修复：检查模型是否有prog_si属性\n",
    "        if hasattr(self.var_model, 'prog_si'):\n",
    "            self.var_model.prog_si = -1\n",
    "        if hasattr(self.vae_local.quantize, 'prog_si'):\n",
    "            self.vae_local.quantize.prog_si = -1\n",
    "            \n",
    "        return loss.item(), accuracy, grad_norm, self.scaler.get_scale()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ccac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_gpu(config, vae, var_model, train_dataset, val_dataset):\n",
    "    torch.manual_seed(config.seed)\n",
    "    if config.device == \"cuda\":\n",
    "        torch.cuda.manual_seed_all(config.seed)\n",
    "    \n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(\n",
    "        var_model.parameters(),\n",
    "        lr=config.lr,\n",
    "        weight_decay=config.weight_decay,\n",
    "        betas=config.betas\n",
    "    )\n",
    "    \n",
    "    trainer = VARTrainer(\n",
    "        device=config.device,\n",
    "        patch_nums=config.var_config[\"patch_nums\"],\n",
    "        resos=(16, 32, 48, 64, 80, 96, 128, 160, 208, 256),\n",
    "        vae_local=vae,\n",
    "        var_model=var,\n",
    "        optimizer=optimizer,\n",
    "        label_smooth=config.label_smooth,\n",
    "        amp_enabled=config.amp_enabled\n",
    "    )\n",
    "    \n",
    "    \n",
    "    global_step = 0\n",
    "    for epoch in range(config.epochs):\n",
    "        var_model.train()        \n",
    "        prog_si = min(epoch // config.prog_epochs + 1, len(config.var_config[\"patch_nums\"]) - 1)\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        epoch_acc = 0.0\n",
    "        epoch_samples = 0\n",
    "        \n",
    "        for i, (neuron_activity, images, _) in enumerate(train_loader):\n",
    "            images = images.to(config.device, non_blocking=True)\n",
    "            neuron_activity = neuron_activity.to(config.device, non_blocking=True)\n",
    "            \n",
    "            stepping = (i + 1) % config.grad_accum == 0\n",
    "            \n",
    "            loss_value, accuracy, grad_norm, scale = trainer.train_step(\n",
    "                it=i,\n",
    "                g_it=global_step,\n",
    "                stepping=stepping,\n",
    "                inp_B3HW=images,\n",
    "                neuron_activity=neuron_activity,\n",
    "                prog_si=prog_si,\n",
    "                prog_wp_it=config.prog_warmup_iters\n",
    "            )\n",
    "            \n",
    "            batch_size = images.size(0)\n",
    "            epoch_loss += loss_value * batch_size\n",
    "            epoch_acc += accuracy * batch_size\n",
    "            epoch_samples += batch_size\n",
    "\n",
    "            global_step += 1\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / epoch_samples\n",
    "        avg_epoch_acc = epoch_acc / epoch_samples\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch}/{config.epochs} Training: \"\n",
    "              f\"Loss = {avg_epoch_loss:.4f} \"\n",
    "              f\"Acc = {avg_epoch_acc:.2f}%\")\n",
    "\n",
    "        if epoch % config.eval_interval == 0:\n",
    "            var_model.eval()\n",
    "            L_mean, L_tail, acc_mean, acc_tail, tot, eval_time = trainer.eval_ep(val_loader)\n",
    "            print(f\"\\nEpoch {epoch} Validation: \"\n",
    "                  f\"Loss = {L_mean:.4f}/{L_tail:.4f} \"\n",
    "                  f\"Acc = {acc_mean:.2f}%/{acc_tail:.2f}% \"\n",
    "                  f\"Time = {eval_time:.1f}s\\n\")\n",
    "            \n",
    "        \n",
    "        # if epoch % config.save_interval == 0:\n",
    "        #     checkpoint = {\n",
    "        #         \"epoch\": epoch,\n",
    "        #         \"model\": trainer.state_dict(),\n",
    "        #         \"optimizer\": optimizer.state_dict(),\n",
    "        #         \"scaler\": trainer.scaler.state_dict()\n",
    "        #     }\n",
    "        #     torch.save(checkpoint, f\"{config.checkpoint_dir}/ckpt_epoch{epoch}.pth\")\n",
    "        #     print(f\"Saved checkpoint at epoch {epoch}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c164e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = TrainingConfig()\n",
    "\n",
    "train_single_gpu(config, vae=vae, var_model=var, train_dataset=train_dataset_csv, val_dataset=val_dataset_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dfb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loader = DataLoader(\n",
    "#         train_dataset_csv,\n",
    "#         batch_size=config.batch_size,\n",
    "#         shuffle=False,\n",
    "#         num_workers=config.num_workers,\n",
    "#         pin_memory=True\n",
    "#     )\n",
    "\n",
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# vae.eval()\n",
    "# var.eval()\n",
    "# pdf_path = \"reconstruction_results_utah.pdf\"\n",
    "# with PdfPages(pdf_path) as pdf:\n",
    "#     for i, (neuron_activity, images, labels) in enumerate(val_loader):\n",
    "#         neuron_activity = neuron_activity.to(device)\n",
    "#         images = images.to(device)\n",
    "#         label_B = neuron_activity\n",
    "#         B = len(label_B)\n",
    "#         cfg = 5\n",
    "#         recon_B3HW = var.autoregressive_infer_cfg(B=B, neuron_activity=neuron_activity, cfg=cfg, top_k=1000, top_p=0.99, more_smooth=True)\n",
    "        \n",
    "#         for i in range(B):\n",
    "#             fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "#             axes[0].imshow(images[i, 0].cpu().detach().numpy(), cmap='gray')\n",
    "#             axes[0].set_title(\"Original\")\n",
    "#             axes[0].axis('off')\n",
    "#             axes[1].imshow(recon_B3HW[i, 2].cpu().detach().numpy(), cmap='gray')\n",
    "#             axes[1].set_title(\"Reconstructed\")\n",
    "#             axes[1].axis('off')\n",
    "#             plt.tight_layout()\n",
    "#             pdf.savefig(fig)\n",
    "#             plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visual_decoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
