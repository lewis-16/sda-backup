{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80b9ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class NeuronDataset(Dataset):\n",
    "    def __init__(self, firing_rate_data, image_labels, image_paths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            firing_rate_data: numpy array of shape (n_trials, n_neurons, n_timebins)\n",
    "            image_labels: list/array of image class labels\n",
    "            image_paths: list/array of image file paths\n",
    "        \"\"\"\n",
    "        self.firing_rate_data = firing_rate_data\n",
    "        self.image_labels = image_labels\n",
    "        self.image_paths = image_paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.firing_rate_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 神经元数据: (n_neurons, n_timebins) -> (n_timebins, n_neurons)\n",
    "        neuro_tensor = torch.tensor(self.firing_rate_data[idx], dtype=torch.float32).T\n",
    "        \n",
    "        # 图像标签和路径\n",
    "        image_label = self.image_labels[idx]\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "            # 手动 resize 和转换为 tensor\n",
    "            img = img.resize((256, 256))\n",
    "            img_array = np.array(img, dtype=np.float32) / 255.0  # 归一化到 [0,1]\n",
    "            img_tensor = torch.from_numpy(img_array).permute(2, 0, 1)  # HWC -> CHW\n",
    "            img_tensor = img_tensor * 2 - 1  # 归一化到 [-1,1]\n",
    "        except (FileNotFoundError, OSError) as e:\n",
    "            # 创建空白图像\n",
    "            img_tensor = torch.zeros(3, 256, 256)\n",
    "            print(f\"Warning: {image_path} not found or corrupted: {e}\")\n",
    "        \n",
    "        return neuro_tensor, img_tensor, image_label\n",
    "\n",
    "\n",
    "def load_firing_rate_data(npz_path, train = True):\n",
    "    \"\"\"加载 firing rate 数据并筛选有效试次\"\"\"\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    firing_rate_list = []\n",
    "    label = []\n",
    "    # 获取所有 firing rate 键\n",
    "    firing_rate_keys = [k for k in data.files if k.endswith('__firing_rate')]\n",
    "    firing_rate_keys = sorted(firing_rate_keys)\n",
    "    \n",
    "    if train:\n",
    "        train = 'train'\n",
    "    else:\n",
    "        train = 'test'\n",
    "    \n",
    "    for key in firing_rate_keys:\n",
    "        if train in key:\n",
    "            temp = data[key]\n",
    "\n",
    "            if np.sum(temp[:100, :]) != 0:\n",
    "                label.append(key.split(\"__\")[0])\n",
    "                firing_rate_list.append(temp[:, :10])\n",
    "    \n",
    "    return firing_rate_list, label\n",
    "\n",
    "\n",
    "def load_image_data(csv_path):\n",
    "    \"\"\"加载图像数据\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 提取 class 和 local_path\n",
    "    image_labels = df['class'].values\n",
    "    image_paths = df['local_path'].values\n",
    "    \n",
    "    print(f\"Loaded {len(image_labels)} images from {csv_path}\")\n",
    "    \n",
    "    return image_labels, image_paths\n",
    "\n",
    "\n",
    "def create_datasets(npz_path, csv_path, test_size=0.2, random_state=42):\n",
    "    \"\"\"创建训练和验证数据集\"\"\"\n",
    "    \n",
    "    # 加载数据\n",
    "    firing_rate_data, label = load_firing_rate_data(npz_path)\n",
    "    image_labels, image_paths = load_image_data(csv_path)\n",
    "    \n",
    "    # 分割训练和验证集\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        range(len(label)), test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    train_dataset = NeuronDataset(\n",
    "        [firing_rate_data[i] for i in train_indices],\n",
    "        [image_labels[i] for i in train_indices],\n",
    "        [image_paths[i] for i in train_indices]\n",
    "    )\n",
    "    \n",
    "    val_dataset = NeuronDataset(\n",
    "        [firing_rate_data[i] for i in val_indices],\n",
    "        [image_labels[i] for i in val_indices],\n",
    "        [image_paths[i] for i in val_indices]\n",
    "    )\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45b3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 22248 images from /media/ubuntu/sda/Monkey/scripts/train_image.csv\n",
      "Train set: 251\n",
      "Val set: 63\n",
      "Neuro tensor shape: torch.Size([2, 10, 204])\n",
      "Image shape: torch.Size([2, 3, 256, 256])\n",
      "Labels: ('album', 'airplane')\n"
     ]
    }
   ],
   "source": [
    "npz_path = \"/media/ubuntu/sda/Monkey/sorted_result/20240112/Block_1/sort/firing_rate_dict_B1_V1_instant_20ms.npz\"\n",
    "csv_path = \"/media/ubuntu/sda/Monkey/scripts/train_image.csv\"\n",
    "\n",
    "train_dataset, val_dataset = create_datasets(npz_path, csv_path)\n",
    "\n",
    "print(f\"Train set: {len(train_dataset)}\")\n",
    "print(f\"Val set: {len(val_dataset)}\")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "for neuro_tensor, img, label in train_loader:\n",
    "    print(f\"Neuro tensor shape: {neuro_tensor.shape}\")\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    print(f\"Labels: {label}\")\n",
    "    break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visual_decoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
