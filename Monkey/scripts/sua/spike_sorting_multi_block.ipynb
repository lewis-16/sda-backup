{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import spikeinterface.extractors as se\n",
        "import spikeinterface as si\n",
        "import spikeinterface.sorters as ss\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "配置参数:\n",
            "  猴子: monkeyF\n",
            "  日期: 20240115\n",
            "  基础目录: /media/ubuntu/sda/Monkey/TVSD\n",
            "  输出目录: /media/ubuntu/sda/Monkey/sorted_result_combined\n",
            "  Probe文件: /media/ubuntu/sda/Monkey/scripts/probe_256.json\n",
            "  映射文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/_logs/1024chns_mapping_20220105.mat\n"
          ]
        }
      ],
      "source": [
        "# 配置参数\n",
        "monkey = 'monkeyF'\n",
        "date = '20240115'  # 可以修改为其他日期\n",
        "base_dir = '/media/ubuntu/sda/Monkey/TVSD'\n",
        "output_base_dir = '/media/ubuntu/sda/Monkey/sorted_result_combined'\n",
        "probe_file = '/media/ubuntu/sda/Monkey/scripts/probe_256.json'\n",
        "mapping_file = '/media/ubuntu/sda/Monkey/TVSD/monkeyF/_logs/1024chns_mapping_20220105.mat'\n",
        "\n",
        "print(f\"配置参数:\")\n",
        "print(f\"  猴子: {monkey}\")\n",
        "print(f\"  日期: {date}\")\n",
        "print(f\"  基础目录: {base_dir}\")\n",
        "print(f\"  输出目录: {output_base_dir}\")\n",
        "print(f\"  Probe文件: {probe_file}\")\n",
        "print(f\"  映射文件: {mapping_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "数据目录: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115\n",
            "输出目录: /media/ubuntu/sda/Monkey/sorted_result_combined/20240115\n",
            "映射数组形状: (1024,)\n",
            "脑区数组形状: (1024,)\n",
            "Probe配置已加载\n"
          ]
        }
      ],
      "source": [
        "# 设置路径和加载配置文件\n",
        "data_dir = Path(base_dir) / monkey / date\n",
        "output_dir = Path(output_base_dir) / date\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 加载映射文件\n",
        "mapping_data = sio.loadmat(mapping_file)\n",
        "mapping = mapping_data['mapping'].flatten() - 1  # 转换为0-based索引\n",
        "\n",
        "# 定义脑区映射\n",
        "if monkey == 'monkeyN':\n",
        "    rois = np.ones(1024)  # V1\n",
        "    rois[512:768] = 2  # V4 (513-768)\n",
        "    rois[768:1024] = 3  # IT (769-1024)\n",
        "else:\n",
        "    rois = np.ones(1024)  # V1\n",
        "    rois[512:832] = 3  # IT (513-832)\n",
        "    rois[832:1024] = 2  # V4 (833-1024)\n",
        "\n",
        "# 加载probe配置\n",
        "with open(probe_file, 'r') as f:\n",
        "    probe_config = json.load(f)\n",
        "\n",
        "print(f\"数据目录: {data_dir}\")\n",
        "print(f\"输出目录: {output_dir}\")\n",
        "print(f\"映射数组形状: {mapping.shape}\")\n",
        "print(f\"脑区数组形状: {rois.shape}\")\n",
        "print(f\"Probe配置已加载\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "找到 5 个Block: ['Block_1', 'Block_2', 'Block_3', 'Block_4', 'Block_5']\n",
            "Hub-instance组合: [('Hub1', 'instance1'), ('Hub1', 'instance2'), ('Hub2', 'instance1'), ('Hub2', 'instance2')]\n",
            "\n",
            "检查 Hub1-instance1:\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_1/Hub1-instance1_B001.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_2/Hub1-instance1_B002.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_3/Hub1-instance1_B003.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_4/Hub1-instance1_B004.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub1-instance1_B005.ns6\n",
            "\n",
            "检查 Hub1-instance2:\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_1/Hub1-instance2_B001.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_2/Hub1-instance2_B002.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_3/Hub1-instance2_B003.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_4/Hub1-instance2_B004.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub1-instance2_B005.ns6\n",
            "\n",
            "检查 Hub2-instance1:\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_1/Hub2-instance1_B001.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_2/Hub2-instance1_B002.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_3/Hub2-instance1_B003.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_4/Hub2-instance1_B004.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub2-instance1_B005.ns6\n",
            "\n",
            "检查 Hub2-instance2:\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_1/Hub2-instance2_B001.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_2/Hub2-instance2_B002.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_3/Hub2-instance2_B003.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_4/Hub2-instance2_B004.ns6\n",
            "  ✓ /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub2-instance2_B005.ns6\n"
          ]
        }
      ],
      "source": [
        "# 获取所有Block目录\n",
        "block_dirs = sorted([d for d in data_dir.iterdir() if d.is_dir() and d.name.startswith('Block_')])\n",
        "print(f\"找到 {len(block_dirs)} 个Block: {[d.name for d in block_dirs]}\")\n",
        "\n",
        "# 定义Hub-instance组合\n",
        "hub_instance_combinations = [\n",
        "    ('Hub1', 'instance1'),\n",
        "    ('Hub1', 'instance2'), \n",
        "    ('Hub2', 'instance1'),\n",
        "    ('Hub2', 'instance2')\n",
        "]\n",
        "\n",
        "print(f\"Hub-instance组合: {hub_instance_combinations}\")\n",
        "\n",
        "# 检查文件是否存在\n",
        "for hub_name, instance_name in hub_instance_combinations:\n",
        "    print(f\"\\n检查 {hub_name}-{instance_name}:\")\n",
        "    for block_dir in block_dirs:\n",
        "        block_num = block_dir.name.split('_')[1]\n",
        "        file_pattern = f\"{hub_name}-{instance_name}_B{block_num.zfill(3)}.ns6\"\n",
        "        file_path = block_dir / file_pattern\n",
        "        exists = \"✓\" if file_path.exists() else \"✗\"\n",
        "        print(f\"  {exists} {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "处理函数已定义\n"
          ]
        }
      ],
      "source": [
        "# 处理单个Hub-instance组合的函数\n",
        "def process_hub_instance(hub_name, instance_name):\n",
        "    \"\"\"处理单个Hub-instance组合的数据\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"处理 {hub_name}-{instance_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # 收集所有Block中该Hub-instance的文件\n",
        "    recording_files = []\n",
        "    for block_dir in block_dirs:\n",
        "        block_num = block_dir.name.split('_')[1]\n",
        "        file_pattern = f\"{hub_name}-{instance_name}_B{block_num.zfill(3)}.ns6\"\n",
        "        file_path = block_dir / file_pattern\n",
        "        \n",
        "        if file_path.exists():\n",
        "            recording_files.append(file_path)\n",
        "            print(f\"  找到文件: {file_path}\")\n",
        "        else:\n",
        "            print(f\"  警告: 未找到文件 {file_path}\")\n",
        "    \n",
        "    if not recording_files:\n",
        "        print(f\"  跳过 {hub_name}-{instance_name}: 未找到任何文件\")\n",
        "        return None\n",
        "    \n",
        "    # 读取并合并所有Block的recording\n",
        "    recordings = []\n",
        "    for file_path in recording_files:\n",
        "        print(f\"  读取文件: {file_path}\")\n",
        "        recording = se.read_blackrock(file_path)\n",
        "        \n",
        "        # 处理多段数据\n",
        "        if recording.get_num_segments() > 1:\n",
        "            recording_list = []\n",
        "            for i in range(recording.get_num_segments()):\n",
        "                recording_list.append(recording.select_segments(i))\n",
        "            recording = si.concatenate_recordings(recording_list)\n",
        "        \n",
        "        recordings.append(recording)\n",
        "    \n",
        "    # 合并所有recording\n",
        "    print(f\"  合并 {len(recordings)} 个recording...\")\n",
        "    combined_recording = si.concatenate_recordings(recordings)\n",
        "    \n",
        "    # 确定当前Hub-instance的脑区\n",
        "    if hub_name == 'Hub1' and instance_name == 'instance1':\n",
        "        file_start_idx = 0\n",
        "    elif hub_name == 'Hub2' and instance_name == 'instance1':\n",
        "        file_start_idx = 256\n",
        "    elif hub_name == 'Hub1' and instance_name == 'instance2':\n",
        "        file_start_idx = 512\n",
        "    elif hub_name == 'Hub2' and instance_name == 'instance2':\n",
        "        file_start_idx = 768\n",
        "    \n",
        "    # 确定主要脑区\n",
        "    roi_counts = np.bincount(rois[file_start_idx:file_start_idx+256].astype(int))\n",
        "    primary_roi = np.argmax(roi_counts)\n",
        "    \n",
        "    if primary_roi == 1:\n",
        "        region_name = 'V1'\n",
        "    elif primary_roi == 2:\n",
        "        region_name = 'V4'\n",
        "    else:\n",
        "        region_name = 'IT'\n",
        "    \n",
        "    print(f\"  主要脑区: {region_name}\")\n",
        "    print(f\"  脑区分布: {roi_counts}\")\n",
        "    \n",
        "    # 设置输出目录\n",
        "    hub_instance_output_dir = output_dir / f\"{hub_name}-{instance_name}_{region_name}\"\n",
        "    hub_instance_output_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    return combined_recording, region_name, hub_instance_output_dir\n",
        "\n",
        "print(\"处理函数已定义\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "处理 Hub1-instance2\n",
            "============================================================\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_1/Hub1-instance2_B001.ns6\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_2/Hub1-instance2_B002.ns6\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_3/Hub1-instance2_B003.ns6\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_4/Hub1-instance2_B004.ns6\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub1-instance2_B005.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_1/Hub1-instance2_B001.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_2/Hub1-instance2_B002.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_3/Hub1-instance2_B003.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_4/Hub1-instance2_B004.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub1-instance2_B005.ns6\n",
            "  合并 5 个recording...\n",
            "  主要脑区: IT\n",
            "  脑区分布: [  0   0   0 256]\n",
            "\n",
            "Recording信息:\n",
            "  采样率: 30000.0 Hz\n",
            "  通道数: 256\n",
            "  样本数: 187701229\n",
            "  持续时间: 6256.71 秒\n",
            "  输出目录: /media/ubuntu/sda/Monkey/sorted_result_combined/20240115/Hub1-instance2_IT\n",
            "BandpassFilterRecording: 256 channels - 30.0kHz - 1 segments - 187,701,229 samples \n",
            "                         6,256.71s (1.74 hours) - int16 dtype - 89.50 GiB\n",
            "CommonReferenceRecording: 256 channels - 30.0kHz - 1 segments - 187,701,229 samples \n",
            "                          6,256.71s (1.74 hours) - int16 dtype - 89.50 GiB\n",
            "Use cache_folder=/tmp/spikeinterface_cache/tmpueqfjae_/3SXFA57Q\n",
            "write_binary_recording \n",
            "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=14.65 MiB - total_memory=14.65 MiB - chunk_duration=1.00s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "write_binary_recording (no parallelization): 100%|██████████| 6257/6257 [23:56<00:00,  4.36it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BinaryFolderRecording: 256 channels - 30.0kHz - 1 segments - 187,701,229 samples \n",
            "                       6,256.71s (1.74 hours) - int16 dtype - 89.50 GiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3129/3129 [22:03<00:00,  2.36it/s]  \n",
            "100%|██████████| 3129/3129 [22:24<00:00,  2.33it/s]  \n",
            "100%|██████████| 16/16 [2:31:51<00:00, 569.44s/it]  \n",
            "100%|██████████| 3129/3129 [13:00<00:00,  4.01it/s]\n",
            "100%|██████████| 16/16 [44:23<00:00, 166.48s/it]\n",
            "estimate_sparsity (no parallelization): 100%|██████████| 6257/6257 [00:05<00:00, 1127.12it/s]\n",
            "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:380: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
            "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
            "compute_waveforms (no parallelization): 100%|██████████| 6257/6257 [05:40<00:00, 18.36it/s]\n",
            "noise_level (no parallelization): 100%|██████████| 20/20 [00:01<00:00, 13.84it/s]\n",
            "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 6257/6257 [04:17<00:00, 24.26it/s]\n",
            "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:1066: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
            "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
            "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
            "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 173.61it/s]\n",
            "write_binary_recording (no parallelization): 100%|██████████| 6257/6257 [18:51<00:00,  5.53it/s]\n",
            "Fitting PCA: 100%|██████████| 249/249 [00:04<00:00, 55.12it/s] \n",
            "Projecting waveforms: 100%|██████████| 249/249 [00:00<00:00, 1877.68it/s]\n",
            "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/spikeinterface/postprocessing/principal_component.py:565: UserWarning: Projection attempted on unfitted PCA models. This could be due to a small number of waveforms for a particular unit.\n",
            "  warnings.warn(\n",
            "extract PCs (no parallelization): 100%|██████████| 6257/6257 [20:32<00:00,  5.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run:\n",
            "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result_combined/20240115/Hub1-instance2_IT/phy_folder_for_kilosort/params.py\n",
            "\n",
            "============================================================\n",
            "处理 Hub2-instance1\n",
            "============================================================\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_1/Hub2-instance1_B001.ns6\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_2/Hub2-instance1_B002.ns6\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_3/Hub2-instance1_B003.ns6\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_4/Hub2-instance1_B004.ns6\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub2-instance1_B005.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_1/Hub2-instance1_B001.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_2/Hub2-instance1_B002.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_3/Hub2-instance1_B003.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_4/Hub2-instance1_B004.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub2-instance1_B005.ns6\n",
            "  合并 5 个recording...\n",
            "  主要脑区: V1\n",
            "  脑区分布: [  0 256]\n",
            "\n",
            "Recording信息:\n",
            "  采样率: 30000.0 Hz\n",
            "  通道数: 256\n",
            "  样本数: 187836208\n",
            "  持续时间: 6261.21 秒\n",
            "  输出目录: /media/ubuntu/sda/Monkey/sorted_result_combined/20240115/Hub2-instance1_V1\n",
            "BandpassFilterRecording: 256 channels - 30.0kHz - 1 segments - 187,836,208 samples \n",
            "                         6,261.21s (1.74 hours) - int16 dtype - 89.57 GiB\n",
            "CommonReferenceRecording: 256 channels - 30.0kHz - 1 segments - 187,836,208 samples \n",
            "                          6,261.21s (1.74 hours) - int16 dtype - 89.57 GiB\n",
            "Use cache_folder=/tmp/spikeinterface_cache/tmpo_r7dr3h/N1H42QN2\n",
            "write_binary_recording \n",
            "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=14.65 MiB - total_memory=14.65 MiB - chunk_duration=1.00s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "write_binary_recording (no parallelization): 100%|██████████| 6262/6262 [29:03<00:00,  3.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BinaryFolderRecording: 256 channels - 30.0kHz - 1 segments - 187,836,208 samples \n",
            "                       6,261.21s (1.74 hours) - int16 dtype - 89.57 GiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3131/3131 [20:55<00:00,  2.49it/s]  \n",
            "100%|██████████| 3131/3131 [19:56<00:00,  2.62it/s]  \n",
            "100%|██████████| 16/16 [3:54:44<00:00, 880.25s/it]   \n",
            "100%|██████████| 3131/3131 [15:48<00:00,  3.30it/s]\n",
            "100%|██████████| 16/16 [1:33:44<00:00, 351.56s/it]\n",
            "estimate_sparsity (no parallelization): 100%|██████████| 6262/6262 [00:07<00:00, 838.71it/s] \n",
            "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:380: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
            "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
            "compute_waveforms (no parallelization): 100%|██████████| 6262/6262 [05:38<00:00, 18.50it/s]\n",
            "noise_level (no parallelization): 100%|██████████| 20/20 [00:01<00:00, 13.69it/s]\n",
            "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 6262/6262 [03:41<00:00, 28.23it/s]\n",
            "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:1066: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
            "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
            "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
            "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
            "/home/ubuntu/.conda/envs/spike_sorting/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 189.79it/s]\n",
            "write_binary_recording (no parallelization): 100%|██████████| 6262/6262 [19:00<00:00,  5.49it/s]\n",
            "Fitting PCA: 100%|██████████| 290/290 [00:04<00:00, 64.04it/s] \n",
            "Projecting waveforms: 100%|██████████| 290/290 [00:00<00:00, 1705.04it/s]\n",
            "extract PCs (no parallelization): 100%|██████████| 6262/6262 [28:21<00:00,  3.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run:\n",
            "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result_combined/20240115/Hub2-instance1_V1/phy_folder_for_kilosort/params.py\n",
            "\n",
            "============================================================\n",
            "处理 Hub2-instance2\n",
            "============================================================\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_1/Hub2-instance2_B001.ns6\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_2/Hub2-instance2_B002.ns6\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_3/Hub2-instance2_B003.ns6\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_4/Hub2-instance2_B004.ns6\n",
            "  找到文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub2-instance2_B005.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_1/Hub2-instance2_B001.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_2/Hub2-instance2_B002.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_3/Hub2-instance2_B003.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_4/Hub2-instance2_B004.ns6\n",
            "  读取文件: /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240115/Block_5/Hub2-instance2_B005.ns6\n",
            "  合并 5 个recording...\n",
            "  主要脑区: V4\n",
            "  脑区分布: [  0   0 192  64]\n",
            "\n",
            "Recording信息:\n",
            "  采样率: 30000.0 Hz\n",
            "  通道数: 256\n",
            "  样本数: 187701626\n",
            "  持续时间: 6256.72 秒\n",
            "  输出目录: /media/ubuntu/sda/Monkey/sorted_result_combined/20240115/Hub2-instance2_V4\n",
            "BandpassFilterRecording: 256 channels - 30.0kHz - 1 segments - 187,701,626 samples \n",
            "                         6,256.72s (1.74 hours) - int16 dtype - 89.50 GiB\n",
            "CommonReferenceRecording: 256 channels - 30.0kHz - 1 segments - 187,701,626 samples \n",
            "                          6,256.72s (1.74 hours) - int16 dtype - 89.50 GiB\n",
            "Use cache_folder=/tmp/spikeinterface_cache/tmpcxj228f5/0RS9ABJ3\n",
            "write_binary_recording \n",
            "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=14.65 MiB - total_memory=14.65 MiB - chunk_duration=1.00s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "write_binary_recording (no parallelization): 100%|██████████| 6257/6257 [28:51<00:00,  3.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BinaryFolderRecording: 256 channels - 30.0kHz - 1 segments - 187,701,626 samples \n",
            "                       6,256.72s (1.74 hours) - int16 dtype - 89.50 GiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3129/3129 [19:47<00:00,  2.63it/s]  \n",
            "100%|██████████| 3129/3129 [19:55<00:00,  2.62it/s]  \n",
            "100%|██████████| 16/16 [4:26:28<00:00, 999.27s/it]   \n",
            "100%|██████████| 3129/3129 [18:37<00:00,  2.80it/s]\n",
            " 25%|██▌       | 4/16 [20:09<1:02:51, 314.28s/it]"
          ]
        }
      ],
      "source": [
        "from probeinterface import write_probeinterface, read_probeinterface\n",
        "import sys\n",
        "import spikeinterface as si\n",
        "import matplotlib.pyplot as plt\n",
        "import spikeinterface.extractors as se\n",
        "import spikeinterface.preprocessing as spre\n",
        "import spikeinterface.sorters as ss\n",
        "import spikeinterface.qualitymetrics as sqm\n",
        "\n",
        "for i in [1, 2, 3]:\n",
        "    hub_name, instance_name = hub_instance_combinations[i]\n",
        "    result = process_hub_instance(hub_name, instance_name)\n",
        "\n",
        "    if result is not None:\n",
        "        combined_recording, region_name, hub_instance_output_dir = result\n",
        "        \n",
        "        print(f\"\\nRecording信息:\")\n",
        "        print(f\"  采样率: {combined_recording.get_sampling_frequency()} Hz\")\n",
        "        print(f\"  通道数: {combined_recording.get_num_channels()}\")\n",
        "        print(f\"  样本数: {combined_recording.get_num_samples()}\")\n",
        "        print(f\"  持续时间: {combined_recording.get_num_samples() / combined_recording.get_sampling_frequency():.2f} 秒\")\n",
        "        print(f\"  输出目录: {hub_instance_output_dir}\")\n",
        "    else:\n",
        "        print(\"处理失败\")\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    probe_30channel = read_probeinterface('/media/ubuntu/sda/Monkey/scripts/probe_256.json')\n",
        "    probe_30channel.set_global_device_channel_indices([i for i in range(256)])\n",
        "\n",
        "    recording_recorded = combined_recording.set_probegroup(probe_30channel)\n",
        "\n",
        "    recording_cmr = recording_recorded\n",
        "    recording_f = spre.bandpass_filter(recording_recorded, freq_min=300, freq_max=3000)\n",
        "    print(recording_f)\n",
        "    recording_cmr = spre.common_reference(recording_f, reference=\"global\", operator=\"median\")\n",
        "    print(recording_cmr)\n",
        "    hub_instance_output_dir = str(hub_instance_output_dir)\n",
        "    # this computes and saves the recording after applying the preprocessing chain\n",
        "    recording_preprocessed = recording_cmr.save(format=\"binary\")\n",
        "    print(recording_preprocessed)\n",
        "    sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, folder=hub_instance_output_dir + \"/kilosort4\")\n",
        "    analyzer_kilosort4 = si.create_sorting_analyzer(sorting=sorting_kilosort4, recording=recording_preprocessed, format='binary_folder', folder=hub_instance_output_dir + '/analyzer_kilosort4_binary')\n",
        "\n",
        "    extensions_to_compute = [\n",
        "                \"random_spikes\",\n",
        "                \"waveforms\",\n",
        "                \"noise_levels\",\n",
        "                \"templates\",\n",
        "                \"spike_amplitudes\",\n",
        "                \"unit_locations\",\n",
        "                \"spike_locations\",\n",
        "                \"correlograms\",\n",
        "                \"template_similarity\"\n",
        "            ]\n",
        "\n",
        "    extension_params = {\n",
        "        \"unit_locations\": {\"method\": \"center_of_mass\"},\n",
        "        \"spike_locations\": {\"ms_before\": 0.1},\n",
        "        \"correlograms\": {\"bin_ms\": 0.1},\n",
        "        \"template_similarity\": {\"method\": \"cosine_similarity\"}\n",
        "    }\n",
        "\n",
        "    analyzer_kilosort4.compute(extensions_to_compute, extension_params=extension_params)\n",
        "\n",
        "    qm_params = sqm.get_default_qm_params()\n",
        "    analyzer_kilosort4.compute(\"quality_metrics\", qm_params)\n",
        "\n",
        "    import spikeinterface.exporters as sexp\n",
        "    sexp.export_to_phy(analyzer_kilosort4, hub_instance_output_dir + \"/phy_folder_for_kilosort\", verbose=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "spike_sorting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
