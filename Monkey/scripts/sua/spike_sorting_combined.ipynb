{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384e9b84",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31mImportError: /home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/lib-dynload/_sqlite3.cpython-311-x86_64-linux-gnu.so: undefined symbol: sqlite3_deserialize. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import spikeinterface as si\n",
    "import matplotlib.pyplot as plt\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.widgets as sw\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import json\n",
    "import probeinterface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5cedfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240112/Block_4/Hub1-instance1_B004.ns6\n",
      "Processing chunk 0-500000 (500000 samples)\n",
      "Processing chunk 500000-1000000 (500000 samples)\n",
      "Processing chunk 1000000-1500000 (500000 samples)\n",
      "Processing chunk 1500000-2000000 (500000 samples)\n",
      "Processing chunk 2000000-2500000 (500000 samples)\n",
      "Processing chunk 2500000-3000000 (500000 samples)\n",
      "Processing chunk 3000000-3500000 (500000 samples)\n",
      "Processing chunk 3500000-4000000 (500000 samples)\n",
      "Processing chunk 4000000-4500000 (500000 samples)\n",
      "Processing chunk 4500000-5000000 (500000 samples)\n",
      "Processing chunk 5000000-5500000 (500000 samples)\n",
      "Processing chunk 5500000-6000000 (500000 samples)\n",
      "Processing chunk 6000000-6500000 (500000 samples)\n",
      "Processing chunk 6500000-7000000 (500000 samples)\n",
      "Processing chunk 7000000-7500000 (500000 samples)\n",
      "Processing chunk 7500000-8000000 (500000 samples)\n",
      "Processing chunk 8000000-8500000 (500000 samples)\n",
      "Processing chunk 8500000-9000000 (500000 samples)\n",
      "Processing chunk 9000000-9500000 (500000 samples)\n",
      "Processing chunk 9500000-10000000 (500000 samples)\n",
      "Processing chunk 10000000-10500000 (500000 samples)\n",
      "Processing chunk 10500000-11000000 (500000 samples)\n",
      "Processing chunk 11000000-11500000 (500000 samples)\n",
      "Processing chunk 11500000-12000000 (500000 samples)\n",
      "Processing chunk 12000000-12500000 (500000 samples)\n",
      "Processing chunk 12500000-13000000 (500000 samples)\n",
      "Processing chunk 13000000-13500000 (500000 samples)\n",
      "Processing chunk 13500000-14000000 (500000 samples)\n",
      "Processing chunk 14000000-14500000 (500000 samples)\n",
      "Processing chunk 14500000-15000000 (500000 samples)\n",
      "Processing chunk 15000000-15500000 (500000 samples)\n",
      "Processing chunk 15500000-16000000 (500000 samples)\n",
      "Processing chunk 16000000-16500000 (500000 samples)\n",
      "Processing chunk 16500000-17000000 (500000 samples)\n",
      "Processing chunk 17000000-17500000 (500000 samples)\n",
      "Processing chunk 17500000-18000000 (500000 samples)\n",
      "Processing chunk 18000000-18500000 (500000 samples)\n",
      "Processing chunk 18500000-19000000 (500000 samples)\n",
      "Processing chunk 19000000-19500000 (500000 samples)\n",
      "Processing chunk 19500000-20000000 (500000 samples)\n",
      "Processing chunk 20000000-20500000 (500000 samples)\n",
      "Processing chunk 20500000-21000000 (500000 samples)\n",
      "Processing chunk 21000000-21500000 (500000 samples)\n",
      "Processing chunk 21500000-22000000 (500000 samples)\n",
      "Processing chunk 22000000-22500000 (500000 samples)\n",
      "Processing chunk 22500000-23000000 (500000 samples)\n",
      "Processing chunk 23000000-23500000 (500000 samples)\n",
      "Processing chunk 23500000-24000000 (500000 samples)\n",
      "Processing chunk 24000000-24500000 (500000 samples)\n",
      "Processing chunk 24500000-25000000 (500000 samples)\n",
      "Processing chunk 25000000-25500000 (500000 samples)\n",
      "Processing chunk 25500000-26000000 (500000 samples)\n",
      "Processing chunk 26000000-26402792 (402792 samples)\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub1-instance1_B004/array_01_V1.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub1-instance1_B004/array_02_V1.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub1-instance1_B004/array_03_V1.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub1-instance1_B004/array_04_V1.npy\n",
      "Completed processing Hub1-instance1_B004.ns6\n",
      "Processing /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240112/Block_4/Hub1-instance2_B004.ns6\n",
      "Processing chunk 0-500000 (500000 samples)\n",
      "Processing chunk 500000-1000000 (500000 samples)\n",
      "Processing chunk 1000000-1500000 (500000 samples)\n",
      "Processing chunk 1500000-2000000 (500000 samples)\n",
      "Processing chunk 2000000-2500000 (500000 samples)\n",
      "Processing chunk 2500000-3000000 (500000 samples)\n",
      "Processing chunk 3000000-3500000 (500000 samples)\n",
      "Processing chunk 3500000-4000000 (500000 samples)\n",
      "Processing chunk 4000000-4500000 (500000 samples)\n",
      "Processing chunk 4500000-5000000 (500000 samples)\n",
      "Processing chunk 5000000-5500000 (500000 samples)\n",
      "Processing chunk 5500000-6000000 (500000 samples)\n",
      "Processing chunk 6000000-6500000 (500000 samples)\n",
      "Processing chunk 6500000-7000000 (500000 samples)\n",
      "Processing chunk 7000000-7500000 (500000 samples)\n",
      "Processing chunk 7500000-8000000 (500000 samples)\n",
      "Processing chunk 8000000-8500000 (500000 samples)\n",
      "Processing chunk 8500000-9000000 (500000 samples)\n",
      "Processing chunk 9000000-9500000 (500000 samples)\n",
      "Processing chunk 9500000-10000000 (500000 samples)\n",
      "Processing chunk 10000000-10500000 (500000 samples)\n",
      "Processing chunk 10500000-11000000 (500000 samples)\n",
      "Processing chunk 11000000-11500000 (500000 samples)\n",
      "Processing chunk 11500000-12000000 (500000 samples)\n",
      "Processing chunk 12000000-12500000 (500000 samples)\n",
      "Processing chunk 12500000-13000000 (500000 samples)\n",
      "Processing chunk 13000000-13500000 (500000 samples)\n",
      "Processing chunk 13500000-14000000 (500000 samples)\n",
      "Processing chunk 14000000-14500000 (500000 samples)\n",
      "Processing chunk 14500000-15000000 (500000 samples)\n",
      "Processing chunk 15000000-15500000 (500000 samples)\n",
      "Processing chunk 15500000-16000000 (500000 samples)\n",
      "Processing chunk 16000000-16500000 (500000 samples)\n",
      "Processing chunk 16500000-17000000 (500000 samples)\n",
      "Processing chunk 17000000-17500000 (500000 samples)\n",
      "Processing chunk 17500000-18000000 (500000 samples)\n",
      "Processing chunk 18000000-18500000 (500000 samples)\n",
      "Processing chunk 18500000-19000000 (500000 samples)\n",
      "Processing chunk 19000000-19500000 (500000 samples)\n",
      "Processing chunk 19500000-20000000 (500000 samples)\n",
      "Processing chunk 20000000-20500000 (500000 samples)\n",
      "Processing chunk 20500000-21000000 (500000 samples)\n",
      "Processing chunk 21000000-21500000 (500000 samples)\n",
      "Processing chunk 21500000-22000000 (500000 samples)\n",
      "Processing chunk 22000000-22500000 (500000 samples)\n",
      "Processing chunk 22500000-23000000 (500000 samples)\n",
      "Processing chunk 23000000-23500000 (500000 samples)\n",
      "Processing chunk 23500000-24000000 (500000 samples)\n",
      "Processing chunk 24000000-24500000 (500000 samples)\n",
      "Processing chunk 24500000-25000000 (500000 samples)\n",
      "Processing chunk 25000000-25500000 (500000 samples)\n",
      "Processing chunk 25500000-26000000 (500000 samples)\n",
      "Processing chunk 26000000-26368205 (368205 samples)\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub1-instance2_B004/array_09_IT.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub1-instance2_B004/array_10_IT.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub1-instance2_B004/array_11_IT.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub1-instance2_B004/array_12_IT.npy\n",
      "Completed processing Hub1-instance2_B004.ns6\n",
      "Processing /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240112/Block_4/Hub2-instance1_B004.ns6\n",
      "Processing chunk 0-500000 (500000 samples)\n",
      "Processing chunk 500000-1000000 (500000 samples)\n",
      "Processing chunk 1000000-1500000 (500000 samples)\n",
      "Processing chunk 1500000-2000000 (500000 samples)\n",
      "Processing chunk 2000000-2500000 (500000 samples)\n",
      "Processing chunk 2500000-3000000 (500000 samples)\n",
      "Processing chunk 3000000-3500000 (500000 samples)\n",
      "Processing chunk 3500000-4000000 (500000 samples)\n",
      "Processing chunk 4000000-4500000 (500000 samples)\n",
      "Processing chunk 4500000-5000000 (500000 samples)\n",
      "Processing chunk 5000000-5500000 (500000 samples)\n",
      "Processing chunk 5500000-6000000 (500000 samples)\n",
      "Processing chunk 6000000-6500000 (500000 samples)\n",
      "Processing chunk 6500000-7000000 (500000 samples)\n",
      "Processing chunk 7000000-7500000 (500000 samples)\n",
      "Processing chunk 7500000-8000000 (500000 samples)\n",
      "Processing chunk 8000000-8500000 (500000 samples)\n",
      "Processing chunk 8500000-9000000 (500000 samples)\n",
      "Processing chunk 9000000-9500000 (500000 samples)\n",
      "Processing chunk 9500000-10000000 (500000 samples)\n",
      "Processing chunk 10000000-10500000 (500000 samples)\n",
      "Processing chunk 10500000-11000000 (500000 samples)\n",
      "Processing chunk 11000000-11500000 (500000 samples)\n",
      "Processing chunk 11500000-12000000 (500000 samples)\n",
      "Processing chunk 12000000-12500000 (500000 samples)\n",
      "Processing chunk 12500000-13000000 (500000 samples)\n",
      "Processing chunk 13000000-13500000 (500000 samples)\n",
      "Processing chunk 13500000-14000000 (500000 samples)\n",
      "Processing chunk 14000000-14500000 (500000 samples)\n",
      "Processing chunk 14500000-15000000 (500000 samples)\n",
      "Processing chunk 15000000-15500000 (500000 samples)\n",
      "Processing chunk 15500000-16000000 (500000 samples)\n",
      "Processing chunk 16000000-16500000 (500000 samples)\n",
      "Processing chunk 16500000-17000000 (500000 samples)\n",
      "Processing chunk 17000000-17500000 (500000 samples)\n",
      "Processing chunk 17500000-18000000 (500000 samples)\n",
      "Processing chunk 18000000-18500000 (500000 samples)\n",
      "Processing chunk 18500000-19000000 (500000 samples)\n",
      "Processing chunk 19000000-19500000 (500000 samples)\n",
      "Processing chunk 19500000-20000000 (500000 samples)\n",
      "Processing chunk 20000000-20500000 (500000 samples)\n",
      "Processing chunk 20500000-21000000 (500000 samples)\n",
      "Processing chunk 21000000-21500000 (500000 samples)\n",
      "Processing chunk 21500000-22000000 (500000 samples)\n",
      "Processing chunk 22000000-22500000 (500000 samples)\n",
      "Processing chunk 22500000-23000000 (500000 samples)\n",
      "Processing chunk 23000000-23500000 (500000 samples)\n",
      "Processing chunk 23500000-24000000 (500000 samples)\n",
      "Processing chunk 24000000-24500000 (500000 samples)\n",
      "Processing chunk 24500000-25000000 (500000 samples)\n",
      "Processing chunk 25000000-25500000 (500000 samples)\n",
      "Processing chunk 25500000-26000000 (500000 samples)\n",
      "Processing chunk 26000000-26402760 (402760 samples)\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub2-instance1_B004/array_05_V1.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub2-instance1_B004/array_06_V1.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub2-instance1_B004/array_07_V1.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub2-instance1_B004/array_08_V1.npy\n",
      "Completed processing Hub2-instance1_B004.ns6\n",
      "Processing /media/ubuntu/sda/Monkey/TVSD/monkeyF/20240112/Block_4/Hub2-instance2_B004.ns6\n",
      "Processing chunk 0-500000 (500000 samples)\n",
      "Processing chunk 500000-1000000 (500000 samples)\n",
      "Processing chunk 1000000-1500000 (500000 samples)\n",
      "Processing chunk 1500000-2000000 (500000 samples)\n",
      "Processing chunk 2000000-2500000 (500000 samples)\n",
      "Processing chunk 2500000-3000000 (500000 samples)\n",
      "Processing chunk 3000000-3500000 (500000 samples)\n",
      "Processing chunk 3500000-4000000 (500000 samples)\n",
      "Processing chunk 4000000-4500000 (500000 samples)\n",
      "Processing chunk 4500000-5000000 (500000 samples)\n",
      "Processing chunk 5000000-5500000 (500000 samples)\n",
      "Processing chunk 5500000-6000000 (500000 samples)\n",
      "Processing chunk 6000000-6500000 (500000 samples)\n",
      "Processing chunk 6500000-7000000 (500000 samples)\n",
      "Processing chunk 7000000-7500000 (500000 samples)\n",
      "Processing chunk 7500000-8000000 (500000 samples)\n",
      "Processing chunk 8000000-8500000 (500000 samples)\n",
      "Processing chunk 8500000-9000000 (500000 samples)\n",
      "Processing chunk 9000000-9500000 (500000 samples)\n",
      "Processing chunk 9500000-10000000 (500000 samples)\n",
      "Processing chunk 10000000-10500000 (500000 samples)\n",
      "Processing chunk 10500000-11000000 (500000 samples)\n",
      "Processing chunk 11000000-11500000 (500000 samples)\n",
      "Processing chunk 11500000-12000000 (500000 samples)\n",
      "Processing chunk 12000000-12500000 (500000 samples)\n",
      "Processing chunk 12500000-13000000 (500000 samples)\n",
      "Processing chunk 13000000-13500000 (500000 samples)\n",
      "Processing chunk 13500000-14000000 (500000 samples)\n",
      "Processing chunk 14000000-14500000 (500000 samples)\n",
      "Processing chunk 14500000-15000000 (500000 samples)\n",
      "Processing chunk 15000000-15500000 (500000 samples)\n",
      "Processing chunk 15500000-16000000 (500000 samples)\n",
      "Processing chunk 16000000-16500000 (500000 samples)\n",
      "Processing chunk 16500000-17000000 (500000 samples)\n",
      "Processing chunk 17000000-17500000 (500000 samples)\n",
      "Processing chunk 17500000-18000000 (500000 samples)\n",
      "Processing chunk 18000000-18500000 (500000 samples)\n",
      "Processing chunk 18500000-19000000 (500000 samples)\n",
      "Processing chunk 19000000-19500000 (500000 samples)\n",
      "Processing chunk 19500000-20000000 (500000 samples)\n",
      "Processing chunk 20000000-20500000 (500000 samples)\n",
      "Processing chunk 20500000-21000000 (500000 samples)\n",
      "Processing chunk 21000000-21500000 (500000 samples)\n",
      "Processing chunk 21500000-22000000 (500000 samples)\n",
      "Processing chunk 22000000-22500000 (500000 samples)\n",
      "Processing chunk 22500000-23000000 (500000 samples)\n",
      "Processing chunk 23000000-23500000 (500000 samples)\n",
      "Processing chunk 23500000-24000000 (500000 samples)\n",
      "Processing chunk 24000000-24500000 (500000 samples)\n",
      "Processing chunk 24500000-25000000 (500000 samples)\n",
      "Processing chunk 25000000-25500000 (500000 samples)\n",
      "Processing chunk 25500000-26000000 (500000 samples)\n",
      "Processing chunk 26000000-26368289 (368289 samples)\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub2-instance2_B004/array_13_IT.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub2-instance2_B004/array_14_V4.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub2-instance2_B004/array_15_V4.npy\n",
      "Saved /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/Hub2-instance2_B004/array_16_V4.npy\n",
      "Completed processing Hub2-instance2_B004.ns6\n",
      "All files processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface as si\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "monkey = 'monkeyF'\n",
    "datadir_gen = '/media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/'\n",
    "mapping_file = f'/media/ubuntu/sda/Monkey/TVSD/monkeyF/_logs/1024chns_mapping_20220105.mat'\n",
    "\n",
    "file_list = [\n",
    "    'Hub1-instance1_B004.ns6',\n",
    "    'Hub1-instance2_B004.ns6',\n",
    "    'Hub2-instance1_B004.ns6',\n",
    "    'Hub2-instance2_B004.ns6'\n",
    "]\n",
    "\n",
    "# 加载映射文件\n",
    "mapping_data = sio.loadmat(mapping_file)\n",
    "mapping = mapping_data['mapping'].flatten() - 1  # 转换为0-based索引\n",
    "\n",
    "# 定义脑区映射\n",
    "if monkey == 'monkeyN':\n",
    "    rois = np.ones(1024)  # V1\n",
    "    rois[512:768] = 2  # V4 (513-768)\n",
    "    rois[768:1024] = 3  # IT (769-1024)\n",
    "else:\n",
    "    rois = np.ones(1024)  # V1\n",
    "    rois[512:832] = 3  # IT (513-832)\n",
    "    rois[832:1024] = 2  # V4 (833-1024)\n",
    "\n",
    "output_dir = Path(datadir_gen) / 'processed_data'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 设置块大小（根据可用内存调整）\n",
    "chunk_size = 500000  # 每次处理的样本数\n",
    "\n",
    "# 处理每个文件\n",
    "for file_idx, file_name in enumerate(file_list):\n",
    "    file_path = f'/media/ubuntu/sda/Monkey/TVSD/monkeyF/20240112/Block_4/{file_name}'\n",
    "    print(f'Processing {file_path}')\n",
    "    \n",
    "    # 读取文件\n",
    "    recording = se.read_blackrock(file_path)\n",
    "    \n",
    "    # 处理多段数据\n",
    "    if recording.get_num_segments() > 1:\n",
    "        recording_list = []\n",
    "        for i in range(recording.get_num_segments()):\n",
    "            recording_list.append(recording.select_segments(i))\n",
    "        recording = si.concatenate_recordings(recording_list)\n",
    "    \n",
    "    # 获取采样率和样本数\n",
    "    sample_rate = recording.get_sampling_frequency()\n",
    "    n_samples = recording.get_num_samples()\n",
    "    \n",
    "    # 获取通道ID列表（字符串类型）\n",
    "    channel_ids = np.array([str(i) for i in range(1, 257)])\n",
    "    \n",
    "    # 确定当前文件在映射中的位置\n",
    "    if 'Hub1-instance1' in file_name:\n",
    "        file_start_idx = 0\n",
    "    elif 'Hub2-instance1' in file_name:\n",
    "        file_start_idx = 256\n",
    "    elif 'Hub1-instance2' in file_name:\n",
    "        file_start_idx = 512\n",
    "    elif 'Hub2-instance2' in file_name:\n",
    "        file_start_idx = 768\n",
    "    else:\n",
    "        raise ValueError(f'Unknown file type: {file_name}')\n",
    "    \n",
    "    # 创建文件输出目录\n",
    "    file_output_dir = output_dir / file_name.replace('.ns6', '')\n",
    "    file_output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # 为每个阵列创建内存映射文件（每个文件有4个阵列）\n",
    "    array_files = []\n",
    "    array_info = []\n",
    "    \n",
    "    # 每个文件有256个通道，分成4组，每组64个通道\n",
    "    for array_idx in range(4):\n",
    "        # 确定阵列的主要脑区\n",
    "        start_chan = file_start_idx + array_idx * 64\n",
    "        end_chan = start_chan + 64\n",
    "        \n",
    "        array_roi_counts = np.bincount(rois[start_chan:end_chan].astype(int))\n",
    "        primary_roi = np.argmax(array_roi_counts)\n",
    "        \n",
    "        if primary_roi == 1:\n",
    "            roi_name = 'V1'\n",
    "        elif primary_roi == 2:\n",
    "            roi_name = 'V4'\n",
    "        else:\n",
    "            roi_name = 'IT'\n",
    "        \n",
    "        output_file = file_output_dir / f'array_{file_start_idx//64 + array_idx + 1:02d}_{roi_name}.npy'\n",
    "        \n",
    "        # 创建内存映射文件\n",
    "        mmap_array = np.lib.format.open_memmap(\n",
    "            output_file, mode='w+', dtype=np.float32, shape=(64, n_samples)\n",
    "        )\n",
    "        array_files.append(mmap_array)\n",
    "        array_info.append({'roi_name': roi_name, 'output_file': output_file})\n",
    "    \n",
    "    # 分块处理数据\n",
    "    for start in range(0, n_samples, chunk_size):\n",
    "        end = min(start + chunk_size, n_samples)\n",
    "        chunk_size_actual = end - start\n",
    "        \n",
    "        print(f'Processing chunk {start}-{end} ({chunk_size_actual} samples)')\n",
    "        \n",
    "        # 获取当前块的数据\n",
    "        chunk_data = recording.get_traces(start_frame=start, end_frame=end)\n",
    "        \n",
    "        # 处理当前文件的每个通道\n",
    "        for i in range(256):\n",
    "            # 使用正确的通道ID获取数据\n",
    "            channel_id = str(i + 1)  # 转换为字符串，因为Recording使用字符串ID\n",
    "            channel_idx_in_recording = np.where(channel_ids == channel_id)[0][0]\n",
    "            \n",
    "            # 确定通道属于哪个阵列（在当前文件的4个阵列中）\n",
    "            array_idx = i // 64\n",
    "            channel_in_array = i % 64\n",
    "            \n",
    "            # 将数据写入对应阵列的内存映射文件\n",
    "            array_files[array_idx][channel_in_array, start:end] = chunk_data[:, channel_idx_in_recording]\n",
    "    \n",
    "    # 保存并关闭内存映射文件\n",
    "    for array_idx, mmap_array in enumerate(array_files):\n",
    "        mmap_array.flush()\n",
    "        del mmap_array  # 释放内存映射\n",
    "        print(f'Saved {array_info[array_idx][\"output_file\"]}')\n",
    "    \n",
    "    print(f'Completed processing {file_name}')\n",
    "\n",
    "print('All files processed successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "442bf6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,368,205 samples \n",
      "                         878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,368,205 samples \n",
      "                          878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpyhqllcph/JI1IHPZD\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [00:37<00:00, 23.72it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,368,205 samples \n",
      "                       878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:37<00:00, 11.80it/s]\n",
      "100%|██████████| 8/8 [02:26<00:00, 18.31s/it]\n",
      "100%|██████████| 440/440 [00:14<00:00, 30.46it/s]\n",
      "100%|██████████| 8/8 [00:31<00:00,  3.95s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 879/879 [00:00<00:00, 23787.45it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 879/879 [00:31<00:00, 27.72it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 55.28it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 879/879 [00:03<00:00, 280.22it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1076.50it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [01:23<00:00, 10.59it/s]\n",
      "Fitting PCA: 100%|██████████| 61/61 [00:02<00:00, 23.14it/s]\n",
      "Projecting waveforms: 100%|██████████| 61/61 [00:00<00:00, 4025.05it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 879/879 [00:48<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_09_IT.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,368,205 samples \n",
      "                         878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,368,205 samples \n",
      "                          878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmp6egrmmk_/CBVQFH8Q\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [00:36<00:00, 23.86it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,368,205 samples \n",
      "                       878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:35<00:00, 12.33it/s]\n",
      "100%|██████████| 8/8 [02:20<00:00, 17.59s/it]\n",
      "100%|██████████| 440/440 [00:12<00:00, 35.91it/s]\n",
      "100%|██████████| 8/8 [00:29<00:00,  3.64s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 879/879 [00:00<00:00, 23369.34it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 879/879 [00:31<00:00, 28.10it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 55.88it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 879/879 [00:02<00:00, 298.35it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1043.87it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [01:22<00:00, 10.68it/s]\n",
      "Fitting PCA: 100%|██████████| 58/58 [00:00<00:00, 216.59it/s]\n",
      "Projecting waveforms: 100%|██████████| 58/58 [00:00<00:00, 4234.83it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 879/879 [00:45<00:00, 19.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_11_IT.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,368,205 samples \n",
      "                         878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,368,205 samples \n",
      "                          878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpzx061fdq/X0UJG3WX\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [00:37<00:00, 23.61it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,368,205 samples \n",
      "                       878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:35<00:00, 12.23it/s]\n",
      "100%|██████████| 8/8 [02:01<00:00, 15.19s/it]\n",
      "100%|██████████| 440/440 [00:09<00:00, 45.11it/s]\n",
      "100%|██████████| 8/8 [00:16<00:00,  2.09s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 879/879 [00:00<00:00, 30106.10it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 879/879 [00:30<00:00, 28.65it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 57.87it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 879/879 [00:02<00:00, 433.75it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 928.93it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [01:22<00:00, 10.62it/s]\n",
      "Fitting PCA: 100%|██████████| 45/45 [00:00<00:00, 131.35it/s]\n",
      "Projecting waveforms: 100%|██████████| 45/45 [00:00<00:00, 4712.82it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 879/879 [00:29<00:00, 29.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_12_IT.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,368,205 samples \n",
      "                         878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,368,205 samples \n",
      "                          878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpx7sew4a6/MHNAG5AO\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [00:36<00:00, 23.87it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,368,205 samples \n",
      "                       878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:34<00:00, 12.66it/s]\n",
      "100%|██████████| 8/8 [02:30<00:00, 18.87s/it]\n",
      "100%|██████████| 440/440 [00:18<00:00, 23.26it/s]\n",
      "100%|██████████| 8/8 [00:41<00:00,  5.16s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 879/879 [00:00<00:00, 16503.77it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 879/879 [00:31<00:00, 28.29it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 50.42it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 879/879 [00:04<00:00, 215.54it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1055.08it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [01:16<00:00, 11.53it/s]\n",
      "Fitting PCA: 100%|██████████| 93/93 [00:02<00:00, 33.23it/s] \n",
      "Projecting waveforms: 100%|██████████| 93/93 [00:00<00:00, 3217.92it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 879/879 [01:00<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_10_IT.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,368,289 samples \n",
      "                         878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,368,289 samples \n",
      "                          878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpbpu9nys6/BLDWV0HQ\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [00:38<00:00, 22.90it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,368,289 samples \n",
      "                       878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:37<00:00, 11.59it/s]\n",
      "100%|██████████| 8/8 [02:16<00:00, 17.12s/it]\n",
      "100%|██████████| 440/440 [00:10<00:00, 42.22it/s]\n",
      "100%|██████████| 8/8 [00:23<00:00,  2.97s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 879/879 [00:00<00:00, 25570.94it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 879/879 [00:31<00:00, 28.15it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 54.73it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 879/879 [00:02<00:00, 357.23it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 965.01it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [01:18<00:00, 11.21it/s]\n",
      "Fitting PCA: 100%|██████████| 49/49 [00:00<00:00, 333.26it/s]\n",
      "Projecting waveforms: 100%|██████████| 49/49 [00:00<00:00, 4295.02it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 879/879 [00:33<00:00, 26.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_13_IT.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,368,289 samples \n",
      "                         878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,368,289 samples \n",
      "                          878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmp8j66731v/WJZPKR7F\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [00:36<00:00, 23.77it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,368,289 samples \n",
      "                       878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:35<00:00, 12.55it/s]\n",
      "100%|██████████| 8/8 [02:45<00:00, 20.69s/it]\n",
      "100%|██████████| 440/440 [00:22<00:00, 19.44it/s]\n",
      "100%|██████████| 8/8 [01:05<00:00,  8.20s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 879/879 [00:00<00:00, 19875.65it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 879/879 [00:32<00:00, 27.25it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 55.71it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 879/879 [00:04<00:00, 179.82it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1120.03it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [01:20<00:00, 10.87it/s]\n",
      "Fitting PCA: 100%|██████████| 82/82 [00:02<00:00, 28.80it/s] \n",
      "Projecting waveforms: 100%|██████████| 82/82 [00:00<00:00, 3573.85it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 879/879 [01:18<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_16_V4.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,368,289 samples \n",
      "                         878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,368,289 samples \n",
      "                          878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmputa7mvjx/D392L7BI\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [00:38<00:00, 22.79it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,368,289 samples \n",
      "                       878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:35<00:00, 12.40it/s]\n",
      "100%|██████████| 8/8 [02:48<00:00, 21.01s/it]\n",
      "100%|██████████| 440/440 [00:12<00:00, 35.65it/s]\n",
      "100%|██████████| 8/8 [00:49<00:00,  6.18s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 879/879 [00:00<00:00, 24641.37it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 879/879 [00:31<00:00, 28.07it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 58.16it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 879/879 [00:03<00:00, 283.41it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1034.09it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [01:22<00:00, 10.61it/s]\n",
      "Fitting PCA: 100%|██████████| 48/48 [00:00<00:00, 242.90it/s]\n",
      "Projecting waveforms: 100%|██████████| 48/48 [00:00<00:00, 4180.28it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 879/879 [00:46<00:00, 19.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_14_V4.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,368,289 samples \n",
      "                         878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,368,289 samples \n",
      "                          878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpclsep3pm/FDT9A47N\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [00:37<00:00, 23.44it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,368,289 samples \n",
      "                       878.94s (14.65 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440/440 [00:37<00:00, 11.61it/s]\n",
      "100%|██████████| 8/8 [02:53<00:00, 21.71s/it]\n",
      "100%|██████████| 440/440 [00:14<00:00, 30.07it/s]\n",
      "100%|██████████| 8/8 [00:37<00:00,  4.64s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 879/879 [00:00<00:00, 21978.82it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 879/879 [00:31<00:00, 27.93it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 56.02it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 879/879 [00:03<00:00, 255.82it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1056.19it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:1565: RuntimeWarning: invalid value encountered in sqrt\n",
      "  std_noise = np.sqrt(std_noise**2 - total_variance)\n",
      "write_binary_recording (no parallelization): 100%|██████████| 879/879 [01:19<00:00, 11.06it/s]\n",
      "Fitting PCA: 100%|██████████| 66/66 [00:09<00:00,  7.04it/s]\n",
      "Projecting waveforms: 100%|██████████| 66/66 [00:00<00:00, 3634.29it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 879/879 [00:51<00:00, 17.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_15_V4.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,402,760 samples \n",
      "                         880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,402,760 samples \n",
      "                          880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpkk9b0auh/TXTTG0YE\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [00:37<00:00, 23.58it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,402,760 samples \n",
      "                       880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [00:37<00:00, 11.71it/s]\n",
      "100%|██████████| 8/8 [03:44<00:00, 28.09s/it]\n",
      "100%|██████████| 441/441 [00:20<00:00, 21.37it/s]\n",
      "100%|██████████| 8/8 [01:01<00:00,  7.65s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 881/881 [00:00<00:00, 20827.55it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 881/881 [00:32<00:00, 27.07it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 55.76it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 881/881 [00:04<00:00, 197.53it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1069.85it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [01:21<00:00, 10.78it/s]\n",
      "Fitting PCA: 100%|██████████| 68/68 [00:00<00:00, 284.36it/s]\n",
      "Projecting waveforms: 100%|██████████| 68/68 [00:00<00:00, 3864.04it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 881/881 [01:08<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_07_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,402,760 samples \n",
      "                         880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,402,760 samples \n",
      "                          880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpz4i52owu/4OWR1EGG\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [00:37<00:00, 23.77it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,402,760 samples \n",
      "                       880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [00:35<00:00, 12.59it/s]\n",
      "100%|██████████| 8/8 [01:47<00:00, 13.48s/it]\n",
      "100%|██████████| 441/441 [00:14<00:00, 31.03it/s]\n",
      "100%|██████████| 8/8 [00:30<00:00,  3.86s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 881/881 [00:00<00:00, 25758.83it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 881/881 [00:30<00:00, 28.52it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 57.44it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 881/881 [00:03<00:00, 292.43it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1097.30it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [01:21<00:00, 10.80it/s]\n",
      "Fitting PCA: 100%|██████████| 57/57 [00:00<00:00, 340.88it/s]\n",
      "Projecting waveforms: 100%|██████████| 57/57 [00:00<00:00, 4103.17it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 881/881 [00:46<00:00, 19.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_05_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,402,760 samples \n",
      "                         880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,402,760 samples \n",
      "                          880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpd71a8kp0/42XPNWDW\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [00:36<00:00, 24.05it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,402,760 samples \n",
      "                       880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [00:36<00:00, 12.13it/s]\n",
      "100%|██████████| 8/8 [02:19<00:00, 17.49s/it]\n",
      "100%|██████████| 441/441 [00:12<00:00, 36.59it/s]\n",
      "100%|██████████| 8/8 [00:26<00:00,  3.32s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 881/881 [00:00<00:00, 33211.24it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 881/881 [00:31<00:00, 28.42it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 55.61it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 881/881 [00:02<00:00, 330.53it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1073.55it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [01:21<00:00, 10.80it/s]\n",
      "Fitting PCA: 100%|██████████| 42/42 [00:00<00:00, 329.83it/s]\n",
      "Projecting waveforms: 100%|██████████| 42/42 [00:00<00:00, 4798.06it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 881/881 [00:40<00:00, 21.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_08_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,402,760 samples \n",
      "                         880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,402,760 samples \n",
      "                          880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmp5czmz75l/ATRE4QJW\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [00:36<00:00, 23.88it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,402,760 samples \n",
      "                       880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [00:35<00:00, 12.31it/s]\n",
      "100%|██████████| 8/8 [02:18<00:00, 17.34s/it]\n",
      "100%|██████████| 441/441 [00:20<00:00, 21.15it/s]\n",
      "100%|██████████| 8/8 [00:44<00:00,  5.58s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 881/881 [00:00<00:00, 23841.73it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 881/881 [00:32<00:00, 27.42it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 56.37it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 881/881 [00:03<00:00, 234.80it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1121.43it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [01:21<00:00, 10.79it/s]\n",
      "Fitting PCA: 100%|██████████| 65/65 [00:00<00:00, 187.47it/s]\n",
      "Projecting waveforms: 100%|██████████| 65/65 [00:00<00:00, 3624.87it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 881/881 [00:58<00:00, 15.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_06_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,402,792 samples \n",
      "                         880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,402,792 samples \n",
      "                          880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpq69kec64/KDCAGMAK\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [00:37<00:00, 23.77it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,402,792 samples \n",
      "                       880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [00:35<00:00, 12.49it/s]\n",
      "100%|██████████| 8/8 [02:17<00:00, 17.14s/it]\n",
      "100%|██████████| 441/441 [00:14<00:00, 30.09it/s]\n",
      "100%|██████████| 8/8 [00:41<00:00,  5.18s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 881/881 [00:00<00:00, 22025.68it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 881/881 [00:32<00:00, 27.19it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 57.13it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 881/881 [00:03<00:00, 245.23it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1097.25it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [01:23<00:00, 10.61it/s]\n",
      "Fitting PCA: 100%|██████████| 67/67 [00:00<00:00, 332.89it/s]\n",
      "Projecting waveforms: 100%|██████████| 67/67 [00:00<00:00, 3754.82it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 881/881 [00:55<00:00, 16.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_04_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,402,792 samples \n",
      "                         880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,402,792 samples \n",
      "                          880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpa11k0gdp/TSU2SFCK\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [00:37<00:00, 23.65it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,402,792 samples \n",
      "                       880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [00:36<00:00, 12.05it/s]\n",
      "100%|██████████| 8/8 [03:46<00:00, 28.28s/it]\n",
      "100%|██████████| 441/441 [00:22<00:00, 19.68it/s]\n",
      "100%|██████████| 8/8 [01:03<00:00,  7.94s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 881/881 [00:00<00:00, 18588.56it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 881/881 [00:31<00:00, 27.68it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 56.32it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 881/881 [00:04<00:00, 181.70it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1078.28it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [01:23<00:00, 10.56it/s]\n",
      "Fitting PCA: 100%|██████████| 80/80 [00:00<00:00, 338.52it/s]\n",
      "Projecting waveforms: 100%|██████████| 80/80 [00:00<00:00, 3612.20it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 881/881 [01:15<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_02_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,402,792 samples \n",
      "                         880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,402,792 samples \n",
      "                          880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmphqpjrt2p/RLG6C2DW\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [00:36<00:00, 23.88it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,402,792 samples \n",
      "                       880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [00:36<00:00, 12.03it/s]\n",
      "100%|██████████| 8/8 [03:48<00:00, 28.61s/it]\n",
      "100%|██████████| 441/441 [00:18<00:00, 24.13it/s]\n",
      "100%|██████████| 8/8 [00:56<00:00,  7.05s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 881/881 [00:00<00:00, 19364.45it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 881/881 [00:31<00:00, 27.75it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 55.91it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 881/881 [00:04<00:00, 199.47it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1122.90it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [01:21<00:00, 10.75it/s]\n",
      "Fitting PCA: 100%|██████████| 77/77 [00:00<00:00, 329.79it/s]\n",
      "Projecting waveforms: 100%|██████████| 77/77 [00:00<00:00, 3484.58it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 881/881 [01:10<00:00, 12.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_01_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 26,402,792 samples \n",
      "                         880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 26,402,792 samples \n",
      "                          880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpyn2bkm8r/9MAROJVG\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [00:36<00:00, 23.84it/s]\n",
      "/tmp/ipykernel_1458373/3656992652.py:23: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 26,402,792 samples \n",
      "                       880.09s (14.67 minutes) - float32 dtype - 6.29 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [00:34<00:00, 12.61it/s]\n",
      "100%|██████████| 8/8 [01:44<00:00, 13.05s/it]\n",
      "100%|██████████| 441/441 [00:15<00:00, 27.97it/s]\n",
      "100%|██████████| 8/8 [00:33<00:00,  4.16s/it]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 881/881 [00:00<00:00, 25547.09it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n",
      "compute_waveforms (no parallelization): 100%|██████████| 881/881 [00:30<00:00, 28.72it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 55.45it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 881/881 [00:03<00:00, 281.34it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/numpy/_core/_methods.py:215: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 1077.23it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 881/881 [01:22<00:00, 10.69it/s]\n",
      "Fitting PCA: 100%|██████████| 58/58 [00:00<00:00, 360.70it/s]\n",
      "Projecting waveforms: 100%|██████████| 58/58 [00:00<00:00, 4135.62it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 881/881 [00:47<00:00, 18.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/array_03_V1.npy/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for file in os.listdir(\"/media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data\"):\n",
    "    for array in os.listdir(f\"/media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/{file}\"):\n",
    "        recording = np.load(f\"/media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/processed_data/{file}/{array}\")\n",
    "        recording = se.NumpyRecording(recording.T, sampling_frequency=30000)\n",
    "        from probeinterface import write_probeinterface, read_probeinterface\n",
    "\n",
    "        probe_30channel = read_probeinterface('/media/ubuntu/sda/Monkey/probe.json')\n",
    "        probe_30channel.set_global_device_channel_indices([i for i in range(64)])\n",
    "        recording_recorded = recording.set_probegroup(probe_30channel)\n",
    "\n",
    "        recording_cmr = recording_recorded\n",
    "        recording_f = spre.bandpass_filter(recording_recorded, freq_min=300, freq_max=3000)\n",
    "        print(recording_f)\n",
    "        recording_cmr = spre.common_reference(recording_f, reference=\"global\", operator=\"median\")\n",
    "        print(recording_cmr)\n",
    "\n",
    "        # this computes and saves the recording after applying the preprocessing chain\n",
    "        recording_preprocessed = recording_cmr.save(format=\"binary\")\n",
    "        print(recording_preprocessed)\n",
    "        os.makedirs(f\"/media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/{array}\", exist_ok=True)\n",
    "        output_folder = f\"/media/ubuntu/sda/Monkey/sorted_result/20240112/Block_4/sort/{array}\"\n",
    "        sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n",
    "        analyzer_kilosort4 = si.create_sorting_analyzer(sorting=sorting_kilosort4, recording=recording_preprocessed, format='binary_folder', folder=output_folder + '/analyzer_kilosort4_binary')\n",
    "\n",
    "        extensions_to_compute = [\n",
    "                    \"random_spikes\",\n",
    "                    \"waveforms\",\n",
    "                    \"noise_levels\",\n",
    "                    \"templates\",\n",
    "                    \"spike_amplitudes\",\n",
    "                    \"unit_locations\",\n",
    "                    \"spike_locations\",\n",
    "                    \"correlograms\",\n",
    "                    \"template_similarity\"\n",
    "                ]\n",
    "\n",
    "        extension_params = {\n",
    "            \"unit_locations\": {\"method\": \"center_of_mass\"},\n",
    "            \"spike_locations\": {\"ms_before\": 0.1},\n",
    "            \"correlograms\": {\"bin_ms\": 0.1},\n",
    "            \"template_similarity\": {\"method\": \"cosine_similarity\"}\n",
    "        }\n",
    "\n",
    "        analyzer_kilosort4.compute(extensions_to_compute, extension_params=extension_params)\n",
    "\n",
    "        qm_params = sqm.get_default_qm_params()\n",
    "        analyzer_kilosort4.compute(\"quality_metrics\", qm_params)\n",
    "\n",
    "        import spikeinterface.exporters as sexp\n",
    "        sexp.export_to_phy(analyzer_kilosort4, output_folder + \"/phy_folder_for_kilosort\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f12fcf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = np.load(\"/media/ubuntu/sda/Monkey/TVSD/monkeyF/20240112/Block_1/processed_data/Hub1-instance1_B001/array_01_V1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cb0ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = se.NumpyRecording(recording.T, sampling_frequency=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14635242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probeinterface import write_probeinterface, read_probeinterface\n",
    "\n",
    "probe_30channel = read_probeinterface('/media/ubuntu/sda/Monkey/probe.json')\n",
    "probe_30channel.set_global_device_channel_indices([i for i in range(64)])\n",
    "recording_recorded = recording.set_probegroup(probe_30channel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81f71a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/base.py:967: UserWarning: The extractor is not serializable to file. The provenance will not be saved.\n",
      "  warnings.warn(\"The extractor is not serializable to file. The provenance will not be saved.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BandpassFilterRecording: 64 channels - 30.0kHz - 1 segments - 7,031,518 samples \n",
      "                         234.38s (3.91 minutes) - float32 dtype - 1.68 GiB\n",
      "CommonReferenceRecording: 64 channels - 30.0kHz - 1 segments - 7,031,518 samples \n",
      "                          234.38s (3.91 minutes) - float32 dtype - 1.68 GiB\n",
      "Use cache_folder=/tmp/spikeinterface_cache/tmpq3oq4adi/UC8PBUQH\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=1 - samples_per_chunk=30,000 - chunk_memory=7.32 MiB - total_memory=7.32 MiB - chunk_duration=1.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "write_binary_recording (no parallelization): 100%|██████████| 235/235 [00:11<00:00, 21.15it/s]\n",
      "/tmp/ipykernel_1458373/1382817715.py:11: DeprecationWarning: `output_folder` is deprecated and will be removed in version 0.103.0 Please use folder instead\n",
      "  sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryFolderRecording: 64 channels - 30.0kHz - 1 segments - 7,031,518 samples \n",
      "                       234.38s (3.91 minutes) - float32 dtype - 1.68 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:09<00:00, 11.83it/s]\n",
      "100%|██████████| 8/8 [00:21<00:00,  2.66s/it]\n",
      "100%|██████████| 118/118 [00:03<00:00, 31.27it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "estimate_sparsity (no parallelization): 100%|██████████| 235/235 [00:00<00:00, 5650.40it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/core/basesorting.py:261: UserWarning: The registered recording will not be persistent on disk, but only available in memory\n",
      "  warnings.warn(\"The registered recording will not be persistent on disk, but only available in memory\")\n"
     ]
    }
   ],
   "source": [
    "recording_cmr = recording_recorded\n",
    "recording_f = spre.bandpass_filter(recording_recorded, freq_min=300, freq_max=3000)\n",
    "print(recording_f)\n",
    "recording_cmr = spre.common_reference(recording_f, reference=\"global\", operator=\"median\")\n",
    "print(recording_cmr)\n",
    "\n",
    "# this computes and saves the recording after applying the preprocessing chain\n",
    "recording_preprocessed = recording_cmr.save(format=\"binary\")\n",
    "print(recording_preprocessed)\n",
    "output_folder = '/media/ubuntu/sda/Monkey/test'\n",
    "sorting_kilosort4 = ss.run_sorter(sorter_name=\"kilosort4\", recording=recording_preprocessed, output_folder=output_folder + \"/kilosort4\")\n",
    "analyzer_kilosort4 = si.create_sorting_analyzer(sorting=sorting_kilosort4, recording=recording_preprocessed, format='binary_folder', folder=output_folder + '/analyzer_kilosort4_binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e69e35e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute_waveforms (no parallelization): 100%|██████████| 235/235 [00:10<00:00, 22.62it/s]\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 50.80it/s]\n",
      "Compute : spike_amplitudes + spike_locations (no parallelization): 100%|██████████| 235/235 [00:01<00:00, 231.21it/s]\n",
      "/home/ubuntu/.conda/envs/spike_sorting_jct/lib/python3.11/site-packages/spikeinterface/qualitymetrics/misc_metrics.py:910: UserWarning: Some units have too few spikes : amplitude_cutoff is set to NaN\n",
      "  warnings.warn(f\"Some units have too few spikes : amplitude_cutoff is set to NaN\")\n",
      "noise_level (no parallelization): 100%|██████████| 20/20 [00:00<00:00, 884.63it/s]\n",
      "write_binary_recording (no parallelization): 100%|██████████| 235/235 [00:24<00:00,  9.40it/s]\n",
      "Fitting PCA: 100%|██████████| 64/64 [00:12<00:00,  5.21it/s]\n",
      "Projecting waveforms: 100%|██████████| 64/64 [00:00<00:00, 2211.66it/s]\n",
      "extract PCs (no parallelization): 100%|██████████| 235/235 [00:16<00:00, 13.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:\n",
      "phy template-gui  /media/ubuntu/sda/Monkey/test/phy_folder_for_kilosort/params.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extensions_to_compute = [\n",
    "            \"random_spikes\",\n",
    "            \"waveforms\",\n",
    "            \"noise_levels\",\n",
    "            \"templates\",\n",
    "            \"spike_amplitudes\",\n",
    "            \"unit_locations\",\n",
    "            \"spike_locations\",\n",
    "            \"correlograms\",\n",
    "            \"template_similarity\"\n",
    "        ]\n",
    "\n",
    "extension_params = {\n",
    "    \"unit_locations\": {\"method\": \"center_of_mass\"},\n",
    "    \"spike_locations\": {\"ms_before\": 0.1},\n",
    "    \"correlograms\": {\"bin_ms\": 0.1},\n",
    "    \"template_similarity\": {\"method\": \"cosine_similarity\"}\n",
    "}\n",
    "\n",
    "analyzer_kilosort4.compute(extensions_to_compute, extension_params=extension_params)\n",
    "\n",
    "qm_params = sqm.get_default_qm_params()\n",
    "analyzer_kilosort4.compute(\"quality_metrics\", qm_params)\n",
    "\n",
    "import spikeinterface.exporters as sexp\n",
    "sexp.export_to_phy(analyzer_kilosort4, output_folder + \"/phy_folder_for_kilosort\", verbose=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike_sorting_jct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
