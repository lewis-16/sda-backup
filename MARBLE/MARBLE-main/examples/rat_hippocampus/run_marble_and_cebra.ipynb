{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train MARBLE and Cebra\n",
    "\n",
    "In this notebook we train the MARBLE and Cebra models to analyse the rat hippocampal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install cebra elephant\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from cebra import CEBRA\n",
    "\n",
    "import MARBLE\n",
    "from rat_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/7609512 -O data/rat_data.pkl\n",
    "\n",
    "with open('data/rat_data.pkl', 'rb') as handle:\n",
    "    hippocampus_pos = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models\n",
    "\n",
    "*[This can be skipped if you already saved the models].*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train and test splits of the data\n",
    "\n",
    "def split_data(data, test_ratio):\n",
    "\n",
    "    split_idx = int(data['neural'].shape[0] * (1-test_ratio))\n",
    "    neural_train = data['neural'][:split_idx]\n",
    "    neural_test = data['neural'][split_idx:]\n",
    "    label_train = data['continuous_index'][:split_idx]\n",
    "    label_test = data['continuous_index'][split_idx:]\n",
    "    \n",
    "    return neural_train.numpy(), neural_test.numpy(), label_train.numpy(), label_test.numpy()\n",
    "\n",
    "\n",
    "neural_train, neural_test, label_train, label_test = split_data(hippocampus_pos['achilles'], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40 hz sampling rate (they binned into 25ms epochs\n",
    "\n",
    "spikes = neural_train[:2000,:].T\n",
    "spikes = [np.where(spikes[ch,:])[0]/40 for ch in range(120)] \n",
    "    \n",
    "_, ax = plt.subplots(figsize=(8,4))\n",
    "ax.eventplot(spikes,color='gray')\n",
    "plt.ylabel('Neurons')\n",
    "plt.xlabel('Time (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CEBRA-time and Cebra-behaviour on all animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 10000\n",
    "output_dimension = 32 #set to 3 for embeddings and 32 for decoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for rat in list(hippocampus_pos.keys()):\n",
    "\n",
    "    print('train Cebra time')\n",
    "    cebra_time = CEBRA(model_architecture='offset10-model',\n",
    "                       batch_size=512,\n",
    "                       learning_rate=3e-4,\n",
    "                       temperature=1.12,\n",
    "                       output_dimension=output_dimension,\n",
    "                       max_iterations=10000,\n",
    "                       distance='cosine',\n",
    "                       conditional='time', # 'time' means we are only using time information in the samples\n",
    "                       device='cuda_if_available',\n",
    "                       verbose=True,\n",
    "                       time_offsets=10)\n",
    "    \n",
    "    cebra_time.fit(hippocampus_pos[rat][\"neural\"])\n",
    "    cebra_time.save(f\"data/cebra_time_{rat}.pt\")\n",
    "\n",
    "    print('train Cebra behaviour')\n",
    "    cebra_behaviour = CEBRA(model_architecture='offset10-model',\n",
    "                            batch_size=512,\n",
    "                            learning_rate=3e-4,\n",
    "                            temperature=1,\n",
    "                            output_dimension=output_dimension, \n",
    "                            max_iterations=max_iterations,\n",
    "                            distance='cosine',\n",
    "                            conditional='time_delta', #'time_delta' means we will use CEBRA-Behavior mode and use auxiliary behavior variable for the model training\n",
    "                            device='cuda_if_available',\n",
    "                            verbose=True,\n",
    "                            time_offsets=10)\n",
    "    \n",
    "    cebra_behaviour.fit(hippocampus_pos[rat][\"neural\"], hippocampus_pos[rat]['continuous_index'].numpy())\n",
    "    cebra_behaviour.save(f\"data/cebra_behaviour_{rat}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train MARBLE with only neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for rat in list(hippocampus_pos.keys()):\n",
    "    # build model \n",
    "    data, labels, _ = convert_spikes_to_rates(hippocampus_pos[rat][\"neural\"],\n",
    "                                              labels=hippocampus_pos[rat]['continuous_index'].numpy(),\n",
    "                                              pca_n=10)\n",
    "    pickle.dump([data, labels], open(f'data/{rat}_preprocessed_data.pkl','wb'))\n",
    "    \n",
    "    # build model\n",
    "    params = {\n",
    "        \"epochs\": 100,\n",
    "        \"order\": 1,  # order of derivatives\n",
    "        \"hidden_channels\": [64],  # number of internal dimensions in MLP\n",
    "        \"out_channels\": output_dimension, \n",
    "        \"inner_product_features\": False,\n",
    "        \"emb_norm\": True, # spherical output embedding\n",
    "        \"diffusion\": False,\n",
    "        \"include_positions\": True,\n",
    "      }\n",
    "    \n",
    "    model = MARBLE.net(data, params=params.copy()) #define model\n",
    "    model.fit(data, outdir=f\"data/hippocampus_{rat}\") # train model\n",
    "    data = model.transform(data) #evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MARBLE with different preprocessing hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vary PCA dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"epochs\": 100,\n",
    "        \"order\": 1,  # order of derivatives\n",
    "        \"hidden_channels\": [64],  # number of internal dimensions in MLP\n",
    "        \"out_channels\": 32, \n",
    "        \"inner_product_features\": False,\n",
    "        \"emb_norm\": True, # spherical output embedding\n",
    "        \"diffusion\": False,\n",
    "        \"include_positions\": True,\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rat = 'achilles'\n",
    "kernel_width = 10\n",
    "\n",
    "for pca_n in [3,5,10,20,30]:\n",
    "\n",
    "    data, _, _ = convert_spikes_to_rates(hippocampus_pos[rat][\"neural\"],\n",
    "                                        pca_n=pca_n,\n",
    "                                        kernel_width=kernel_width)\n",
    "    model = MARBLE.net(data, params=params.copy())\n",
    "    model.fit(data, outdir=f\"data/hippocampus_{rat}_pca{pca_n}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vary Gaussian kernel width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_n = 20\n",
    "rat = 'achilles'\n",
    "\n",
    "for kernel_width in [3,5,10,20,30,50,100]:\n",
    "    data, _, _ = convert_spikes_to_rates(hippocampus_pos[rat][\"neural\"], \n",
    "                                         pca_n=pca_n,\n",
    "                                         kernel_width=kernel_width)\n",
    "    model = MARBLE.net(data, params=params.copy())\n",
    "    model.fit(data, outdir=f\"data/hippocampus_{rat}_kw{kernel_width}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
