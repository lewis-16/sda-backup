{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity analysis\n",
    "\n",
    "In this notebook, we compare MARBLE for different hyperparameter settings to show the robustness of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install cebra statannotations elephant\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from statannotations.Annotator import Annotator\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import cebra\n",
    "\n",
    "import MARBLE\n",
    "from rat_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/7609512 -O data/rat_data.pkl\n",
    "\n",
    "with open('data/rat_data.pkl', 'rb') as handle:\n",
    "    hippocampus_pos = pickle.load(handle)\n",
    "    \n",
    "hippocampus_pos = hippocampus_pos['achilles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train and test splits of the data\n",
    "def split_data(data, test_ratio):\n",
    "\n",
    "    split_idx = int(data['neural'].shape[0] * (1-test_ratio))\n",
    "    neural_train = data['neural'][:split_idx]\n",
    "    neural_test = data['neural'][split_idx:]\n",
    "    label_train = data['continuous_index'][:split_idx]\n",
    "    label_test = data['continuous_index'][split_idx:]\n",
    "    \n",
    "    return neural_train.numpy(), neural_test.numpy(), label_train.numpy(), label_test.numpy()\n",
    "\n",
    "neural_train, neural_test, label_train, label_test = split_data(hippocampus_pos, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness vs number of PCA components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch and evaluate pretrained MARBLE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/10212902 -O data/marble_achilles_pca3.pth\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/10212900 -O data/marble_achilles_pca5.pth\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/10212891 -O data/marble_achilles_pca10.pth\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/10212896 -O data/marble_achilles_pca20.pth\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/10212901 -O data/marble_achilles_pca30.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing, labels_train, labels_test = [], [], [], []\n",
    "\n",
    "for i, pca_n in enumerate([3, 5, 10, 20, 30]):\n",
    "    data_train, label_train_marble, pca = convert_spikes_to_rates(neural_train.T, label_train, pca_n=pca_n)\n",
    "    data_test, label_test_marble, _ = convert_spikes_to_rates(neural_test.T, label_test, pca=pca)\n",
    "    marble_model = MARBLE.net(data_train, loadpath=f\"data/marble_achilles_pca{pca_n}.pth\")\n",
    "    \n",
    "    data_train = marble_model.transform(data_train)\n",
    "    data_test = marble_model.transform(data_test)\n",
    "    \n",
    "    training.append(data_train)\n",
    "    testing.append(data_test)\n",
    "    labels_train.append(label_train_marble)\n",
    "    labels_test.append(label_test_marble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch and evaluate pretrained Cebra models for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cebra-time\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/7609517 -O data/cebra_time_achilles_32D.pt\n",
    "cebra_time_model = cebra.CEBRA.load(\"data/cebra_time_achilles_32D.pt\")\n",
    "cebra_time_train = cebra_time_model.transform(neural_train)\n",
    "cebra_time_test = cebra_time_model.transform(neural_test)\n",
    "\n",
    "#Cebra-behaviour\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/7609520 -O data/cebra_behaviour_achilles_32D.pt\n",
    "cebra_behaviour_model = cebra.CEBRA.load(\"data/cebra_behaviour_achilles_32D.pt\")\n",
    "cebra_behaviour_train = cebra_behaviour_model.transform(neural_train)\n",
    "cebra_behaviour_test = cebra_behaviour_model.transform(neural_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_time_decode = decoding_pos_dir(cebra_time_train, cebra_time_test, label_train, label_test)\n",
    "cebra_behaviour_decode = decoding_pos_dir(cebra_behaviour_train, cebra_behaviour_test, label_train, label_test)\n",
    "marble_decode = decoding_pos_dir(data_train.emb, data_test.emb, label_train_marble, label_test_marble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 5\n",
    "num_plots_per_model = 2\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "\n",
    "for i, pca_n in enumerate([3, 5, 10, 20, 30]):\n",
    "    \n",
    "    data_train = training[i]\n",
    "    data_test = testing[i]\n",
    "    label_train_marble = labels_train[i]\n",
    "    label_test_marble = labels_test[i]\n",
    "\n",
    "    # Calculate subplot index for training data\n",
    "    ax1 = fig.add_subplot( num_plots_per_model, num_models, i+1, projection='3d')\n",
    "    ax = cebra.plot_embedding(ax=ax1, embedding=data_train.emb, embedding_labels=label_train_marble[:,0], markersize=0.2, title=f'MARBLE-train_pca{pca_n}')\n",
    "    \n",
    "    # Calculate subplot index for testing data\n",
    "    ax2 = fig.add_subplot(num_plots_per_model, num_models, num_models + i + 1, projection='3d')\n",
    "    ax = cebra.plot_embedding(ax=ax2, embedding=data_test.emb, embedding_labels=label_test_marble[:,0], markersize=1, title=f'MARBLE-test_pca{pca_n}')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [cebra_time_decode[4][:-1], cebra_behaviour_decode[4][:-1] ]\n",
    "for i, pca_n in enumerate([3, 5, 10, 20, 30]):\n",
    "    \n",
    "    data_train = training[i]\n",
    "    data_test = testing[i]\n",
    "    label_train_marble = labels_train[i]\n",
    "    label_test_marble = labels_test[i]\n",
    "    \n",
    "    marble_decode = decoding_pos_dir(data_train.emb, data_test.emb, label_train_marble, label_test_marble)\n",
    "    results.append(marble_decode[4])\n",
    "    \n",
    "results = pd.DataFrame(data=np.vstack(results).T,columns=['c-time','c-behaviour','pca3','pca5','pca10','pca20','pca30',])\n",
    "results = results.melt()\n",
    "results.columns = ['model','accuracy']\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "sns.despine(bottom=True, left=True)\n",
    "\n",
    "random_sampling = np.random.randint(low=0, high=results.shape[0], size=(200,))\n",
    "order = ['c-time','c-behaviour','pca5','pca3','pca10','pca20','pca30',]\n",
    "sns.stripplot(\n",
    "    data=results.iloc[random_sampling,:], x=\"model\", y=\"accuracy\", order=order, \n",
    "    dodge=True, alpha=.5, zorder=1, color='gray',\n",
    ")\n",
    "\n",
    "sns.pointplot(\n",
    "    data=results, x=\"model\", y=\"accuracy\",  order=order, \n",
    "    join=False, dodge=.8 - .8 / 3, palette=\"dark\",\n",
    "    markers=\"d\", scale=.75, errorbar=None\n",
    ")\n",
    "\n",
    "plt.ylim([0,0.4])\n",
    "\n",
    "pairs=[(\"c-time\", \"c-behaviour\"),\n",
    "      (\"c-behaviour\", \"pca3\"),\n",
    "      (\"pca3\", \"pca5\"),\n",
    "      (\"pca5\", \"pca10\"),\n",
    "      (\"pca10\", \"pca20\"),\n",
    "      (\"pca20\", \"pca30\"),]\n",
    "\n",
    "annotator = Annotator(ax, pairs, data=results, x=\"model\", y=\"accuracy\",order=order)\n",
    "annotator.configure(test='Wilcoxon', text_format='star', loc='outside')\n",
    "annotator.apply_and_annotate()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness against kernel width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch pretrained MARBLE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/10212895 -O data/marble_achilles_kw3.pth\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/10212898 -O data/marble_achilles_kw5.pth\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/10212892 -O data/marble_achilles_kw10.pth\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/10212893 -O data/marble_achilles_kw20.pth\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/10212894 -O data/marble_achilles_kw30.pth\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/10212897 -O data/marble_achilles_kw50.pth\n",
    "!wget -nc https://dataverse.harvard.edu/api/access/datafile/10212899 -O data/marble_achilles_kw100.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training, testing, labels_train, labels_test = [], [], [], []\n",
    "pca_n = 20\n",
    "\n",
    "for i, kw in enumerate([3, 5, 10, 20, 30, 50, 100]):\n",
    "    data_train, label_train_marble, pca = convert_spikes_to_rates(neural_train.T, label_train, pca_n=pca_n, kernel_width=kw)\n",
    "    data_test, label_test_marble, _ = convert_spikes_to_rates(neural_test.T, label_test, kernel_width=kw,  pca=pca)\n",
    "    marble_model = MARBLE.net(data_train, loadpath=f\"data/marble_achilles_kw{kw}.pth\")\n",
    "    \n",
    "    data_train = marble_model.transform(data_train)\n",
    "    data_test = marble_model.transform(data_test)\n",
    "    \n",
    "    training.append(data_train)\n",
    "    testing.append(data_test)\n",
    "    labels_train.append(label_train_marble)\n",
    "    labels_test.append(label_test_marble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 7\n",
    "num_plots_per_model = 2\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "\n",
    "for i, kw in enumerate([3, 5, 10, 20, 30, 50, 100]):\n",
    "    data_train = training[i]\n",
    "    data_test = testing[i]\n",
    "    label_train_marble = labels_train[i]\n",
    "    label_test_marble = labels_test[i]\n",
    "\n",
    "    # Calculate subplot index for training data in the first row\n",
    "    ax1 = fig.add_subplot(num_plots_per_model, num_models, i+1, projection='3d')\n",
    "    ax = cebra.plot_embedding(ax=ax1, embedding=data_train.emb, embedding_labels=label_train_marble[:,0], markersize=0.2, title=f'MARBLE-train_kw{kw}')\n",
    "    \n",
    "    # Calculate subplot index for testing data in the second row\n",
    "    ax2 = fig.add_subplot(num_plots_per_model, num_models, num_models + i + 1, projection='3d')\n",
    "    ax = cebra.plot_embedding(ax=ax2, embedding=data_test.emb, embedding_labels=label_test_marble[:,0], markersize=1, title=f'MARBLE-test_kw{kw}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('marble_cebra_embeddings_3D_kernelwidth_scan.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = [cebra_time_decode[4][:-1], cebra_behaviour_decode[4][:-1] ]\n",
    "for i, kw in enumerate([3, 5, 10, 20, 30, 50, 100]):\n",
    "    \n",
    "    data_train = training[i]\n",
    "    data_test = testing[i]\n",
    "    label_train_marble = labels_train[i]\n",
    "    label_test_marble = labels_test[i]\n",
    "    \n",
    "    marble_decode = decoding_pos_dir(data_train.emb, data_test.emb, label_train_marble, label_test_marble)\n",
    "    results.append(marble_decode[4])\n",
    "    \n",
    "    \n",
    "    \n",
    "results = pd.DataFrame(data=np.vstack(results).T,columns=['c-time','c-pos+dir', 'c-pos','kw3','kw5','kw10','kw20','kw30','kw50','kw100',])\n",
    "results = results.melt()\n",
    "results.columns = ['model','accuracy']\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "sns.despine(bottom=True, left=True)\n",
    "\n",
    "random_sampling = np.random.randint(low=0, high=results.shape[0], size=(200,))\n",
    "\n",
    "sns.stripplot(\n",
    "    data=results.iloc[random_sampling,:], x=\"model\", y=\"accuracy\", order=['c-time','c-pos+dir', 'c-pos','kw3','kw5','kw10','kw20','kw30','kw50','kw100',], \n",
    "    dodge=True, alpha=.5, zorder=1, color='gray',\n",
    ")\n",
    "\n",
    "sns.pointplot(\n",
    "    data=results, x=\"model\", y=\"accuracy\",\n",
    "    join=False, dodge=.8 - .8 / 3, palette=\"dark\",\n",
    "    markers=\"d\", scale=.75, errorbar=None\n",
    ")\n",
    "\n",
    "plt.ylim([0,0.4])\n",
    "\n",
    "pairs=[(\"c-time\", \"kw3\"),\n",
    "      (\"c-pos+dir\", \"kw3\"),\n",
    "      (\"c-pos\", \"kw3\"),\n",
    "        (\"kw3\", \"kw5\"),\n",
    "      (\"kw5\", \"kw10\"),\n",
    "      (\"kw10\", \"kw20\"),\n",
    "      (\"kw20\", \"kw30\"),\n",
    "      (\"kw30\", \"kw50\"),\n",
    "      (\"kw50\", \"kw100\")]\n",
    "\n",
    "annotator = Annotator(ax, pairs, data=results, x=\"model\", y=\"accuracy\",)\n",
    "annotator.configure(test='Wilcoxon', text_format='star', loc='outside')\n",
    "annotator.apply_and_annotate()\n",
    "plt.tight_layout()\n",
    "plt.savefig('decoding_accuracy_rat_32output_violin_kwscan.svg')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
